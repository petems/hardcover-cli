This file is a merged representation of the entire codebase, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
.github/
  workflows/
    ci.yml
    dependency-update.yml
    nightly.yml
    release.yml
  dependabot.yml
  pull_request_template.md
  WORKFLOWS.md
cmd/
  book_test.go
  book.go
  config_integration_test.go
  config_test.go
  config.go
  context.go
  me_test.go
  me.go
  root_test.go
  root.go
  schema.go
  search_test.go
  search.go
internal/
  client/
    client_test.go
    client.go
    generated.go
    genqlient.yaml
    queries.graphql
    schema.graphql
  config/
    config_test.go
    config.go
.gitignore
.golangci.yml
DEVELOPMENT.md
go.mod
GRAPHQL.md
HARDCOVER_API_ISSUE.md
LICENSE
main.go
Makefile
README.md
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="cmd/schema.go">
package cmd

import (
	"context"
	"encoding/json"
	"fmt"
	"io"
	"net/http"
	"os"
	"path/filepath"
	"strings"

	"hardcover-cli/internal/config"

	"github.com/spf13/cobra"
)

const (
	unknownType = "Unknown"
	dirPerm     = 0o750
	filePerm    = 0o600
)

var schemaCmd = &cobra.Command{
	Use:   "schema",
	Short: "Fetch the latest GraphQL schema from the remote endpoint",
	Long: `Fetch the latest GraphQL schema from the Hardcover.app GraphQL API endpoint.
This command downloads the schema using introspection and saves it to the local schema file.
Authentication is handled via the config file or command line arguments.`,
	RunE: runSchemaFetch,
}

func initSchemaCmd() {
	schemaCmd.Flags().StringP("output", "o", "", "Output file path (default: internal/client/schema.graphql)")
	schemaCmd.Flags().StringP("endpoint", "e", "", "GraphQL endpoint URL (default: from config)")
}

func runSchemaFetch(cmd *cobra.Command, args []string) error {
	ctx := cmd.Context()
	cfg, ok := getConfig(ctx)
	if !ok {
		return fmt.Errorf("failed to get configuration")
	}

	// Get and validate flags
	outputPath, endpoint, err := getSchemaFlags(cmd)
	if err != nil {
		return err
	}

	// Set defaults
	outputPath = getDefaultOutputPath(outputPath)
	endpoint = getDefaultEndpoint(endpoint, cfg)

	// Ensure output directory exists
	if dirErr := ensureOutputDirectory(outputPath); dirErr != nil {
		return dirErr
	}

	// Display status
	displaySchemaStatus(endpoint, cfg.APIKey)

	// Fetch schema
	schemaSDL, err := fetchSchema(ctx, endpoint, cfg.APIKey)
	if err != nil {
		return err
	}

	// Write to file
	if err := os.WriteFile(outputPath, []byte(schemaSDL), filePerm); err != nil {
		return fmt.Errorf("failed to write schema file: %w", err)
	}

	fmt.Printf("Schema successfully written to: %s\n", outputPath)
	return nil
}

func introspectionToSDL(introspection map[string]interface{}) (string, error) {
	// Convert introspection JSON to GraphQL SDL
	data, ok := introspection["data"].(map[string]interface{})
	if !ok {
		return "", fmt.Errorf("invalid introspection response format")
	}

	schema, ok := data["__schema"].(map[string]interface{})
	if !ok {
		return "", fmt.Errorf("invalid schema in introspection response")
	}

	var sdl strings.Builder
	sdl.WriteString("# Generated GraphQL Schema from Introspection\n\n")

	// Extract types
	types, ok := schema["types"].([]interface{})
	if !ok {
		return "", fmt.Errorf("invalid types in schema")
	}

	// Process each type
	for _, typeInterface := range types {
		if err := processType(&sdl, typeInterface); err != nil {
			return "", err
		}
	}

	return sdl.String(), nil
}

func processType(sdl *strings.Builder, typeInterface interface{}) error {
	typeMap, ok := typeInterface.(map[string]interface{})
	if !ok {
		return nil
	}

	kind, ok := typeMap["kind"].(string)
	if !ok {
		return nil
	}
	name, ok := typeMap["name"].(string)
	if !ok {
		return nil
	}
	description, _ := typeMap["description"].(string) //nolint:errcheck // description is optional

	// Skip introspection types
	if strings.HasPrefix(name, "__") {
		return nil
	}

	// Add description as comment
	if description != "" {
		fmt.Fprintf(sdl, "\"\"\"\n%s\n\"\"\"\n", description)
	}

	switch kind {
	case "OBJECT":
		return processObjectType(sdl, typeMap, name)
	case "SCALAR":
		fmt.Fprintf(sdl, "scalar %s\n\n", name)
	case "ENUM":
		return processEnumType(sdl, typeMap)
	case "INPUT_OBJECT":
		return processInputObjectType(sdl, typeMap)
	}

	return nil
}

func processObjectType(sdl *strings.Builder, typeMap map[string]interface{}, name string) error {
	// Map query_root to Query for standard GraphQL compatibility
	typeName := name
	if name == "query_root" {
		typeName = "Query"
	}
	fmt.Fprintf(sdl, "type %s {\n", typeName)

	if fields, ok := typeMap["fields"].([]interface{}); ok {
		for _, fieldInterface := range fields {
			field, ok := fieldInterface.(map[string]interface{})
			if !ok {
				continue
			}
			fieldName, ok := field["name"].(string)
			if !ok {
				continue
			}
			fieldType := getTypeString(field["type"])
			fmt.Fprintf(sdl, "  %s: %s\n", fieldName, fieldType)
		}
	}
	sdl.WriteString("}\n\n")
	return nil
}

func processEnumType(sdl *strings.Builder, typeMap map[string]interface{}) error {
	name, ok := typeMap["name"].(string)
	if !ok {
		return nil
	}
	fmt.Fprintf(sdl, "enum %s {\n", name)

	if enumValues, ok := typeMap["enumValues"].([]interface{}); ok {
		for _, valueInterface := range enumValues {
			value, ok := valueInterface.(map[string]interface{})
			if !ok {
				continue
			}
			valueName, ok := value["name"].(string)
			if !ok {
				continue
			}
			fmt.Fprintf(sdl, "  %s\n", valueName)
		}
	}
	sdl.WriteString("}\n\n")
	return nil
}

func processInputObjectType(sdl *strings.Builder, typeMap map[string]interface{}) error {
	name, ok := typeMap["name"].(string)
	if !ok {
		return nil
	}
	fmt.Fprintf(sdl, "input %s {\n", name)

	if inputFields, ok := typeMap["inputFields"].([]interface{}); ok {
		for _, fieldInterface := range inputFields {
			field, ok := fieldInterface.(map[string]interface{})
			if !ok {
				continue
			}
			fieldName, ok := field["name"].(string)
			if !ok {
				continue
			}
			fieldType := getTypeString(field["type"])
			fmt.Fprintf(sdl, "  %s: %s\n", fieldName, fieldType)
		}
	}
	sdl.WriteString("}\n\n")
	return nil
}

func getTypeString(typeInterface interface{}) string {
	typeMap, ok := typeInterface.(map[string]interface{})
	if !ok {
		return unknownType
	}

	kind, ok := typeMap["kind"].(string)
	if !ok {
		return unknownType
	}
	name, ok := typeMap["name"].(string)
	if !ok {
		return unknownType
	}

	switch kind {
	case "NON_NULL":
		return getTypeString(typeMap["ofType"]) + "!"
	case "LIST":
		return "[" + getTypeString(typeMap["ofType"]) + "]"
	case "SCALAR", "OBJECT", "ENUM", "INPUT_OBJECT":
		return name
	default:
		return unknownType
	}
}

func getIntrospectionQuery() string {
	return `{"query": "query IntrospectionQuery { __schema { queryType { name } mutationType { name } ` +
		`subscriptionType { name } types { ...FullType } directives { name description locations ` +
		`args { ...InputValue } } } } fragment FullType on __Type { kind name description ` +
		`fields(includeDeprecated: true) { name description args { ...InputValue } type { ...TypeRef } ` +
		`isDeprecated deprecationReason } inputFields { ...InputValue } interfaces { ...TypeRef } ` +
		`enumValues(includeDeprecated: true) { name description isDeprecated deprecationReason } ` +
		`possibleTypes { ...TypeRef } } fragment InputValue on __InputValue { name description ` +
		`type { ...TypeRef } defaultValue } fragment TypeRef on __Type { kind name ofType { kind name ` +
		`ofType { kind name ofType { kind name ofType { kind name ofType { kind name } } } } } } } }"}`
}

func getSchemaFlags(cmd *cobra.Command) (outputPath, endpoint string, err error) {
	outputPath, err = cmd.Flags().GetString("output")
	if err != nil {
		return "", "", fmt.Errorf("failed to get output flag: %w", err)
	}
	endpoint, err = cmd.Flags().GetString("endpoint")
	if err != nil {
		return "", "", fmt.Errorf("failed to get endpoint flag: %w", err)
	}
	return outputPath, endpoint, nil
}

func getDefaultOutputPath(outputPath string) string {
	if outputPath == "" {
		return "internal/client/schema.graphql"
	}
	return outputPath
}

func getDefaultEndpoint(endpoint string, cfg *config.Config) string {
	if endpoint == "" {
		endpoint = cfg.BaseURL
	}
	if endpoint == "" {
		endpoint = "https://api.hardcover.app/v1/graphql"
	}
	return endpoint
}

func ensureOutputDirectory(outputPath string) error {
	outputDir := filepath.Dir(outputPath)
	if mkdirErr := os.MkdirAll(outputDir, dirPerm); mkdirErr != nil {
		return fmt.Errorf("failed to create output directory: %w", mkdirErr)
	}
	return nil
}

func displaySchemaStatus(endpoint, apiKey string) {
	fmt.Printf("Fetching schema from: %s\n", endpoint)
	if apiKey != "" {
		fmt.Println("Using API key for authentication")
	} else {
		fmt.Println("No API key found - trying without authentication")
	}
}

func fetchSchema(ctx context.Context, endpoint, apiKey string) (string, error) {
	// Create HTTP request
	req, err := http.NewRequestWithContext(ctx, "POST", endpoint, strings.NewReader(getIntrospectionQuery()))
	if err != nil {
		return "", fmt.Errorf("failed to create request: %w", err)
	}

	req.Header.Set("Content-Type", "application/json")
	if apiKey != "" {
		req.Header.Set("Authorization", "Bearer "+apiKey)
	}

	// Make request
	client := &http.Client{}
	resp, err := client.Do(req)
	if err != nil {
		return "", fmt.Errorf("failed to make request: %w", err)
	}
	defer func() {
		if closeErr := resp.Body.Close(); closeErr != nil {
			fmt.Printf("Warning: failed to close response body: %v\n", closeErr)
		}
	}()

	if resp.StatusCode != http.StatusOK {
		body, readErr := io.ReadAll(resp.Body)
		if readErr != nil {
			return "", fmt.Errorf("HTTP %d: failed to read response body: %w", resp.StatusCode, readErr)
		}
		return "", fmt.Errorf("HTTP %d: %s", resp.StatusCode, string(body))
	}

	// Parse response
	var result map[string]interface{}
	if decodeErr := json.NewDecoder(resp.Body).Decode(&result); decodeErr != nil {
		return "", fmt.Errorf("failed to decode response: %w", decodeErr)
	}

	// Check for GraphQL errors
	if errors, ok := result["errors"].([]interface{}); ok && len(errors) > 0 {
		return "", fmt.Errorf("GraphQL errors: %v", errors)
	}

	// Convert introspection result to GraphQL SDL
	schemaSDL, err := introspectionToSDL(result)
	if err != nil {
		return "", fmt.Errorf("failed to convert introspection to SDL: %w", err)
	}

	return schemaSDL, nil
}

func setupSchemaCommands() {
	initSchemaCmd()
	rootCmd.AddCommand(schemaCmd)
}
</file>

<file path="HARDCOVER_API_ISSUE.md">
# Hardcover API GraphQL Introspection Issue

## Summary

The GraphQL introspection schema at `https://api.hardcover.app/v1/graphql` does not expose the parameters for the `search` field, even though the API documentation and runtime behavior support them.

## Issue Details

**Expected Schema (per API docs):**
```graphql
type Query {
  search(
    query: String!
    query_type: String
    per_page: Int
    page: Int
    sort: String
    fields: String
    weights: String
  ): SearchOutput
}
```

**Actual Introspection Result:**
```graphql
type Query {
  search: SearchOutput
}
```

## Impact

- **Code Generation Tools**: Tools like `genqlient` cannot generate type-safe code for the search functionality because the introspection schema doesn't match the runtime API.
- **Developer Experience**: Developers need to manually patch their local schema files or use raw HTTP requests for search functionality.
- **Documentation Mismatch**: The API documentation at https://docs.hardcover.app/api/guides/searching/ shows parameters that aren't reflected in the introspection schema.

## Workaround

Currently, developers need to manually patch their local `schema.graphql` files to add the missing parameters, then regenerate their client code.

## Request

Could the GraphQL introspection schema be updated to include the search field parameters? This would enable proper code generation and improve the developer experience.

## References

- [API Search Documentation](https://docs.hardcover.app/api/guides/searching/)
- GraphQL Endpoint: `https://api.hardcover.app/v1/graphql`

## Example Query That Works at Runtime

```graphql
query SearchBooks {
  search(
    query: "lord of the rings"
    query_type: "Book"
    per_page: 5
    page: 1
  ) {
    results
    ids
    query
    query_type
  }
}
```

This query works perfectly at runtime but cannot be validated or code-generated from the current introspection schema.
</file>

<file path=".github/pull_request_template.md">
## Description

Please provide a clear and concise description of the changes in this PR.

### Type of Change

Please delete options that are not relevant:

- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] Documentation update
- [ ] Performance improvement
- [ ] Code refactoring (no functional changes)
- [ ] Test improvements
- [ ] CI/CD improvements

## Related Issues

Fixes #(issue_number)
Closes #(issue_number)
Related to #(issue_number)

## Changes Made

Please describe the changes made in this PR:

- 
- 
- 

## Testing

### Test Coverage

- [ ] Unit tests added/updated
- [ ] Integration tests added/updated
- [ ] All existing tests pass
- [ ] New tests pass

### Manual Testing

Please describe the manual testing performed:

- [ ] Tested on Linux
- [ ] Tested on macOS
- [ ] Tested on Windows
- [ ] Tested CLI commands
- [ ] Tested error scenarios

### Test Commands

```bash
# Commands used for testing
go test ./...
go test -race ./...
./hardcover --help
# Add specific test commands here
```

## Code Quality

- [ ] Code follows Go best practices
- [ ] Code is properly formatted (`gofmt`)
- [ ] Code passes linting (`golangci-lint`)
- [ ] Code includes proper error handling
- [ ] Code includes appropriate comments/documentation

## Security

- [ ] No sensitive information is exposed
- [ ] Input validation is implemented where needed
- [ ] Security best practices are followed
- [ ] Dependencies are up to date and secure

## Performance

- [ ] Changes do not negatively impact performance
- [ ] Benchmarks run (if applicable)
- [ ] Memory usage is reasonable

## Documentation

- [ ] Code is self-documenting
- [ ] README updated (if needed)
- [ ] API documentation updated (if needed)
- [ ] Help text updated (if needed)
- [ ] CHANGELOG updated (if needed)

## Dependencies

- [ ] No new dependencies added
- [ ] New dependencies are necessary and well-maintained
- [ ] Dependencies are properly versioned
- [ ] `go.mod` and `go.sum` are updated

## Breaking Changes

If this PR introduces breaking changes, please describe them and the migration path:

- 
- 

## Screenshots/Examples

If applicable, add screenshots or example outputs to help explain your changes:

```
# Example command output
$ hardcover --help
...
```

## Checklist

- [ ] I have read the [CONTRIBUTING](CONTRIBUTING.md) guidelines
- [ ] My code follows the project's coding standards
- [ ] I have performed a self-review of my code
- [ ] I have commented my code, particularly in hard-to-understand areas
- [ ] I have made corresponding changes to the documentation
- [ ] My changes generate no new warnings
- [ ] I have added tests that prove my fix is effective or that my feature works
- [ ] New and existing unit tests pass locally with my changes
- [ ] Any dependent changes have been merged and published

## Additional Notes

Add any additional notes or context about the PR here.

## Reviewer Focus Areas

Please pay special attention to:

- [ ] Logic correctness
- [ ] Error handling
- [ ] Performance implications
- [ ] Security considerations
- [ ] API design
- [ ] Test coverage

---

**For Reviewers:**

- [ ] Code review completed
- [ ] Tests verified
- [ ] Documentation reviewed
- [ ] Security considerations checked
- [ ] Performance impact assessed
</file>

<file path="cmd/config_integration_test.go">
package cmd

import (
	"context"
	"testing"

	"github.com/spf13/cobra"
	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/require"

	"hardcover-cli/internal/config"
)

func TestWithConfig_AddsConfigurationToContext(t *testing.T) {
	// Test that withConfig properly adds configuration to context
	ctx := context.Background()
	cfg := &config.Config{
		APIKey:  "test-api-key",
		BaseURL: "https://test.example.com/graphql",
	}

	newCtx := withConfig(ctx, cfg)

	// Verify configuration can be retrieved
	retrievedCfg, ok := getConfig(newCtx)
	require.True(t, ok, "Configuration should be retrievable from context")
	assert.Equal(t, cfg.APIKey, retrievedCfg.APIKey)
	assert.Equal(t, cfg.BaseURL, retrievedCfg.BaseURL)
}

func TestGetConfig_RetrievesConfigurationFromContext(t *testing.T) {
	// Test that getConfig properly retrieves configuration from context
	ctx := context.Background()
	cfg := &config.Config{
		APIKey:  "test-api-key",
		BaseURL: "https://test.example.com/graphql",
	}

	ctxWithConfig := withConfig(ctx, cfg)

	// Test successful retrieval
	retrievedCfg, ok := getConfig(ctxWithConfig)
	require.True(t, ok, "Should successfully retrieve configuration")
	assert.Equal(t, cfg.APIKey, retrievedCfg.APIKey)
	assert.Equal(t, cfg.BaseURL, retrievedCfg.BaseURL)

	// Test retrieval from context without configuration
	emptyCtx := context.Background()
	_, ok = getConfig(emptyCtx)
	assert.False(t, ok, "Should return false when no configuration in context")
}

func TestGetConfig_ReturnsNilWhenNoConfiguration(t *testing.T) {
	// Test that getConfig returns nil when no configuration is in context
	ctx := context.Background()

	cfg, ok := getConfig(ctx)
	assert.False(t, ok, "Should return false when no configuration in context")
	assert.Nil(t, cfg, "Should return nil configuration when not found")
}

func TestSetupCommands_RegistersAllCommands(t *testing.T) {
	// Test that SetupCommands properly registers all commands
	// This ensures the command structure is set up correctly

	// Create a fresh root command for testing
	testRootCmd := &cobra.Command{Use: "test"}

	// Store original and restore after test
	originalRootCmd := rootCmd
	rootCmd = testRootCmd
	defer func() { rootCmd = originalRootCmd }()

	// Setup commands
	SetupCommands()

	// Verify that commands are registered
	expectedCommands := []string{"me", "search", "book", "config"}
	for _, expectedCmd := range expectedCommands {
		found := false
		for _, cmd := range testRootCmd.Commands() {
			if cmd.Use == expectedCmd {
				found = true
				break
			}
		}
		assert.True(t, found, "Command %s should be registered", expectedCmd)
	}
}

func TestSetupRootCommand_ConfiguresFlagsAndInitialization(t *testing.T) {
	// Test that setupRootCommand properly configures flags and initialization

	// Create a fresh root command for testing
	testRootCmd := &cobra.Command{Use: "test"}

	// Store original and restore after test
	originalRootCmd := rootCmd
	rootCmd = testRootCmd
	defer func() { rootCmd = originalRootCmd }()

	// Setup root command
	setupRootCommand()

	// Verify that persistent flags are configured
	configFlag := testRootCmd.PersistentFlags().Lookup("config")
	assert.NotNil(t, configFlag, "config flag should be configured")

	apiKeyFlag := testRootCmd.PersistentFlags().Lookup("api-key")
	assert.NotNil(t, apiKeyFlag, "api-key flag should be configured")

	// Verify that local flags are configured
	toggleFlag := testRootCmd.Flags().Lookup("toggle")
	assert.NotNil(t, toggleFlag, "toggle flag should be configured")
}
</file>

<file path="cmd/root_test.go">
package cmd

import (
	"context"
	"testing"

	"github.com/spf13/cobra"
	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/require"
)

func TestExecute_LoadsConfiguration(t *testing.T) {
	// This test verifies that the Execute function properly loads configuration
	// and sets it in the context before executing commands

	// We can't easily test the full Execute function since it calls os.Exit,
	// but we can test the configuration loading logic separately
}

func TestInitConfig_LoadsConfiguration(t *testing.T) {
	// Test that initConfig properly loads configuration and sets context
	// This is a unit test for the initConfig function

	// Create a test command to work with
	testCmd := &cobra.Command{}
	testCmd.SetContext(context.Background())

	// Set up flags
	testCmd.PersistentFlags().String("api-key", "", "test flag")

	// Mock the root command for testing
	originalRootCmd := rootCmd
	rootCmd = testCmd
	defer func() { rootCmd = originalRootCmd }()

	// Call initConfig
	initConfig()

	// Verify that context was set
	cfg, ok := getConfig(testCmd.Context())
	require.True(t, ok, "Configuration should be set in context")
	assert.NotNil(t, cfg, "Configuration should not be nil")
	assert.Equal(t, "https://api.hardcover.app/v1/graphql", cfg.BaseURL)
}
</file>

<file path="internal/client/generated.go">
// Code generated by github.com/Khan/genqlient, DO NOT EDIT.

package client

import (
	"context"

	"github.com/Khan/genqlient/graphql"
)

// GetBookBooks_by_pkBooks includes the requested fields of the GraphQL type books.
// The GraphQL type's documentation follows.
//
// columns and relationships of "books"
type GetBookBooks_by_pkBooks struct {
	Id                  int     `json:"id"`
	Title               string  `json:"title"`
	Description         string  `json:"description"`
	Slug                string  `json:"slug"`
	Pages               int     `json:"pages"`
	Rating              float64 `json:"rating"`
	Ratings_count       int     `json:"ratings_count"`
	Release_year        int     `json:"release_year"`
	Release_date        string  `json:"release_date"`
	Subtitle            string  `json:"subtitle"`
	Created_at          string  `json:"created_at"`
	Updated_at          string  `json:"updated_at"`
	Cached_contributors string  `json:"cached_contributors"`
	Cached_tags         string  `json:"cached_tags"`
	Cached_image        string  `json:"cached_image"`
}

// GetId returns GetBookBooks_by_pkBooks.Id, and is useful for accessing the field via an interface.
func (v *GetBookBooks_by_pkBooks) GetId() int { return v.Id }

// GetTitle returns GetBookBooks_by_pkBooks.Title, and is useful for accessing the field via an interface.
func (v *GetBookBooks_by_pkBooks) GetTitle() string { return v.Title }

// GetDescription returns GetBookBooks_by_pkBooks.Description, and is useful for accessing the field via an interface.
func (v *GetBookBooks_by_pkBooks) GetDescription() string { return v.Description }

// GetSlug returns GetBookBooks_by_pkBooks.Slug, and is useful for accessing the field via an interface.
func (v *GetBookBooks_by_pkBooks) GetSlug() string { return v.Slug }

// GetPages returns GetBookBooks_by_pkBooks.Pages, and is useful for accessing the field via an interface.
func (v *GetBookBooks_by_pkBooks) GetPages() int { return v.Pages }

// GetRating returns GetBookBooks_by_pkBooks.Rating, and is useful for accessing the field via an interface.
func (v *GetBookBooks_by_pkBooks) GetRating() float64 { return v.Rating }

// GetRatings_count returns GetBookBooks_by_pkBooks.Ratings_count, and is useful for accessing the field via an interface.
func (v *GetBookBooks_by_pkBooks) GetRatings_count() int { return v.Ratings_count }

// GetRelease_year returns GetBookBooks_by_pkBooks.Release_year, and is useful for accessing the field via an interface.
func (v *GetBookBooks_by_pkBooks) GetRelease_year() int { return v.Release_year }

// GetRelease_date returns GetBookBooks_by_pkBooks.Release_date, and is useful for accessing the field via an interface.
func (v *GetBookBooks_by_pkBooks) GetRelease_date() string { return v.Release_date }

// GetSubtitle returns GetBookBooks_by_pkBooks.Subtitle, and is useful for accessing the field via an interface.
func (v *GetBookBooks_by_pkBooks) GetSubtitle() string { return v.Subtitle }

// GetCreated_at returns GetBookBooks_by_pkBooks.Created_at, and is useful for accessing the field via an interface.
func (v *GetBookBooks_by_pkBooks) GetCreated_at() string { return v.Created_at }

// GetUpdated_at returns GetBookBooks_by_pkBooks.Updated_at, and is useful for accessing the field via an interface.
func (v *GetBookBooks_by_pkBooks) GetUpdated_at() string { return v.Updated_at }

// GetCached_contributors returns GetBookBooks_by_pkBooks.Cached_contributors, and is useful for accessing the field via an interface.
func (v *GetBookBooks_by_pkBooks) GetCached_contributors() string { return v.Cached_contributors }

// GetCached_tags returns GetBookBooks_by_pkBooks.Cached_tags, and is useful for accessing the field via an interface.
func (v *GetBookBooks_by_pkBooks) GetCached_tags() string { return v.Cached_tags }

// GetCached_image returns GetBookBooks_by_pkBooks.Cached_image, and is useful for accessing the field via an interface.
func (v *GetBookBooks_by_pkBooks) GetCached_image() string { return v.Cached_image }

// GetBookResponse is returned by GetBook on success.
type GetBookResponse struct {
	Books_by_pk GetBookBooks_by_pkBooks `json:"books_by_pk"`
}

// GetBooks_by_pk returns GetBookResponse.Books_by_pk, and is useful for accessing the field via an interface.
func (v *GetBookResponse) GetBooks_by_pk() GetBookBooks_by_pkBooks { return v.Books_by_pk }

// GetBooksBooks includes the requested fields of the GraphQL type books.
// The GraphQL type's documentation follows.
//
// columns and relationships of "books"
type GetBooksBooks struct {
	Id            int     `json:"id"`
	Title         string  `json:"title"`
	Description   string  `json:"description"`
	Slug          string  `json:"slug"`
	Pages         int     `json:"pages"`
	Rating        float64 `json:"rating"`
	Ratings_count int     `json:"ratings_count"`
	Release_year  int     `json:"release_year"`
	Created_at    string  `json:"created_at"`
	Updated_at    string  `json:"updated_at"`
}

// GetId returns GetBooksBooks.Id, and is useful for accessing the field via an interface.
func (v *GetBooksBooks) GetId() int { return v.Id }

// GetTitle returns GetBooksBooks.Title, and is useful for accessing the field via an interface.
func (v *GetBooksBooks) GetTitle() string { return v.Title }

// GetDescription returns GetBooksBooks.Description, and is useful for accessing the field via an interface.
func (v *GetBooksBooks) GetDescription() string { return v.Description }

// GetSlug returns GetBooksBooks.Slug, and is useful for accessing the field via an interface.
func (v *GetBooksBooks) GetSlug() string { return v.Slug }

// GetPages returns GetBooksBooks.Pages, and is useful for accessing the field via an interface.
func (v *GetBooksBooks) GetPages() int { return v.Pages }

// GetRating returns GetBooksBooks.Rating, and is useful for accessing the field via an interface.
func (v *GetBooksBooks) GetRating() float64 { return v.Rating }

// GetRatings_count returns GetBooksBooks.Ratings_count, and is useful for accessing the field via an interface.
func (v *GetBooksBooks) GetRatings_count() int { return v.Ratings_count }

// GetRelease_year returns GetBooksBooks.Release_year, and is useful for accessing the field via an interface.
func (v *GetBooksBooks) GetRelease_year() int { return v.Release_year }

// GetCreated_at returns GetBooksBooks.Created_at, and is useful for accessing the field via an interface.
func (v *GetBooksBooks) GetCreated_at() string { return v.Created_at }

// GetUpdated_at returns GetBooksBooks.Updated_at, and is useful for accessing the field via an interface.
func (v *GetBooksBooks) GetUpdated_at() string { return v.Updated_at }

// GetBooksResponse is returned by GetBooks on success.
type GetBooksResponse struct {
	Books []GetBooksBooks `json:"books"`
}

// GetBooks returns GetBooksResponse.Books, and is useful for accessing the field via an interface.
func (v *GetBooksResponse) GetBooks() []GetBooksBooks { return v.Books }

// GetCurrentUserMeUsers includes the requested fields of the GraphQL type users.
// The GraphQL type's documentation follows.
//
// columns and relationships of "users"
type GetCurrentUserMeUsers struct {
	Id         int    `json:"id"`
	Username   string `json:"username"`
	Email      string `json:"email"`
	Created_at string `json:"created_at"`
	Updated_at string `json:"updated_at"`
}

// GetId returns GetCurrentUserMeUsers.Id, and is useful for accessing the field via an interface.
func (v *GetCurrentUserMeUsers) GetId() int { return v.Id }

// GetUsername returns GetCurrentUserMeUsers.Username, and is useful for accessing the field via an interface.
func (v *GetCurrentUserMeUsers) GetUsername() string { return v.Username }

// GetEmail returns GetCurrentUserMeUsers.Email, and is useful for accessing the field via an interface.
func (v *GetCurrentUserMeUsers) GetEmail() string { return v.Email }

// GetCreated_at returns GetCurrentUserMeUsers.Created_at, and is useful for accessing the field via an interface.
func (v *GetCurrentUserMeUsers) GetCreated_at() string { return v.Created_at }

// GetUpdated_at returns GetCurrentUserMeUsers.Updated_at, and is useful for accessing the field via an interface.
func (v *GetCurrentUserMeUsers) GetUpdated_at() string { return v.Updated_at }

// GetCurrentUserResponse is returned by GetCurrentUser on success.
type GetCurrentUserResponse struct {
	Me []GetCurrentUserMeUsers `json:"me"`
}

// GetMe returns GetCurrentUserResponse.Me, and is useful for accessing the field via an interface.
func (v *GetCurrentUserResponse) GetMe() []GetCurrentUserMeUsers { return v.Me }

// SearchBooksResponse is returned by SearchBooks on success.
type SearchBooksResponse struct {
	Search SearchBooksSearchSearchOutput `json:"search"`
}

// GetSearch returns SearchBooksResponse.Search, and is useful for accessing the field via an interface.
func (v *SearchBooksResponse) GetSearch() SearchBooksSearchSearchOutput { return v.Search }

// SearchBooksSearchSearchOutput includes the requested fields of the GraphQL type SearchOutput.
type SearchBooksSearchSearchOutput struct {
	Error      string `json:"error"`
	Ids        []int  `json:"ids"`
	Page       int    `json:"page"`
	Per_page   int    `json:"per_page"`
	Query      string `json:"query"`
	Query_type string `json:"query_type"`
	Results    string `json:"results"`
}

// GetError returns SearchBooksSearchSearchOutput.Error, and is useful for accessing the field via an interface.
func (v *SearchBooksSearchSearchOutput) GetError() string { return v.Error }

// GetIds returns SearchBooksSearchSearchOutput.Ids, and is useful for accessing the field via an interface.
func (v *SearchBooksSearchSearchOutput) GetIds() []int { return v.Ids }

// GetPage returns SearchBooksSearchSearchOutput.Page, and is useful for accessing the field via an interface.
func (v *SearchBooksSearchSearchOutput) GetPage() int { return v.Page }

// GetPer_page returns SearchBooksSearchSearchOutput.Per_page, and is useful for accessing the field via an interface.
func (v *SearchBooksSearchSearchOutput) GetPer_page() int { return v.Per_page }

// GetQuery returns SearchBooksSearchSearchOutput.Query, and is useful for accessing the field via an interface.
func (v *SearchBooksSearchSearchOutput) GetQuery() string { return v.Query }

// GetQuery_type returns SearchBooksSearchSearchOutput.Query_type, and is useful for accessing the field via an interface.
func (v *SearchBooksSearchSearchOutput) GetQuery_type() string { return v.Query_type }

// GetResults returns SearchBooksSearchSearchOutput.Results, and is useful for accessing the field via an interface.
func (v *SearchBooksSearchSearchOutput) GetResults() string { return v.Results }

// __GetBookInput is used internally by genqlient
type __GetBookInput struct {
	Id int `json:"id"`
}

// GetId returns __GetBookInput.Id, and is useful for accessing the field via an interface.
func (v *__GetBookInput) GetId() int { return v.Id }

// __SearchBooksInput is used internally by genqlient
type __SearchBooksInput struct {
	Query      string `json:"query"`
	Query_type string `json:"query_type"`
	Per_page   int    `json:"per_page"`
	Page       int    `json:"page"`
}

// GetQuery returns __SearchBooksInput.Query, and is useful for accessing the field via an interface.
func (v *__SearchBooksInput) GetQuery() string { return v.Query }

// GetQuery_type returns __SearchBooksInput.Query_type, and is useful for accessing the field via an interface.
func (v *__SearchBooksInput) GetQuery_type() string { return v.Query_type }

// GetPer_page returns __SearchBooksInput.Per_page, and is useful for accessing the field via an interface.
func (v *__SearchBooksInput) GetPer_page() int { return v.Per_page }

// GetPage returns __SearchBooksInput.Page, and is useful for accessing the field via an interface.
func (v *__SearchBooksInput) GetPage() int { return v.Page }

// The query executed by GetBook.
const GetBook_Operation = `
query GetBook ($id: Int!) {
	books_by_pk(id: $id) {
		id
		title
		description
		slug
		pages
		rating
		ratings_count
		release_year
		release_date
		subtitle
		created_at
		updated_at
		cached_contributors
		cached_tags
		cached_image
	}
}
`

func GetBook(
	ctx_ context.Context,
	client_ graphql.Client,
	id int,
) (data_ *GetBookResponse, err_ error) {
	req_ := &graphql.Request{
		OpName: "GetBook",
		Query:  GetBook_Operation,
		Variables: &__GetBookInput{
			Id: id,
		},
	}

	data_ = &GetBookResponse{}
	resp_ := &graphql.Response{Data: data_}

	err_ = client_.MakeRequest(
		ctx_,
		req_,
		resp_,
	)

	return data_, err_
}

// The query executed by GetBooks.
const GetBooks_Operation = `
query GetBooks {
	books {
		id
		title
		description
		slug
		pages
		rating
		ratings_count
		release_year
		created_at
		updated_at
	}
}
`

func GetBooks(
	ctx_ context.Context,
	client_ graphql.Client,
) (data_ *GetBooksResponse, err_ error) {
	req_ := &graphql.Request{
		OpName: "GetBooks",
		Query:  GetBooks_Operation,
	}

	data_ = &GetBooksResponse{}
	resp_ := &graphql.Response{Data: data_}

	err_ = client_.MakeRequest(
		ctx_,
		req_,
		resp_,
	)

	return data_, err_
}

// The query executed by GetCurrentUser.
const GetCurrentUser_Operation = `
query GetCurrentUser {
	me {
		id
		username
		email
		created_at
		updated_at
	}
}
`

func GetCurrentUser(
	ctx_ context.Context,
	client_ graphql.Client,
) (data_ *GetCurrentUserResponse, err_ error) {
	req_ := &graphql.Request{
		OpName: "GetCurrentUser",
		Query:  GetCurrentUser_Operation,
	}

	data_ = &GetCurrentUserResponse{}
	resp_ := &graphql.Response{Data: data_}

	err_ = client_.MakeRequest(
		ctx_,
		req_,
		resp_,
	)

	return data_, err_
}

// The query executed by SearchBooks.
const SearchBooks_Operation = `
query SearchBooks ($query: String!, $query_type: String = "Book", $per_page: Int = 10, $page: Int = 1) {
	search(query: $query, query_type: $query_type, per_page: $per_page, page: $page) {
		error
		ids
		page
		per_page
		query
		query_type
		results
	}
}
`

func SearchBooks(
	ctx_ context.Context,
	client_ graphql.Client,
	query string,
	query_type string,
	per_page int,
	page int,
) (data_ *SearchBooksResponse, err_ error) {
	req_ := &graphql.Request{
		OpName: "SearchBooks",
		Query:  SearchBooks_Operation,
		Variables: &__SearchBooksInput{
			Query:      query,
			Query_type: query_type,
			Per_page:   per_page,
			Page:       page,
		},
	}

	data_ = &SearchBooksResponse{}
	resp_ := &graphql.Response{Data: data_}

	err_ = client_.MakeRequest(
		ctx_,
		req_,
		resp_,
	)

	return data_, err_
}
</file>

<file path="internal/client/queries.graphql">
query GetCurrentUser {
  me {
    id
    username
    email
    created_at
    updated_at
  }
}

query SearchBooks($query: String!, $query_type: String = "Book", $per_page: Int = 10, $page: Int = 1) {
  search(query: $query, query_type: $query_type, per_page: $per_page, page: $page) {
    error
    ids
    page
    per_page
    query
    query_type
    results
  }
}

query GetBook($id: Int!) {
  books_by_pk(id: $id) {
    id
    title
    description
    slug
    pages
    rating
    ratings_count
    release_year
    release_date
    subtitle
    created_at
    updated_at
    cached_contributors
    cached_tags
    cached_image
  }
}

query GetBooks {
  books {
    id
    title
    description
    slug
    pages
    rating
    ratings_count
    release_year
    created_at
    updated_at
  }
}
</file>

<file path="DEVELOPMENT.md">
# Hardcover CLI Development Summary

## Project Overview

This project implements a comprehensive GoLang command-line interface (CLI) application for interacting with the Hardcover.app GraphQL API. The application is built using industry best practices and includes extensive testing and documentation.

## Architecture & Design

### Core Components

1. **CLI Framework**: Built using the Cobra library for robust command-line interface management
2. **GraphQL Client**: Custom HTTP client with type-safe GraphQL query execution
3. **Configuration Management**: Flexible configuration system supporting both file and environment variable sources
4. **Comprehensive Testing**: Unit tests with mocking and high coverage using testify

### Directory Structure

```
hardcover-cli/
├── cmd/                    # CLI command implementations
│   ├── root.go            # Root command and initialization
│   ├── me.go              # User profile command
│   ├── search.go          # Book search functionality
│   ├── book.go            # Book details retrieval
│   ├── config.go          # Configuration management commands
│   ├── context.go         # Context utilities for config passing
│   └── *_test.go          # Comprehensive unit tests
├── internal/
│   ├── client/            # GraphQL client implementation
│   │   ├── client.go      # HTTP client wrapper
│   │   ├── schema.graphql # GraphQL schema definition
│   │   ├── queries.graphql # GraphQL queries
│   │   └── genqlient.yaml # genqlient configuration
│   └── config/            # Configuration management
│       ├── config.go      # Configuration logic
│       └── config_test.go # Configuration tests
├── main.go                # Application entry point
├── go.mod                 # Go module definition
├── README.md             # User documentation
└── DEVELOPMENT.md        # This file
```

## Implementation Details

### Commands Implemented

#### 1. `hardcover me`
- Fetches authenticated user profile information
- Displays user ID, username, email, and timestamps
- Includes comprehensive error handling and validation

#### 2. `hardcover search books <query>`
- Searches for books using GraphQL API
- Supports filtering by title, author, and other criteria
- Displays formatted results with book details, ratings, and genres
- Includes pagination support and result counting

#### 3. `hardcover book get <book_id>`
- Retrieves detailed information for a specific book
- Shows comprehensive book metadata including:
  - Title, description, and publication details
  - Author and contributor information
  - Genre classification
  - Ratings and review statistics
  - Cover image and external URLs

#### 4. `hardcover config` subcommands
- `set-api-key`: Store API key securely
- `get-api-key`: Display current API key (masked for security)
- `show-path`: Show configuration file location

### GraphQL Integration

The application uses a well-defined GraphQL schema with the following key queries:

```graphql
# User profile retrieval
query GetCurrentUser {
  me {
    id
    username
    email
    createdAt
    updatedAt
  }
}

# Book search functionality
query SearchBooks($query: String!) {
  search(query: $query, type: BOOKS) {
    ... on BookSearchResults {
      totalCount
      results {
        ... on Book {
          id
          title
          slug
          cached_contributors { name role }
          cached_genres { name }
          averageRating
          ratingsCount
        }
      }
    }
  }
}

# Book details retrieval
query GetBook($id: ID!) {
  book(id: $id) {
    id
    title
    description
    # ... additional fields
  }
}
```

### Configuration System

The application implements a flexible configuration system:

1. **Environment Variables**: `HARDCOVER_API_KEY`
2. **Configuration File**: `~/.hardcover/config.yaml`
3. **Command-line Flags**: `--api-key` for one-time overrides

Configuration precedence: Command-line flags > Environment variables > Configuration file

### Testing Strategy

The project includes comprehensive unit tests with:

- **Package Coverage**: All major packages have dedicated test files
- **Mocking**: HTTP server mocking for API interactions
- **Error Scenarios**: Testing of failure cases and edge conditions
- **Integration Tests**: Command registration and interaction testing
- **Configuration Tests**: File system mocking and environment variable testing

### Test Files Overview

- `internal/config/config_test.go`: Configuration management tests
- `internal/client/client_test.go`: GraphQL client tests
- `cmd/me_test.go`: User profile command tests
- `cmd/search_test.go`: Book search command tests
- `cmd/book_test.go`: Book retrieval command tests
- `cmd/config_test.go`: Configuration command tests

### Error Handling

The application implements comprehensive error handling:

- **API Errors**: GraphQL error parsing and user-friendly messages
- **Network Errors**: Connection failure handling and timeouts
- **Configuration Errors**: Missing API keys and invalid configurations
- **Validation Errors**: Input validation and argument checking

### Security Considerations

1. **API Key Storage**: Secure file permissions (0600) for configuration files
2. **API Key Display**: Masking of sensitive information in output
3. **HTTP Headers**: Proper authentication header handling
4. **Input Validation**: Sanitization of user inputs

## Dependencies

- **github.com/spf13/cobra**: CLI framework
- **github.com/stretchr/testify**: Testing framework with assertions and mocks
- **gopkg.in/yaml.v3**: YAML configuration file parsing

## Future Enhancements

1. **genqlient Integration**: Complete the type-safe GraphQL client generation
2. **Additional Commands**: Support for more Hardcover.app API endpoints
3. **Output Formats**: JSON and CSV output options
4. **Batch Operations**: Support for bulk operations
5. **Interactive Mode**: TUI for enhanced user experience
6. **Configuration Profiles**: Support for multiple API configurations

## Build and Deployment

### Local Development

```bash
# Clone the repository
git clone <repository-url>
cd hardcover-cli

# Install dependencies
go mod tidy

# Build the application
go build -o hardcover .

# Run tests
go test ./...

# Run with coverage
go test ./... -cover
```

### Production Deployment

```bash
# Build for production
go build -ldflags="-s -w" -o hardcover .

# Cross-compilation examples
GOOS=linux GOARCH=amd64 go build -o hardcover-linux .
GOOS=windows GOARCH=amd64 go build -o hardcover-windows.exe .
GOOS=darwin GOARCH=amd64 go build -o hardcover-macos .
```

## Code Quality

The project follows Go best practices:

- **Package Structure**: Clear separation of concerns
- **Error Handling**: Comprehensive error checking and reporting
- **Documentation**: Extensive inline documentation and help text
- **Testing**: High test coverage with meaningful test cases
- **Code Style**: Consistent formatting and naming conventions

## API Integration

The application integrates with the Hardcover.app GraphQL API:

- **Endpoint**: `https://api.hardcover.app/v1/graphql`
- **Authentication**: Bearer token authentication
- **Rate Limiting**: Respectful API usage with appropriate timeouts
- **Error Handling**: Proper GraphQL error parsing and user feedback

## Performance Considerations

1. **HTTP Client**: Reusable HTTP client with connection pooling
2. **Timeouts**: Configurable request timeouts (30 seconds default)
3. **Memory Usage**: Efficient JSON parsing and minimal memory footprint
4. **Concurrent Safety**: Thread-safe configuration and client usage

## Conclusion

This Hardcover CLI application demonstrates a professional-grade Go application with:

- Clean architecture and separation of concerns
- Comprehensive testing and error handling
- User-friendly CLI interface with extensive help documentation
- Secure configuration management
- Extensible design for future enhancements

The project serves as an excellent example of modern Go development practices and can be easily extended to support additional Hardcover.app API functionality.
</file>

<file path="GRAPHQL.md">
# GraphQL Code Generation

This document describes the Make tasks available for managing GraphQL schema and code generation in the hardcover-cli project.

## Overview

The project uses [genqlient](https://github.com/Khan/genqlient) to generate type-safe Go code from GraphQL schemas and queries. This ensures that your Go code is always in sync with the GraphQL API schema.

## Make Tasks

### `make graphql-info`
Shows information about the current GraphQL configuration:
- Schema file location
- Configuration file location
- Generated code file location
- Current GraphQL endpoint
- List of available types in the schema

### `make graphql-generate`
Generates Go code from the current GraphQL schema and queries:
- Ensures all dependencies are installed
- Runs genqlient to generate type-safe Go code
- Updates `internal/client/generated.go`

### `make graphql-fetch`
Fetches the latest GraphQL schema from a remote endpoint:
- Downloads the schema using GraphQL introspection
- Converts the introspection result to GraphQL SDL format
- Updates `internal/client/schema.graphql`

**Usage:**
```bash
# Using the default endpoint
make graphql-fetch

# Using a custom endpoint
make graphql-fetch GRAPHQL_ENDPOINT=https://your-api.com/graphql

# With authentication (if required)
make graphql-fetch GRAPHQL_ENDPOINT=https://your-api.com/graphql
```

**Requirements:**
- The GraphQL endpoint must support introspection queries
- If authentication is required, you may need to modify the curl command in the Makefile
- `jq` is recommended for JSON processing (optional)
- `go` command must be available

### `make graphql-update`
Complete workflow that fetches the latest schema and regenerates code:
- Runs `graphql-fetch` to get the latest schema
- Runs `graphql-generate` to create updated Go code

## Configuration

### GraphQL Endpoint
The default GraphQL endpoint is set in the Makefile:
```makefile
GRAPHQL_ENDPOINT ?= https://api.hardcover.app/v1/graphql
```

You can override this by setting the environment variable or passing it as a parameter to the make commands.

### Files
- **Schema**: `internal/client/schema.graphql` - GraphQL schema definition
- **Queries**: `internal/client/queries.graphql` - GraphQL queries used by the CLI
- **Config**: `internal/client/genqlient.yaml` - genqlient configuration
- **Generated**: `internal/client/generated.go` - Generated Go code (do not edit manually)

## Workflow

### Development Workflow
1. Make changes to `internal/client/queries.graphql` if you need new queries
2. Run `make graphql-generate` to regenerate the Go code
3. Update your Go code to use the new generated types
4. Test your changes

### Schema Update Workflow
1. Run `make graphql-update` to fetch the latest schema and regenerate code
2. Review the changes in `internal/client/generated.go`
3. Update your Go code if the API has changed
4. Test your changes

### Adding New Queries
1. Add your GraphQL query to `internal/client/queries.graphql`
2. Run `make graphql-generate` to generate the corresponding Go types
3. Use the generated types in your Go code

## Troubleshooting

### Schema Fetch Issues
If `make graphql-fetch` fails:
1. Check that the endpoint URL is correct
2. Verify the endpoint is accessible
3. Ensure the endpoint supports introspection queries
4. Check if authentication is required

### Code Generation Issues
If `make graphql-generate` fails:
1. Run `go mod tidy` to ensure dependencies are up to date
2. Check that the schema file is valid GraphQL
3. Verify that queries reference valid schema types

### Authentication
If the GraphQL endpoint requires authentication, you'll need to modify the `graphql-fetch` task in the Makefile to include the appropriate headers:

```makefile
@curl -s -H "Content-Type: application/json" \
     -H "Authorization: Bearer YOUR_TOKEN" \
     -d '{"query":"..."}' \
     $(GRAPHQL_ENDPOINT) > /tmp/schema_response.json
```

## Examples

### Fetch schema from a different endpoint
```bash
make graphql-fetch GRAPHQL_ENDPOINT=https://staging-api.hardcover.app/v1/graphql
```

### Generate code only (without fetching schema)
```bash
make graphql-generate
```

### Complete update workflow
```bash
make graphql-update
```

### Check current configuration
```bash
make graphql-info
```
</file>

<file path="LICENSE">
MIT License

Copyright (c) 2025 Peter Souter

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
</file>

<file path="internal/client/genqlient.yaml">
# Local schema file (for development/offline use)
schema: schema.graphql

# Remote schema endpoint (for production/updates)
# schema: https://api.hardcover.app/v1/graphql

operations:
  - queries.graphql
generated: generated.go

# Bindings for custom scalars
bindings:
  citext:
    type: string
  timestamptz:
    type: string
  jsonb:
    type: string
  numeric:
    type: float64
  timestamp:
    type: string
  date:
    type: string
  json:
    type: string
</file>

<file path="internal/client/schema.graphql">
# Generated GraphQL Schema from Introspection

type AuthorIdType {
  author: authors
  errors: [String]
  id: Int
}

input AuthorInputType {
  alias_id: Int
  bio: String
  born_date: date
  born_year: Int
  death_date: date
  death_year: Int
  gender_id: Int
  id: Int
  image_id: Int
  is_bipoc: Boolean
  is_lgbtq: Boolean
  location: String
  locked: Boolean
  name: String
  name_personal: String
  slug: String
}

input BasicTag {
  category: String!
  spoiler: Boolean!
  tag: String!
}

type BasicTagType {
  category: String!
  categorySlug: String!
  count: Int
  spoiler: Boolean!
  tag: String!
  tagSlug: String!
}

input BookDtoInput {
  asin: String
  audio_seconds: Int
  contributions: [ContributionInputType]
  country_id: Int
  edition_format: String
  edition_information: String
  image_id: Int
  isbn_10: String
  isbn_13: String
  language_id: Int
  page_count: Int
  publisher_id: Int
  reading_format_id: Int
  release_date: date
  subtitle: String
  title: String
}

input BookDtoType {
  book_category_id: Int
  characters: [CharacterDtoInput]
  collection_book_ids: [Int]
  compilation: Boolean
  description: String
  headline: String
  librarian_tags: [TagsDtoInput]
  literary_type_id: Int
  series: [BookSeriesDtoInput]
  title: String
}

type BookIdType {
  book: books
  errors: [String]
  id: Int
}

input BookInput {
  book_status_id: Int
  canonical_id: Int
  default_audio_edition_id: Int
  default_cover_edition_id: Int
  default_ebook_edition_id: Int
  default_physical_edition_id: Int
  dto: BookDtoType
  locked: Boolean
  slug: String
  user_added: Boolean
}

type BookMappingIdType {
  book_mapping: book_mappings
  errors: [String]
  id: Int
}

input BookMappingInput {
  edition_id: Int!
  external_id: String!
  platform_id: Int!
}

input BookSeriesDtoInput {
  collection_book_ids: [Int]
  compilation: Boolean
  details: String
  featured: Boolean
  name: String
  position: numeric
  series_id: Int!
}

scalar Boolean

"""
Boolean expression to compare columns of type "Boolean". All fields are combined with logical 'AND'.
"""
input Boolean_comparison_exp {
  _eq: Boolean
  _gt: Boolean
  _gte: Boolean
  _in: [Boolean!]
  _is_null: Boolean
  _lt: Boolean
  _lte: Boolean
  _neq: Boolean
  _nin: [Boolean!]
}

input CharacterDtoInput {
  character_id: Int!
  position: Int!
  spoiler: Boolean!
}

type CharacterIdType {
  character: characters
  errors: [String]
  id: Int
}

input CharacterInput {
  biography: String
  gender_id: Int
  has_disability: Boolean
  image_id: Int
  is_lgbtq: Boolean
  is_poc: Boolean
  locked: Boolean
  name: String
  slug: String
  state: String
}

type CollectionImportIdType {
  collection_import: collection_imports
  id: Int
}

input CollectionImportInput {
  contents_key: String!
  override_date_read: Boolean!
  override_ratings: Boolean!
  override_shelves: Boolean!
  platform_id: Int!
  tag_resolution: Int!
  user_id: Int!
}

type CollectionImportResultIdType {
  collection_import_result: collection_import_results
  id: Int
}

input ContributionInputType {
  author_id: Int!
  contribution: String
}

input CreateBookFromPlatformInput {
  book_id: Int
  external_id: String!
  platform_id: Int!
}

input CreatePromptInput {
  description: String!
  privacy_setting_id: Int!
  question: String!
}

input DatesReadInput {
  action: String
  edition_id: Int
  finished_at: date
  id: Int
  progress_pages: Int
  progress_seconds: Int
  reading_format_id: Int
  started_at: date
}

type DeleteFollowedPromptType {
  success: Boolean!
}

type DeleteListType {
  success: Boolean!
}

type DeleteReadingJournalOutput {
  id: Int!
}

type DeleteReadingJournalsOutput {
  ids: [Int]
}

input DtoTag {
  spoiler: Boolean!
  tag: String!
  tagSlug: String!
}

type EditionIdType {
  edition: editions
  errors: [String]
  id: Int
}

input EditionInput {
  book_id: Int
  dto: BookDtoInput
  locked: Boolean
}

scalar Float

type FollowedListType {
  errors: [String]
  followed_list: followed_lists
  id: Int
}

type FollowedPromptType {
  errors: [String]
  followed_prompt: followed_prompts
  id: Int
}

type FollowedUserType {
  error: String
  followed_user: users
  followed_user_id: Int
  followed_users: followed_users
  id: Int
  user: users
  user_id: Int
}

input GoalConditionInput {
  authorBipoc: Int
  authorGenderIds: [Int]
  authorLgbtqia: Int
  bookCategoryIds: [Int]
  readingFormatId: Int
}

type GoalIdType {
  errors: [String]
  goal: goals
  id: Int
}

input GoalInput {
  archived: Boolean
  conditions: GoalConditionInput!
  description: String!
  end_date: date!
  goal: Int!
  metric: String!
  privacy_setting_id: Int
  start_date: date!
}

type ImageIdType {
  id: Int!
  image: images
}

input ImageInput {
  imageable_id: Int!
  imageable_type: String!
  url: String!
}

type InsertBlockOutput {
  error: String
  id: Int
  user_block: user_blocks
}

scalar Int

"""
Boolean expression to compare columns of type "Int". All fields are combined with logical 'AND'.
"""
input Int_comparison_exp {
  _eq: Int
  _gt: Int
  _gte: Int
  _in: [Int!]
  _is_null: Boolean
  _lt: Int
  _lte: Int
  _neq: Int
  _nin: [Int!]
}

type LikeDeleteType {
  likes_count: Int!
}

type LikeType {
  id: Int!
  like: likes
  likes_count: Int!
}

type ListBookDeleteType {
  id: Int
  list: lists
  list_id: Int
}

type ListBookIdType {
  id: Int
  list_book: list_books
}

input ListBookInput {
  book_id: Int!
  edition_id: Int
  list_id: Int!
  position: Int
}

type ListDeleteType {
  success: Boolean!
}

type ListIdType {
  errors: [String]
  id: Int
  list: lists
}

input ListInput {
  default_view: String
  description: String
  featured_profile: Boolean
  name: String
  privacy_setting_id: Int
  ranked: Boolean
  url: String
}

type NewBookIdType {
  book: books
  edition: editions
  edition_id: Int
  errors: [String]
  id: Int
}

type NewsletterStatusType {
  subscribed: Boolean!
}

type OptionalEditionIdType {
  edition: editions
  errors: [String]
  id: Int
}

input PromptAnswerCreateInput {
  book_id: Int!
  description: String
  prompt_id: Int!
}

type PromptAnswerIdType {
  book_id: Int!
  id: Int
  prompt_answer: prompt_answers
  prompt_book: prompt_books_summary
  prompt_id: Int!
  user_id: Int!
}

type PromptIdType {
  error: String
  id: Int
  prompt: prompts
}

type PublisherIdType {
  errors: [String]
  id: Int
  publisher: publishers
}

input PublisherInputType {
  canonical_id: Int
  locked: Boolean
  name: String
  slug: String
  state: String
}

input ReadingJournalCreateType {
  action_at: date
  book_id: Int!
  edition_id: Int
  entry: String
  event: String!
  metadata: jsonb
  privacy_setting_id: Int!
  tags: [BasicTag]!
}

type ReadingJournalOutput {
  errors: [String]
  id: Int
  reading_journal: reading_journals
}

input ReadingJournalUpdateType {
  action_at: date
  edition_id: Int
  entry: String
  event: String
  metadata: jsonb
  privacy_setting_id: Int
  tags: [BasicTag]
}

type ReferralType {
  book: books
  book_id: Int!
  count: Int!
}

input ReportInput {
  details: String!
  metadata: jsonb
  reportable_id: Int!
  reportable_type: String!
  service_name: String
}

type ReportOutput {
  complete: Boolean
  created: Boolean
  errors: [String]
}

type SearchOutput {
  error: String
  ids: [Int]
  page: Int
  per_page: Int
  query: String
  query_type: String
  results: jsonb
}

type SeriesIdType {
  errors: [String]
  id: Int
  series: series
}

input SeriesInput {
  name: String!
}

input SeriesInputType {
  author_id: Int
  description: String
  id: Int
  is_completed: Boolean
  locked: Boolean
  name: String
  slug: String
  state: String
}

scalar String

"""
Boolean expression to compare columns of type "String". All fields are combined with logical 'AND'.
"""
input String_comparison_exp {
  _eq: String
  _gt: String
  _gte: String
  _ilike: String
  _in: [String!]
  _iregex: String
  _is_null: Boolean
  _like: String
  _lt: String
  _lte: String
  _neq: String
  _nilike: String
  _nin: [String!]
  _niregex: String
  _nlike: String
  _nregex: String
  _nsimilar: String
  _regex: String
  _similar: String
}

type SubscriptionsType {
  billing_portal_url: String
  membership: String
  membership_ends_at: timestamp
  monthly_session_id: String
  monthly_session_url: String
  payment_system: String
  yearly_session_id: String
  yearly_session_url: String
}

type SuccessType {
  success: Boolean!
}

input TagsDtoInput {
  ContentWarning: [DtoTag]
  Genre: [DtoTag]
  Mood: [DtoTag]
}

type TagsType {
  tags: [BasicTagType]!
}

type TrendingBookType {
  error: String
  ids: [Int]
}

input UpdatePromptInput {
  description: String!
  id: Int!
  privacy_setting_id: Int!
  question: String!
}

input UserBookCreateInput {
  book_id: Int!
  date_added: date
  edition_id: Int
  first_started_reading_date: date
  last_read_date: date
  media_url: String
  privacy_setting_id: Int
  private_notes: String
  rating: numeric
  read_count: Int
  reading_format_id: Int
  recommended_by: String
  recommended_for: String
  referrer_user_id: Int
  review_has_spoilers: Boolean
  review_slate: jsonb
  reviewed_at: date
  sponsored_review: Boolean
  status_id: Int
  url: String
}

type UserBookDeleteType {
  book_id: Int
  id: Int
  user_book: user_books
  user_id: Int
}

type UserBookIdType {
  error: String
  id: Int
  user_book: user_books
}

type UserBookReadIdType {
  error: String
  id: Int
  user_book_read: user_book_reads
}

input UserBookUpdateInput {
  date_added: date
  edition_id: Int
  first_started_reading_date: date
  last_read_date: date
  media_url: String
  privacy_setting_id: Int
  private_notes: String
  rating: numeric
  read_count: Int
  reading_format_id: Int
  recommended_by: String
  recommended_for: String
  referrer_user_id: Int
  review_has_spoilers: Boolean
  review_slate: jsonb
  reviewed_at: date
  sponsored_review: Boolean
  status_id: Int
  url: String
}

type UserBooksReadUpsertType {
  error: String
  user_book: user_books
  user_book_id: Int
}

type UserIdType {
  errors: [String]
  id: Int
  user: users
}

input UserJoinInput {
  email: String!
  password: String!
  referrer_id: Int
  referrer_url: String
}

input UserLoginInput {
  email: String!
  password: String!
}

type ValidateReceiptType {
  result: jsonb!
  supporter: Boolean
}

"""
columns and relationships of "activities"
"""
type activities {
  book: books
  book_id: Int
  created_at: timestamptz
  data: jsonb!
  event: String!
  followers: [followed_users!]!
  id: Int!
  likes: [likes!]!
  likes_count: Int!
  object_type: String!
  original_book_id: Int
  privacy_setting: privacy_settings!
  privacy_setting_id: Int!
  uid: String!
  user: users!
  user_id: Int!
}

"""
order by aggregate values of table "activities"
"""
input activities_aggregate_order_by {
  avg: activities_avg_order_by
  count: order_by
  max: activities_max_order_by
  min: activities_min_order_by
  stddev: activities_stddev_order_by
  stddev_pop: activities_stddev_pop_order_by
  stddev_samp: activities_stddev_samp_order_by
  sum: activities_sum_order_by
  var_pop: activities_var_pop_order_by
  var_samp: activities_var_samp_order_by
  variance: activities_variance_order_by
}

"""
order by avg() on columns of table "activities"
"""
input activities_avg_order_by {
  book_id: order_by
  id: order_by
  likes_count: order_by
  original_book_id: order_by
  privacy_setting_id: order_by
  user_id: order_by
}

"""
Boolean expression to filter rows from the table "activities". All fields are combined with a logical 'AND'.
"""
input activities_bool_exp {
  _and: [activities_bool_exp!]
  _not: activities_bool_exp
  _or: [activities_bool_exp!]
  book: books_bool_exp
  book_id: Int_comparison_exp
  created_at: timestamptz_comparison_exp
  data: jsonb_comparison_exp
  event: String_comparison_exp
  followers: followed_users_bool_exp
  id: Int_comparison_exp
  likes: likes_bool_exp
  likes_count: Int_comparison_exp
  object_type: String_comparison_exp
  original_book_id: Int_comparison_exp
  privacy_setting: privacy_settings_bool_exp
  privacy_setting_id: Int_comparison_exp
  uid: String_comparison_exp
  user: users_bool_exp
  user_id: Int_comparison_exp
}

"""
order by max() on columns of table "activities"
"""
input activities_max_order_by {
  book_id: order_by
  created_at: order_by
  event: order_by
  id: order_by
  likes_count: order_by
  object_type: order_by
  original_book_id: order_by
  privacy_setting_id: order_by
  uid: order_by
  user_id: order_by
}

"""
order by min() on columns of table "activities"
"""
input activities_min_order_by {
  book_id: order_by
  created_at: order_by
  event: order_by
  id: order_by
  likes_count: order_by
  object_type: order_by
  original_book_id: order_by
  privacy_setting_id: order_by
  uid: order_by
  user_id: order_by
}

"""
response of any mutation on the table "activities"
"""
type activities_mutation_response {
  affected_rows: Int!
  returning: [activities!]!
}

"""
Ordering options when selecting data from "activities".
"""
input activities_order_by {
  book: books_order_by
  book_id: order_by
  created_at: order_by
  data: order_by
  event: order_by
  followers_aggregate: followed_users_aggregate_order_by
  id: order_by
  likes_aggregate: likes_aggregate_order_by
  likes_count: order_by
  object_type: order_by
  original_book_id: order_by
  privacy_setting: privacy_settings_order_by
  privacy_setting_id: order_by
  uid: order_by
  user: users_order_by
  user_id: order_by
}

"""
select columns of table "activities"
"""
enum activities_select_column {
  book_id
  created_at
  data
  event
  id
  likes_count
  object_type
  original_book_id
  privacy_setting_id
  uid
  user_id
}

"""
order by stddev() on columns of table "activities"
"""
input activities_stddev_order_by {
  book_id: order_by
  id: order_by
  likes_count: order_by
  original_book_id: order_by
  privacy_setting_id: order_by
  user_id: order_by
}

"""
order by stddev_pop() on columns of table "activities"
"""
input activities_stddev_pop_order_by {
  book_id: order_by
  id: order_by
  likes_count: order_by
  original_book_id: order_by
  privacy_setting_id: order_by
  user_id: order_by
}

"""
order by stddev_samp() on columns of table "activities"
"""
input activities_stddev_samp_order_by {
  book_id: order_by
  id: order_by
  likes_count: order_by
  original_book_id: order_by
  privacy_setting_id: order_by
  user_id: order_by
}

"""
Streaming cursor of the table "activities"
"""
input activities_stream_cursor_input {
  initial_value: activities_stream_cursor_value_input!
  ordering: cursor_ordering
}

"""
Initial value of the column from where the streaming should start
"""
input activities_stream_cursor_value_input {
  book_id: Int
  created_at: timestamptz
  data: jsonb
  event: String
  id: Int
  likes_count: Int
  object_type: String
  original_book_id: Int
  privacy_setting_id: Int
  uid: String
  user_id: Int
}

"""
order by sum() on columns of table "activities"
"""
input activities_sum_order_by {
  book_id: order_by
  id: order_by
  likes_count: order_by
  original_book_id: order_by
  privacy_setting_id: order_by
  user_id: order_by
}

"""
order by var_pop() on columns of table "activities"
"""
input activities_var_pop_order_by {
  book_id: order_by
  id: order_by
  likes_count: order_by
  original_book_id: order_by
  privacy_setting_id: order_by
  user_id: order_by
}

"""
order by var_samp() on columns of table "activities"
"""
input activities_var_samp_order_by {
  book_id: order_by
  id: order_by
  likes_count: order_by
  original_book_id: order_by
  privacy_setting_id: order_by
  user_id: order_by
}

"""
order by variance() on columns of table "activities"
"""
input activities_variance_order_by {
  book_id: order_by
  id: order_by
  likes_count: order_by
  original_book_id: order_by
  privacy_setting_id: order_by
  user_id: order_by
}

input activity_feed_args {
  feed_limit: Int
  feed_offset: Int
}

input activity_foryou_feed_args {
  feed_limit: Int
  feed_offset: Int
}

"""
columns and relationships of "authors"
"""
type authors {
  alias: [authors!]!
  alias_id: Int
  alternate_names: jsonb!
  bio: String
  books_count: Int!
  born_date: date
  born_year: Int
  cached_image: jsonb!
  canonical: authors
  canonical_id: Int
  contributions: [contributions!]!
  contributions_aggregate: contributions_aggregate!
  creator: users
  death_date: date
  death_year: Int
  gender_id: Int
  id: Int!
  identifiers: jsonb!
  image: images
  image_id: Int
  is_bipoc: Boolean
  is_lgbtq: Boolean
  links: jsonb!
  location: String
  locked: Boolean!
  name: String!
  name_personal: String
  slug: String
  state: String!
  title: String
  user_id: Int
  users_count: Int!
}

"""
order by aggregate values of table "authors"
"""
input authors_aggregate_order_by {
  avg: authors_avg_order_by
  count: order_by
  max: authors_max_order_by
  min: authors_min_order_by
  stddev: authors_stddev_order_by
  stddev_pop: authors_stddev_pop_order_by
  stddev_samp: authors_stddev_samp_order_by
  sum: authors_sum_order_by
  var_pop: authors_var_pop_order_by
  var_samp: authors_var_samp_order_by
  variance: authors_variance_order_by
}

"""
order by avg() on columns of table "authors"
"""
input authors_avg_order_by {
  alias_id: order_by
  books_count: order_by
  born_year: order_by
  canonical_id: order_by
  death_year: order_by
  gender_id: order_by
  id: order_by
  image_id: order_by
  user_id: order_by
  users_count: order_by
}

"""
Boolean expression to filter rows from the table "authors". All fields are combined with a logical 'AND'.
"""
input authors_bool_exp {
  _and: [authors_bool_exp!]
  _not: authors_bool_exp
  _or: [authors_bool_exp!]
  alias: authors_bool_exp
  alias_id: Int_comparison_exp
  alternate_names: jsonb_comparison_exp
  bio: String_comparison_exp
  books_count: Int_comparison_exp
  born_date: date_comparison_exp
  born_year: Int_comparison_exp
  cached_image: jsonb_comparison_exp
  canonical: authors_bool_exp
  canonical_id: Int_comparison_exp
  contributions: contributions_bool_exp
  contributions_aggregate: contributions_aggregate_bool_exp
  creator: users_bool_exp
  death_date: date_comparison_exp
  death_year: Int_comparison_exp
  gender_id: Int_comparison_exp
  id: Int_comparison_exp
  identifiers: jsonb_comparison_exp
  image: images_bool_exp
  image_id: Int_comparison_exp
  is_bipoc: Boolean_comparison_exp
  is_lgbtq: Boolean_comparison_exp
  links: jsonb_comparison_exp
  location: String_comparison_exp
  locked: Boolean_comparison_exp
  name: String_comparison_exp
  name_personal: String_comparison_exp
  slug: String_comparison_exp
  state: String_comparison_exp
  title: String_comparison_exp
  user_id: Int_comparison_exp
  users_count: Int_comparison_exp
}

"""
order by max() on columns of table "authors"
"""
input authors_max_order_by {
  alias_id: order_by
  bio: order_by
  books_count: order_by
  born_date: order_by
  born_year: order_by
  canonical_id: order_by
  death_date: order_by
  death_year: order_by
  gender_id: order_by
  id: order_by
  image_id: order_by
  location: order_by
  name: order_by
  name_personal: order_by
  slug: order_by
  state: order_by
  title: order_by
  user_id: order_by
  users_count: order_by
}

"""
order by min() on columns of table "authors"
"""
input authors_min_order_by {
  alias_id: order_by
  bio: order_by
  books_count: order_by
  born_date: order_by
  born_year: order_by
  canonical_id: order_by
  death_date: order_by
  death_year: order_by
  gender_id: order_by
  id: order_by
  image_id: order_by
  location: order_by
  name: order_by
  name_personal: order_by
  slug: order_by
  state: order_by
  title: order_by
  user_id: order_by
  users_count: order_by
}

"""
Ordering options when selecting data from "authors".
"""
input authors_order_by {
  alias_aggregate: authors_aggregate_order_by
  alias_id: order_by
  alternate_names: order_by
  bio: order_by
  books_count: order_by
  born_date: order_by
  born_year: order_by
  cached_image: order_by
  canonical: authors_order_by
  canonical_id: order_by
  contributions_aggregate: contributions_aggregate_order_by
  creator: users_order_by
  death_date: order_by
  death_year: order_by
  gender_id: order_by
  id: order_by
  identifiers: order_by
  image: images_order_by
  image_id: order_by
  is_bipoc: order_by
  is_lgbtq: order_by
  links: order_by
  location: order_by
  locked: order_by
  name: order_by
  name_personal: order_by
  slug: order_by
  state: order_by
  title: order_by
  user_id: order_by
  users_count: order_by
}

"""
select columns of table "authors"
"""
enum authors_select_column {
  alias_id
  alternate_names
  bio
  books_count
  born_date
  born_year
  cached_image
  canonical_id
  death_date
  death_year
  gender_id
  id
  identifiers
  image_id
  is_bipoc
  is_lgbtq
  links
  location
  locked
  name
  name_personal
  slug
  state
  title
  user_id
  users_count
}

"""
order by stddev() on columns of table "authors"
"""
input authors_stddev_order_by {
  alias_id: order_by
  books_count: order_by
  born_year: order_by
  canonical_id: order_by
  death_year: order_by
  gender_id: order_by
  id: order_by
  image_id: order_by
  user_id: order_by
  users_count: order_by
}

"""
order by stddev_pop() on columns of table "authors"
"""
input authors_stddev_pop_order_by {
  alias_id: order_by
  books_count: order_by
  born_year: order_by
  canonical_id: order_by
  death_year: order_by
  gender_id: order_by
  id: order_by
  image_id: order_by
  user_id: order_by
  users_count: order_by
}

"""
order by stddev_samp() on columns of table "authors"
"""
input authors_stddev_samp_order_by {
  alias_id: order_by
  books_count: order_by
  born_year: order_by
  canonical_id: order_by
  death_year: order_by
  gender_id: order_by
  id: order_by
  image_id: order_by
  user_id: order_by
  users_count: order_by
}

"""
Streaming cursor of the table "authors"
"""
input authors_stream_cursor_input {
  initial_value: authors_stream_cursor_value_input!
  ordering: cursor_ordering
}

"""
Initial value of the column from where the streaming should start
"""
input authors_stream_cursor_value_input {
  alias_id: Int
  alternate_names: jsonb
  bio: String
  books_count: Int
  born_date: date
  born_year: Int
  cached_image: jsonb
  canonical_id: Int
  death_date: date
  death_year: Int
  gender_id: Int
  id: Int
  identifiers: jsonb
  image_id: Int
  is_bipoc: Boolean
  is_lgbtq: Boolean
  links: jsonb
  location: String
  locked: Boolean
  name: String
  name_personal: String
  slug: String
  state: String
  title: String
  user_id: Int
  users_count: Int
}

"""
order by sum() on columns of table "authors"
"""
input authors_sum_order_by {
  alias_id: order_by
  books_count: order_by
  born_year: order_by
  canonical_id: order_by
  death_year: order_by
  gender_id: order_by
  id: order_by
  image_id: order_by
  user_id: order_by
  users_count: order_by
}

"""
order by var_pop() on columns of table "authors"
"""
input authors_var_pop_order_by {
  alias_id: order_by
  books_count: order_by
  born_year: order_by
  canonical_id: order_by
  death_year: order_by
  gender_id: order_by
  id: order_by
  image_id: order_by
  user_id: order_by
  users_count: order_by
}

"""
order by var_samp() on columns of table "authors"
"""
input authors_var_samp_order_by {
  alias_id: order_by
  books_count: order_by
  born_year: order_by
  canonical_id: order_by
  death_year: order_by
  gender_id: order_by
  id: order_by
  image_id: order_by
  user_id: order_by
  users_count: order_by
}

"""
order by variance() on columns of table "authors"
"""
input authors_variance_order_by {
  alias_id: order_by
  books_count: order_by
  born_year: order_by
  canonical_id: order_by
  death_year: order_by
  gender_id: order_by
  id: order_by
  image_id: order_by
  user_id: order_by
  users_count: order_by
}

scalar bigint

"""
Boolean expression to compare columns of type "bigint". All fields are combined with logical 'AND'.
"""
input bigint_comparison_exp {
  _eq: bigint
  _gt: bigint
  _gte: bigint
  _in: [bigint!]
  _is_null: Boolean
  _lt: bigint
  _lte: bigint
  _neq: bigint
  _nin: [bigint!]
}

"""
columns and relationships of "book_categories"
"""
type book_categories {
  id: bigint!
  name: String!
}

"""
Boolean expression to filter rows from the table "book_categories". All fields are combined with a logical 'AND'.
"""
input book_categories_bool_exp {
  _and: [book_categories_bool_exp!]
  _not: book_categories_bool_exp
  _or: [book_categories_bool_exp!]
  id: bigint_comparison_exp
  name: String_comparison_exp
}

"""
Ordering options when selecting data from "book_categories".
"""
input book_categories_order_by {
  id: order_by
  name: order_by
}

"""
select columns of table "book_categories"
"""
enum book_categories_select_column {
  id
  name
}

"""
Streaming cursor of the table "book_categories"
"""
input book_categories_stream_cursor_input {
  initial_value: book_categories_stream_cursor_value_input!
  ordering: cursor_ordering
}

"""
Initial value of the column from where the streaming should start
"""
input book_categories_stream_cursor_value_input {
  id: bigint
  name: String
}

"""
columns and relationships of "book_characters"
"""
type book_characters {
  book: books
  book_id: bigint!
  character: characters
  character_id: bigint!
  id: bigint!
  only_mentioned: Boolean!
  position: Int!
  spoiler: Boolean!
}

"""
order by aggregate values of table "book_characters"
"""
input book_characters_aggregate_order_by {
  avg: book_characters_avg_order_by
  count: order_by
  max: book_characters_max_order_by
  min: book_characters_min_order_by
  stddev: book_characters_stddev_order_by
  stddev_pop: book_characters_stddev_pop_order_by
  stddev_samp: book_characters_stddev_samp_order_by
  sum: book_characters_sum_order_by
  var_pop: book_characters_var_pop_order_by
  var_samp: book_characters_var_samp_order_by
  variance: book_characters_variance_order_by
}

"""
order by avg() on columns of table "book_characters"
"""
input book_characters_avg_order_by {
  book_id: order_by
  character_id: order_by
  id: order_by
  position: order_by
}

"""
Boolean expression to filter rows from the table "book_characters". All fields are combined with a logical 'AND'.
"""
input book_characters_bool_exp {
  _and: [book_characters_bool_exp!]
  _not: book_characters_bool_exp
  _or: [book_characters_bool_exp!]
  book: books_bool_exp
  book_id: bigint_comparison_exp
  character: characters_bool_exp
  character_id: bigint_comparison_exp
  id: bigint_comparison_exp
  only_mentioned: Boolean_comparison_exp
  position: Int_comparison_exp
  spoiler: Boolean_comparison_exp
}

"""
order by max() on columns of table "book_characters"
"""
input book_characters_max_order_by {
  book_id: order_by
  character_id: order_by
  id: order_by
  position: order_by
}

"""
order by min() on columns of table "book_characters"
"""
input book_characters_min_order_by {
  book_id: order_by
  character_id: order_by
  id: order_by
  position: order_by
}

"""
Ordering options when selecting data from "book_characters".
"""
input book_characters_order_by {
  book: books_order_by
  book_id: order_by
  character: characters_order_by
  character_id: order_by
  id: order_by
  only_mentioned: order_by
  position: order_by
  spoiler: order_by
}

"""
select columns of table "book_characters"
"""
enum book_characters_select_column {
  book_id
  character_id
  id
  only_mentioned
  position
  spoiler
}

"""
order by stddev() on columns of table "book_characters"
"""
input book_characters_stddev_order_by {
  book_id: order_by
  character_id: order_by
  id: order_by
  position: order_by
}

"""
order by stddev_pop() on columns of table "book_characters"
"""
input book_characters_stddev_pop_order_by {
  book_id: order_by
  character_id: order_by
  id: order_by
  position: order_by
}

"""
order by stddev_samp() on columns of table "book_characters"
"""
input book_characters_stddev_samp_order_by {
  book_id: order_by
  character_id: order_by
  id: order_by
  position: order_by
}

"""
Streaming cursor of the table "book_characters"
"""
input book_characters_stream_cursor_input {
  initial_value: book_characters_stream_cursor_value_input!
  ordering: cursor_ordering
}

"""
Initial value of the column from where the streaming should start
"""
input book_characters_stream_cursor_value_input {
  book_id: bigint
  character_id: bigint
  id: bigint
  only_mentioned: Boolean
  position: Int
  spoiler: Boolean
}

"""
order by sum() on columns of table "book_characters"
"""
input book_characters_sum_order_by {
  book_id: order_by
  character_id: order_by
  id: order_by
  position: order_by
}

"""
order by var_pop() on columns of table "book_characters"
"""
input book_characters_var_pop_order_by {
  book_id: order_by
  character_id: order_by
  id: order_by
  position: order_by
}

"""
order by var_samp() on columns of table "book_characters"
"""
input book_characters_var_samp_order_by {
  book_id: order_by
  character_id: order_by
  id: order_by
  position: order_by
}

"""
order by variance() on columns of table "book_characters"
"""
input book_characters_variance_order_by {
  book_id: order_by
  character_id: order_by
  id: order_by
  position: order_by
}

"""
columns and relationships of "book_collections"
"""
type book_collections {
  book_id: Int!
  child_book_id: Int!
  id: bigint!
  position: Int!
}

"""
Boolean expression to filter rows from the table "book_collections". All fields are combined with a logical 'AND'.
"""
input book_collections_bool_exp {
  _and: [book_collections_bool_exp!]
  _not: book_collections_bool_exp
  _or: [book_collections_bool_exp!]
  book_id: Int_comparison_exp
  child_book_id: Int_comparison_exp
  id: bigint_comparison_exp
  position: Int_comparison_exp
}

"""
Ordering options when selecting data from "book_collections".
"""
input book_collections_order_by {
  book_id: order_by
  child_book_id: order_by
  id: order_by
  position: order_by
}

"""
select columns of table "book_collections"
"""
enum book_collections_select_column {
  book_id
  child_book_id
  id
  position
}

"""
Streaming cursor of the table "book_collections"
"""
input book_collections_stream_cursor_input {
  initial_value: book_collections_stream_cursor_value_input!
  ordering: cursor_ordering
}

"""
Initial value of the column from where the streaming should start
"""
input book_collections_stream_cursor_value_input {
  book_id: Int
  child_book_id: Int
  id: bigint
  position: Int
}

"""
columns and relationships of "book_mappings"
"""
type book_mappings {
  attempts: Int
  book: books!
  book_id: Int!
  created_at: timestamptz
  dto_external: json!
  edition: editions
  edition_id: Int
  external_data_id: Int
  external_id: String!
  id: Int!
  loaded: Boolean
  loaded_at: timestamp
  normalized_at: timestamp
  original_book_id: Int
  platform: platforms!
  platform_id: Int!
  state: String!
  updated_at: timestamptz
  verified: Boolean
  verified_at: timestamp
}

"""
order by aggregate values of table "book_mappings"
"""
input book_mappings_aggregate_order_by {
  avg: book_mappings_avg_order_by
  count: order_by
  max: book_mappings_max_order_by
  min: book_mappings_min_order_by
  stddev: book_mappings_stddev_order_by
  stddev_pop: book_mappings_stddev_pop_order_by
  stddev_samp: book_mappings_stddev_samp_order_by
  sum: book_mappings_sum_order_by
  var_pop: book_mappings_var_pop_order_by
  var_samp: book_mappings_var_samp_order_by
  variance: book_mappings_variance_order_by
}

"""
order by avg() on columns of table "book_mappings"
"""
input book_mappings_avg_order_by {
  attempts: order_by
  book_id: order_by
  edition_id: order_by
  external_data_id: order_by
  id: order_by
  original_book_id: order_by
  platform_id: order_by
}

"""
Boolean expression to filter rows from the table "book_mappings". All fields are combined with a logical 'AND'.
"""
input book_mappings_bool_exp {
  _and: [book_mappings_bool_exp!]
  _not: book_mappings_bool_exp
  _or: [book_mappings_bool_exp!]
  attempts: Int_comparison_exp
  book: books_bool_exp
  book_id: Int_comparison_exp
  created_at: timestamptz_comparison_exp
  dto_external: json_comparison_exp
  edition: editions_bool_exp
  edition_id: Int_comparison_exp
  external_data_id: Int_comparison_exp
  external_id: String_comparison_exp
  id: Int_comparison_exp
  loaded: Boolean_comparison_exp
  loaded_at: timestamp_comparison_exp
  normalized_at: timestamp_comparison_exp
  original_book_id: Int_comparison_exp
  platform: platforms_bool_exp
  platform_id: Int_comparison_exp
  state: String_comparison_exp
  updated_at: timestamptz_comparison_exp
  verified: Boolean_comparison_exp
  verified_at: timestamp_comparison_exp
}

"""
order by max() on columns of table "book_mappings"
"""
input book_mappings_max_order_by {
  attempts: order_by
  book_id: order_by
  created_at: order_by
  edition_id: order_by
  external_data_id: order_by
  external_id: order_by
  id: order_by
  loaded_at: order_by
  normalized_at: order_by
  original_book_id: order_by
  platform_id: order_by
  state: order_by
  updated_at: order_by
  verified_at: order_by
}

"""
order by min() on columns of table "book_mappings"
"""
input book_mappings_min_order_by {
  attempts: order_by
  book_id: order_by
  created_at: order_by
  edition_id: order_by
  external_data_id: order_by
  external_id: order_by
  id: order_by
  loaded_at: order_by
  normalized_at: order_by
  original_book_id: order_by
  platform_id: order_by
  state: order_by
  updated_at: order_by
  verified_at: order_by
}

"""
Ordering options when selecting data from "book_mappings".
"""
input book_mappings_order_by {
  attempts: order_by
  book: books_order_by
  book_id: order_by
  created_at: order_by
  dto_external: order_by
  edition: editions_order_by
  edition_id: order_by
  external_data_id: order_by
  external_id: order_by
  id: order_by
  loaded: order_by
  loaded_at: order_by
  normalized_at: order_by
  original_book_id: order_by
  platform: platforms_order_by
  platform_id: order_by
  state: order_by
  updated_at: order_by
  verified: order_by
  verified_at: order_by
}

"""
select columns of table "book_mappings"
"""
enum book_mappings_select_column {
  attempts
  book_id
  created_at
  dto_external
  edition_id
  external_data_id
  external_id
  id
  loaded
  loaded_at
  normalized_at
  original_book_id
  platform_id
  state
  updated_at
  verified
  verified_at
}

"""
order by stddev() on columns of table "book_mappings"
"""
input book_mappings_stddev_order_by {
  attempts: order_by
  book_id: order_by
  edition_id: order_by
  external_data_id: order_by
  id: order_by
  original_book_id: order_by
  platform_id: order_by
}

"""
order by stddev_pop() on columns of table "book_mappings"
"""
input book_mappings_stddev_pop_order_by {
  attempts: order_by
  book_id: order_by
  edition_id: order_by
  external_data_id: order_by
  id: order_by
  original_book_id: order_by
  platform_id: order_by
}

"""
order by stddev_samp() on columns of table "book_mappings"
"""
input book_mappings_stddev_samp_order_by {
  attempts: order_by
  book_id: order_by
  edition_id: order_by
  external_data_id: order_by
  id: order_by
  original_book_id: order_by
  platform_id: order_by
}

"""
Streaming cursor of the table "book_mappings"
"""
input book_mappings_stream_cursor_input {
  initial_value: book_mappings_stream_cursor_value_input!
  ordering: cursor_ordering
}

"""
Initial value of the column from where the streaming should start
"""
input book_mappings_stream_cursor_value_input {
  attempts: Int
  book_id: Int
  created_at: timestamptz
  dto_external: json
  edition_id: Int
  external_data_id: Int
  external_id: String
  id: Int
  loaded: Boolean
  loaded_at: timestamp
  normalized_at: timestamp
  original_book_id: Int
  platform_id: Int
  state: String
  updated_at: timestamptz
  verified: Boolean
  verified_at: timestamp
}

"""
order by sum() on columns of table "book_mappings"
"""
input book_mappings_sum_order_by {
  attempts: order_by
  book_id: order_by
  edition_id: order_by
  external_data_id: order_by
  id: order_by
  original_book_id: order_by
  platform_id: order_by
}

"""
order by var_pop() on columns of table "book_mappings"
"""
input book_mappings_var_pop_order_by {
  attempts: order_by
  book_id: order_by
  edition_id: order_by
  external_data_id: order_by
  id: order_by
  original_book_id: order_by
  platform_id: order_by
}

"""
order by var_samp() on columns of table "book_mappings"
"""
input book_mappings_var_samp_order_by {
  attempts: order_by
  book_id: order_by
  edition_id: order_by
  external_data_id: order_by
  id: order_by
  original_book_id: order_by
  platform_id: order_by
}

"""
order by variance() on columns of table "book_mappings"
"""
input book_mappings_variance_order_by {
  attempts: order_by
  book_id: order_by
  edition_id: order_by
  external_data_id: order_by
  id: order_by
  original_book_id: order_by
  platform_id: order_by
}

"""
columns and relationships of "book_series"
"""
type book_series {
  book: books
  book_id: Int!
  created_at: timestamp!
  details: String
  featured: Boolean!
  id: bigint!
  position: float8
  series: series
  series_id: Int!
  updated_at: timestamp!
}

"""
aggregated selection of "book_series"
"""
type book_series_aggregate {
  aggregate: book_series_aggregate_fields
  nodes: [book_series!]!
}

input book_series_aggregate_bool_exp {
  avg: book_series_aggregate_bool_exp_avg
  bool_and: book_series_aggregate_bool_exp_bool_and
  bool_or: book_series_aggregate_bool_exp_bool_or
  corr: book_series_aggregate_bool_exp_corr
  count: book_series_aggregate_bool_exp_count
  covar_samp: book_series_aggregate_bool_exp_covar_samp
  max: book_series_aggregate_bool_exp_max
  min: book_series_aggregate_bool_exp_min
  stddev_samp: book_series_aggregate_bool_exp_stddev_samp
  sum: book_series_aggregate_bool_exp_sum
  var_samp: book_series_aggregate_bool_exp_var_samp
}

input book_series_aggregate_bool_exp_avg {
  arguments: book_series_select_column_book_series_aggregate_bool_exp_avg_arguments_columns!
  distinct: Boolean
  filter: book_series_bool_exp
  predicate: float8_comparison_exp!
}

input book_series_aggregate_bool_exp_bool_and {
  arguments: book_series_select_column_book_series_aggregate_bool_exp_bool_and_arguments_columns!
  distinct: Boolean
  filter: book_series_bool_exp
  predicate: Boolean_comparison_exp!
}

input book_series_aggregate_bool_exp_bool_or {
  arguments: book_series_select_column_book_series_aggregate_bool_exp_bool_or_arguments_columns!
  distinct: Boolean
  filter: book_series_bool_exp
  predicate: Boolean_comparison_exp!
}

input book_series_aggregate_bool_exp_corr {
  arguments: book_series_aggregate_bool_exp_corr_arguments!
  distinct: Boolean
  filter: book_series_bool_exp
  predicate: float8_comparison_exp!
}

input book_series_aggregate_bool_exp_corr_arguments {
  X: book_series_select_column_book_series_aggregate_bool_exp_corr_arguments_columns!
  Y: book_series_select_column_book_series_aggregate_bool_exp_corr_arguments_columns!
}

input book_series_aggregate_bool_exp_count {
  arguments: [book_series_select_column!]
  distinct: Boolean
  filter: book_series_bool_exp
  predicate: Int_comparison_exp!
}

input book_series_aggregate_bool_exp_covar_samp {
  arguments: book_series_aggregate_bool_exp_covar_samp_arguments!
  distinct: Boolean
  filter: book_series_bool_exp
  predicate: float8_comparison_exp!
}

input book_series_aggregate_bool_exp_covar_samp_arguments {
  X: book_series_select_column_book_series_aggregate_bool_exp_covar_samp_arguments_columns!
  Y: book_series_select_column_book_series_aggregate_bool_exp_covar_samp_arguments_columns!
}

input book_series_aggregate_bool_exp_max {
  arguments: book_series_select_column_book_series_aggregate_bool_exp_max_arguments_columns!
  distinct: Boolean
  filter: book_series_bool_exp
  predicate: float8_comparison_exp!
}

input book_series_aggregate_bool_exp_min {
  arguments: book_series_select_column_book_series_aggregate_bool_exp_min_arguments_columns!
  distinct: Boolean
  filter: book_series_bool_exp
  predicate: float8_comparison_exp!
}

input book_series_aggregate_bool_exp_stddev_samp {
  arguments: book_series_select_column_book_series_aggregate_bool_exp_stddev_samp_arguments_columns!
  distinct: Boolean
  filter: book_series_bool_exp
  predicate: float8_comparison_exp!
}

input book_series_aggregate_bool_exp_sum {
  arguments: book_series_select_column_book_series_aggregate_bool_exp_sum_arguments_columns!
  distinct: Boolean
  filter: book_series_bool_exp
  predicate: float8_comparison_exp!
}

input book_series_aggregate_bool_exp_var_samp {
  arguments: book_series_select_column_book_series_aggregate_bool_exp_var_samp_arguments_columns!
  distinct: Boolean
  filter: book_series_bool_exp
  predicate: float8_comparison_exp!
}

"""
aggregate fields of "book_series"
"""
type book_series_aggregate_fields {
  avg: book_series_avg_fields
  count: Int!
  max: book_series_max_fields
  min: book_series_min_fields
  stddev: book_series_stddev_fields
  stddev_pop: book_series_stddev_pop_fields
  stddev_samp: book_series_stddev_samp_fields
  sum: book_series_sum_fields
  var_pop: book_series_var_pop_fields
  var_samp: book_series_var_samp_fields
  variance: book_series_variance_fields
}

"""
order by aggregate values of table "book_series"
"""
input book_series_aggregate_order_by {
  avg: book_series_avg_order_by
  count: order_by
  max: book_series_max_order_by
  min: book_series_min_order_by
  stddev: book_series_stddev_order_by
  stddev_pop: book_series_stddev_pop_order_by
  stddev_samp: book_series_stddev_samp_order_by
  sum: book_series_sum_order_by
  var_pop: book_series_var_pop_order_by
  var_samp: book_series_var_samp_order_by
  variance: book_series_variance_order_by
}

"""
aggregate avg on columns
"""
type book_series_avg_fields {
  book_id: Float
  id: Float
  position: Float
  series_id: Float
}

"""
order by avg() on columns of table "book_series"
"""
input book_series_avg_order_by {
  book_id: order_by
  id: order_by
  position: order_by
  series_id: order_by
}

"""
Boolean expression to filter rows from the table "book_series". All fields are combined with a logical 'AND'.
"""
input book_series_bool_exp {
  _and: [book_series_bool_exp!]
  _not: book_series_bool_exp
  _or: [book_series_bool_exp!]
  book: books_bool_exp
  book_id: Int_comparison_exp
  created_at: timestamp_comparison_exp
  details: String_comparison_exp
  featured: Boolean_comparison_exp
  id: bigint_comparison_exp
  position: float8_comparison_exp
  series: series_bool_exp
  series_id: Int_comparison_exp
  updated_at: timestamp_comparison_exp
}

"""
aggregate max on columns
"""
type book_series_max_fields {
  book_id: Int
  created_at: timestamp
  details: String
  id: bigint
  position: float8
  series_id: Int
  updated_at: timestamp
}

"""
order by max() on columns of table "book_series"
"""
input book_series_max_order_by {
  book_id: order_by
  created_at: order_by
  details: order_by
  id: order_by
  position: order_by
  series_id: order_by
  updated_at: order_by
}

"""
aggregate min on columns
"""
type book_series_min_fields {
  book_id: Int
  created_at: timestamp
  details: String
  id: bigint
  position: float8
  series_id: Int
  updated_at: timestamp
}

"""
order by min() on columns of table "book_series"
"""
input book_series_min_order_by {
  book_id: order_by
  created_at: order_by
  details: order_by
  id: order_by
  position: order_by
  series_id: order_by
  updated_at: order_by
}

"""
Ordering options when selecting data from "book_series".
"""
input book_series_order_by {
  book: books_order_by
  book_id: order_by
  created_at: order_by
  details: order_by
  featured: order_by
  id: order_by
  position: order_by
  series: series_order_by
  series_id: order_by
  updated_at: order_by
}

"""
select columns of table "book_series"
"""
enum book_series_select_column {
  book_id
  created_at
  details
  featured
  id
  position
  series_id
  updated_at
}

"""
select "book_series_aggregate_bool_exp_avg_arguments_columns" columns of table "book_series"
"""
enum book_series_select_column_book_series_aggregate_bool_exp_avg_arguments_columns {
  position
}

"""
select "book_series_aggregate_bool_exp_bool_and_arguments_columns" columns of table "book_series"
"""
enum book_series_select_column_book_series_aggregate_bool_exp_bool_and_arguments_columns {
  featured
}

"""
select "book_series_aggregate_bool_exp_bool_or_arguments_columns" columns of table "book_series"
"""
enum book_series_select_column_book_series_aggregate_bool_exp_bool_or_arguments_columns {
  featured
}

"""
select "book_series_aggregate_bool_exp_corr_arguments_columns" columns of table "book_series"
"""
enum book_series_select_column_book_series_aggregate_bool_exp_corr_arguments_columns {
  position
}

"""
select "book_series_aggregate_bool_exp_covar_samp_arguments_columns" columns of table "book_series"
"""
enum book_series_select_column_book_series_aggregate_bool_exp_covar_samp_arguments_columns {
  position
}

"""
select "book_series_aggregate_bool_exp_max_arguments_columns" columns of table "book_series"
"""
enum book_series_select_column_book_series_aggregate_bool_exp_max_arguments_columns {
  position
}

"""
select "book_series_aggregate_bool_exp_min_arguments_columns" columns of table "book_series"
"""
enum book_series_select_column_book_series_aggregate_bool_exp_min_arguments_columns {
  position
}

"""
select "book_series_aggregate_bool_exp_stddev_samp_arguments_columns" columns of table "book_series"
"""
enum book_series_select_column_book_series_aggregate_bool_exp_stddev_samp_arguments_columns {
  position
}

"""
select "book_series_aggregate_bool_exp_sum_arguments_columns" columns of table "book_series"
"""
enum book_series_select_column_book_series_aggregate_bool_exp_sum_arguments_columns {
  position
}

"""
select "book_series_aggregate_bool_exp_var_samp_arguments_columns" columns of table "book_series"
"""
enum book_series_select_column_book_series_aggregate_bool_exp_var_samp_arguments_columns {
  position
}

"""
aggregate stddev on columns
"""
type book_series_stddev_fields {
  book_id: Float
  id: Float
  position: Float
  series_id: Float
}

"""
order by stddev() on columns of table "book_series"
"""
input book_series_stddev_order_by {
  book_id: order_by
  id: order_by
  position: order_by
  series_id: order_by
}

"""
aggregate stddev_pop on columns
"""
type book_series_stddev_pop_fields {
  book_id: Float
  id: Float
  position: Float
  series_id: Float
}

"""
order by stddev_pop() on columns of table "book_series"
"""
input book_series_stddev_pop_order_by {
  book_id: order_by
  id: order_by
  position: order_by
  series_id: order_by
}

"""
aggregate stddev_samp on columns
"""
type book_series_stddev_samp_fields {
  book_id: Float
  id: Float
  position: Float
  series_id: Float
}

"""
order by stddev_samp() on columns of table "book_series"
"""
input book_series_stddev_samp_order_by {
  book_id: order_by
  id: order_by
  position: order_by
  series_id: order_by
}

"""
Streaming cursor of the table "book_series"
"""
input book_series_stream_cursor_input {
  initial_value: book_series_stream_cursor_value_input!
  ordering: cursor_ordering
}

"""
Initial value of the column from where the streaming should start
"""
input book_series_stream_cursor_value_input {
  book_id: Int
  created_at: timestamp
  details: String
  featured: Boolean
  id: bigint
  position: float8
  series_id: Int
  updated_at: timestamp
}

"""
aggregate sum on columns
"""
type book_series_sum_fields {
  book_id: Int
  id: bigint
  position: float8
  series_id: Int
}

"""
order by sum() on columns of table "book_series"
"""
input book_series_sum_order_by {
  book_id: order_by
  id: order_by
  position: order_by
  series_id: order_by
}

"""
aggregate var_pop on columns
"""
type book_series_var_pop_fields {
  book_id: Float
  id: Float
  position: Float
  series_id: Float
}

"""
order by var_pop() on columns of table "book_series"
"""
input book_series_var_pop_order_by {
  book_id: order_by
  id: order_by
  position: order_by
  series_id: order_by
}

"""
aggregate var_samp on columns
"""
type book_series_var_samp_fields {
  book_id: Float
  id: Float
  position: Float
  series_id: Float
}

"""
order by var_samp() on columns of table "book_series"
"""
input book_series_var_samp_order_by {
  book_id: order_by
  id: order_by
  position: order_by
  series_id: order_by
}

"""
aggregate variance on columns
"""
type book_series_variance_fields {
  book_id: Float
  id: Float
  position: Float
  series_id: Float
}

"""
order by variance() on columns of table "book_series"
"""
input book_series_variance_order_by {
  book_id: order_by
  id: order_by
  position: order_by
  series_id: order_by
}

"""
columns and relationships of "book_statuses"
"""
type book_statuses {
  books: [books!]!
  books_aggregate: books_aggregate!
  id: smallint!
  name: String!
}

"""
Boolean expression to filter rows from the table "book_statuses". All fields are combined with a logical 'AND'.
"""
input book_statuses_bool_exp {
  _and: [book_statuses_bool_exp!]
  _not: book_statuses_bool_exp
  _or: [book_statuses_bool_exp!]
  books: books_bool_exp
  books_aggregate: books_aggregate_bool_exp
  id: smallint_comparison_exp
  name: String_comparison_exp
}

"""
Ordering options when selecting data from "book_statuses".
"""
input book_statuses_order_by {
  books_aggregate: books_aggregate_order_by
  id: order_by
  name: order_by
}

"""
select columns of table "book_statuses"
"""
enum book_statuses_select_column {
  id
  name
}

"""
Streaming cursor of the table "book_statuses"
"""
input book_statuses_stream_cursor_input {
  initial_value: book_statuses_stream_cursor_value_input!
  ordering: cursor_ordering
}

"""
Initial value of the column from where the streaming should start
"""
input book_statuses_stream_cursor_value_input {
  id: smallint
  name: String
}

"""
columns and relationships of "bookles"
"""
type bookles {
  book: books
  book_id: Int
  created_at: timestamp
  date: date
  id: bigint!
}

"""
Boolean expression to filter rows from the table "bookles". All fields are combined with a logical 'AND'.
"""
input bookles_bool_exp {
  _and: [bookles_bool_exp!]
  _not: bookles_bool_exp
  _or: [bookles_bool_exp!]
  book: books_bool_exp
  book_id: Int_comparison_exp
  created_at: timestamp_comparison_exp
  date: date_comparison_exp
  id: bigint_comparison_exp
}

"""
Ordering options when selecting data from "bookles".
"""
input bookles_order_by {
  book: books_order_by
  book_id: order_by
  created_at: order_by
  date: order_by
  id: order_by
}

"""
select columns of table "bookles"
"""
enum bookles_select_column {
  book_id
  created_at
  date
  id
}

"""
Streaming cursor of the table "bookles"
"""
input bookles_stream_cursor_input {
  initial_value: bookles_stream_cursor_value_input!
  ordering: cursor_ordering
}

"""
Initial value of the column from where the streaming should start
"""
input bookles_stream_cursor_value_input {
  book_id: Int
  created_at: timestamp
  date: date
  id: bigint
}

"""
columns and relationships of "books"
"""
type books {
  activities_count: Int!
  alternative_titles: json!
  audio_seconds: Int
  book_category_id: Int!
  book_characters: [book_characters!]!
  book_mappings: [book_mappings!]!
  book_series: [book_series!]!
  book_series_aggregate: book_series_aggregate!
  book_status: book_statuses!
  book_status_id: smallint!
  cached_contributors: json!
  cached_featured_series: jsonb
  cached_header_image: jsonb!
  cached_image: jsonb!
  cached_tags: json!
  canonical: books
  canonical_id: Int
  collection_import_results: [collection_import_results!]!
  compilation: Boolean!
  contributions: [contributions!]!
  contributions_aggregate: contributions_aggregate!
  created_at: timestamp!
  created_by_user_id: Int
  default_audio_edition: editions
  default_audio_edition_id: Int
  default_cover_edition: editions
  default_cover_edition_id: Int
  default_ebook_edition: editions
  default_ebook_edition_id: Int
  default_physical_edition: editions
  default_physical_edition_id: Int
  description: String
  dto: json
  dto_combined: json
  dto_external: json
  editions: [editions!]!
  editions_count: Int!
  featured_book_series: book_series
  featured_book_series_id: Int
  header_image_id: Int
  headline: String
  id: Int!
  image: images
  image_id: Int
  images: [images!]!
  import_platform_id: Int!
  journals_count: Int!
  links: jsonb!
  list_books: [list_books!]!
  list_books_aggregate: list_books_aggregate!
  lists_count: Int
  literary_type_id: Int
  locked: Boolean!
  pages: Int
  prompt_answers: [prompt_answers!]!
  prompt_answers_aggregate: prompt_answers_aggregate!
  prompt_summaries: [prompt_books_summary!]!
  prompts_count: Int!
  rating: numeric
  ratings_count: Int!
  ratings_distribution: jsonb!
  recommendations: [recommendations!]!
  release_date: date
  release_year: Int
  reviews_count: Int!
  slug: String
  state: String
  subtitle: String
  taggable_counts: [taggable_counts!]!
  taggings: [taggings!]!
  taggings_aggregate: taggings_aggregate!
  title: String
  updated_at: timestamptz
  user_added: Boolean!
  user_books: [user_books!]!
  user_books_aggregate: user_books_aggregate!
  users_count: Int!
  users_read_count: Int!
}

"""
aggregated selection of "books"
"""
type books_aggregate {
  aggregate: books_aggregate_fields
  nodes: [books!]!
}

input books_aggregate_bool_exp {
  bool_and: books_aggregate_bool_exp_bool_and
  bool_or: books_aggregate_bool_exp_bool_or
  count: books_aggregate_bool_exp_count
}

input books_aggregate_bool_exp_bool_and {
  arguments: books_select_column_books_aggregate_bool_exp_bool_and_arguments_columns!
  distinct: Boolean
  filter: books_bool_exp
  predicate: Boolean_comparison_exp!
}

input books_aggregate_bool_exp_bool_or {
  arguments: books_select_column_books_aggregate_bool_exp_bool_or_arguments_columns!
  distinct: Boolean
  filter: books_bool_exp
  predicate: Boolean_comparison_exp!
}

input books_aggregate_bool_exp_count {
  arguments: [books_select_column!]
  distinct: Boolean
  filter: books_bool_exp
  predicate: Int_comparison_exp!
}

"""
aggregate fields of "books"
"""
type books_aggregate_fields {
  avg: books_avg_fields
  count: Int!
  max: books_max_fields
  min: books_min_fields
  stddev: books_stddev_fields
  stddev_pop: books_stddev_pop_fields
  stddev_samp: books_stddev_samp_fields
  sum: books_sum_fields
  var_pop: books_var_pop_fields
  var_samp: books_var_samp_fields
  variance: books_variance_fields
}

"""
order by aggregate values of table "books"
"""
input books_aggregate_order_by {
  avg: books_avg_order_by
  count: order_by
  max: books_max_order_by
  min: books_min_order_by
  stddev: books_stddev_order_by
  stddev_pop: books_stddev_pop_order_by
  stddev_samp: books_stddev_samp_order_by
  sum: books_sum_order_by
  var_pop: books_var_pop_order_by
  var_samp: books_var_samp_order_by
  variance: books_variance_order_by
}

"""
aggregate avg on columns
"""
type books_avg_fields {
  activities_count: Float
  audio_seconds: Float
  book_category_id: Float
  book_status_id: Float
  canonical_id: Float
  created_by_user_id: Float
  default_audio_edition_id: Float
  default_cover_edition_id: Float
  default_ebook_edition_id: Float
  default_physical_edition_id: Float
  editions_count: Float
  featured_book_series_id: Float
  header_image_id: Float
  id: Float
  image_id: Float
  import_platform_id: Float
  journals_count: Float
  lists_count: Float
  literary_type_id: Float
  pages: Float
  prompts_count: Float
  rating: Float
  ratings_count: Float
  release_year: Float
  reviews_count: Float
  users_count: Float
  users_read_count: Float
}

"""
order by avg() on columns of table "books"
"""
input books_avg_order_by {
  activities_count: order_by
  audio_seconds: order_by
  book_category_id: order_by
  book_status_id: order_by
  canonical_id: order_by
  created_by_user_id: order_by
  default_audio_edition_id: order_by
  default_cover_edition_id: order_by
  default_ebook_edition_id: order_by
  default_physical_edition_id: order_by
  editions_count: order_by
  featured_book_series_id: order_by
  header_image_id: order_by
  id: order_by
  image_id: order_by
  import_platform_id: order_by
  journals_count: order_by
  lists_count: order_by
  literary_type_id: order_by
  pages: order_by
  prompts_count: order_by
  rating: order_by
  ratings_count: order_by
  release_year: order_by
  reviews_count: order_by
  users_count: order_by
  users_read_count: order_by
}

"""
Boolean expression to filter rows from the table "books". All fields are combined with a logical 'AND'.
"""
input books_bool_exp {
  _and: [books_bool_exp!]
  _not: books_bool_exp
  _or: [books_bool_exp!]
  activities_count: Int_comparison_exp
  alternative_titles: json_comparison_exp
  audio_seconds: Int_comparison_exp
  book_category_id: Int_comparison_exp
  book_characters: book_characters_bool_exp
  book_mappings: book_mappings_bool_exp
  book_series: book_series_bool_exp
  book_series_aggregate: book_series_aggregate_bool_exp
  book_status: book_statuses_bool_exp
  book_status_id: smallint_comparison_exp
  cached_contributors: json_comparison_exp
  cached_featured_series: jsonb_comparison_exp
  cached_header_image: jsonb_comparison_exp
  cached_image: jsonb_comparison_exp
  cached_tags: json_comparison_exp
  canonical: books_bool_exp
  canonical_id: Int_comparison_exp
  collection_import_results: collection_import_results_bool_exp
  compilation: Boolean_comparison_exp
  contributions: contributions_bool_exp
  contributions_aggregate: contributions_aggregate_bool_exp
  created_at: timestamp_comparison_exp
  created_by_user_id: Int_comparison_exp
  default_audio_edition: editions_bool_exp
  default_audio_edition_id: Int_comparison_exp
  default_cover_edition: editions_bool_exp
  default_cover_edition_id: Int_comparison_exp
  default_ebook_edition: editions_bool_exp
  default_ebook_edition_id: Int_comparison_exp
  default_physical_edition: editions_bool_exp
  default_physical_edition_id: Int_comparison_exp
  description: String_comparison_exp
  dto: json_comparison_exp
  dto_combined: json_comparison_exp
  dto_external: json_comparison_exp
  editions: editions_bool_exp
  editions_count: Int_comparison_exp
  featured_book_series: book_series_bool_exp
  featured_book_series_id: Int_comparison_exp
  header_image_id: Int_comparison_exp
  headline: String_comparison_exp
  id: Int_comparison_exp
  image: images_bool_exp
  image_id: Int_comparison_exp
  images: images_bool_exp
  import_platform_id: Int_comparison_exp
  journals_count: Int_comparison_exp
  links: jsonb_comparison_exp
  list_books: list_books_bool_exp
  list_books_aggregate: list_books_aggregate_bool_exp
  lists_count: Int_comparison_exp
  literary_type_id: Int_comparison_exp
  locked: Boolean_comparison_exp
  pages: Int_comparison_exp
  prompt_answers: prompt_answers_bool_exp
  prompt_answers_aggregate: prompt_answers_aggregate_bool_exp
  prompt_summaries: prompt_books_summary_bool_exp
  prompts_count: Int_comparison_exp
  rating: numeric_comparison_exp
  ratings_count: Int_comparison_exp
  ratings_distribution: jsonb_comparison_exp
  recommendations: recommendations_bool_exp
  release_date: date_comparison_exp
  release_year: Int_comparison_exp
  reviews_count: Int_comparison_exp
  slug: String_comparison_exp
  state: String_comparison_exp
  subtitle: String_comparison_exp
  taggable_counts: taggable_counts_bool_exp
  taggings: taggings_bool_exp
  taggings_aggregate: taggings_aggregate_bool_exp
  title: String_comparison_exp
  updated_at: timestamptz_comparison_exp
  user_added: Boolean_comparison_exp
  user_books: user_books_bool_exp
  user_books_aggregate: user_books_aggregate_bool_exp
  users_count: Int_comparison_exp
  users_read_count: Int_comparison_exp
}

"""
aggregate max on columns
"""
type books_max_fields {
  activities_count: Int
  audio_seconds: Int
  book_category_id: Int
  book_status_id: smallint
  canonical_id: Int
  created_at: timestamp
  created_by_user_id: Int
  default_audio_edition_id: Int
  default_cover_edition_id: Int
  default_ebook_edition_id: Int
  default_physical_edition_id: Int
  description: String
  editions_count: Int
  featured_book_series_id: Int
  header_image_id: Int
  headline: String
  id: Int
  image_id: Int
  import_platform_id: Int
  journals_count: Int
  lists_count: Int
  literary_type_id: Int
  pages: Int
  prompts_count: Int
  rating: numeric
  ratings_count: Int
  release_date: date
  release_year: Int
  reviews_count: Int
  slug: String
  state: String
  subtitle: String
  title: String
  updated_at: timestamptz
  users_count: Int
  users_read_count: Int
}

"""
order by max() on columns of table "books"
"""
input books_max_order_by {
  activities_count: order_by
  audio_seconds: order_by
  book_category_id: order_by
  book_status_id: order_by
  canonical_id: order_by
  created_at: order_by
  created_by_user_id: order_by
  default_audio_edition_id: order_by
  default_cover_edition_id: order_by
  default_ebook_edition_id: order_by
  default_physical_edition_id: order_by
  description: order_by
  editions_count: order_by
  featured_book_series_id: order_by
  header_image_id: order_by
  headline: order_by
  id: order_by
  image_id: order_by
  import_platform_id: order_by
  journals_count: order_by
  lists_count: order_by
  literary_type_id: order_by
  pages: order_by
  prompts_count: order_by
  rating: order_by
  ratings_count: order_by
  release_date: order_by
  release_year: order_by
  reviews_count: order_by
  slug: order_by
  state: order_by
  subtitle: order_by
  title: order_by
  updated_at: order_by
  users_count: order_by
  users_read_count: order_by
}

"""
aggregate min on columns
"""
type books_min_fields {
  activities_count: Int
  audio_seconds: Int
  book_category_id: Int
  book_status_id: smallint
  canonical_id: Int
  created_at: timestamp
  created_by_user_id: Int
  default_audio_edition_id: Int
  default_cover_edition_id: Int
  default_ebook_edition_id: Int
  default_physical_edition_id: Int
  description: String
  editions_count: Int
  featured_book_series_id: Int
  header_image_id: Int
  headline: String
  id: Int
  image_id: Int
  import_platform_id: Int
  journals_count: Int
  lists_count: Int
  literary_type_id: Int
  pages: Int
  prompts_count: Int
  rating: numeric
  ratings_count: Int
  release_date: date
  release_year: Int
  reviews_count: Int
  slug: String
  state: String
  subtitle: String
  title: String
  updated_at: timestamptz
  users_count: Int
  users_read_count: Int
}

"""
order by min() on columns of table "books"
"""
input books_min_order_by {
  activities_count: order_by
  audio_seconds: order_by
  book_category_id: order_by
  book_status_id: order_by
  canonical_id: order_by
  created_at: order_by
  created_by_user_id: order_by
  default_audio_edition_id: order_by
  default_cover_edition_id: order_by
  default_ebook_edition_id: order_by
  default_physical_edition_id: order_by
  description: order_by
  editions_count: order_by
  featured_book_series_id: order_by
  header_image_id: order_by
  headline: order_by
  id: order_by
  image_id: order_by
  import_platform_id: order_by
  journals_count: order_by
  lists_count: order_by
  literary_type_id: order_by
  pages: order_by
  prompts_count: order_by
  rating: order_by
  ratings_count: order_by
  release_date: order_by
  release_year: order_by
  reviews_count: order_by
  slug: order_by
  state: order_by
  subtitle: order_by
  title: order_by
  updated_at: order_by
  users_count: order_by
  users_read_count: order_by
}

"""
Ordering options when selecting data from "books".
"""
input books_order_by {
  activities_count: order_by
  alternative_titles: order_by
  audio_seconds: order_by
  book_category_id: order_by
  book_characters_aggregate: book_characters_aggregate_order_by
  book_mappings_aggregate: book_mappings_aggregate_order_by
  book_series_aggregate: book_series_aggregate_order_by
  book_status: book_statuses_order_by
  book_status_id: order_by
  cached_contributors: order_by
  cached_featured_series: order_by
  cached_header_image: order_by
  cached_image: order_by
  cached_tags: order_by
  canonical: books_order_by
  canonical_id: order_by
  collection_import_results_aggregate: collection_import_results_aggregate_order_by
  compilation: order_by
  contributions_aggregate: contributions_aggregate_order_by
  created_at: order_by
  created_by_user_id: order_by
  default_audio_edition: editions_order_by
  default_audio_edition_id: order_by
  default_cover_edition: editions_order_by
  default_cover_edition_id: order_by
  default_ebook_edition: editions_order_by
  default_ebook_edition_id: order_by
  default_physical_edition: editions_order_by
  default_physical_edition_id: order_by
  description: order_by
  dto: order_by
  dto_combined: order_by
  dto_external: order_by
  editions_aggregate: editions_aggregate_order_by
  editions_count: order_by
  featured_book_series: book_series_order_by
  featured_book_series_id: order_by
  header_image_id: order_by
  headline: order_by
  id: order_by
  image: images_order_by
  image_id: order_by
  images_aggregate: images_aggregate_order_by
  import_platform_id: order_by
  journals_count: order_by
  links: order_by
  list_books_aggregate: list_books_aggregate_order_by
  lists_count: order_by
  literary_type_id: order_by
  locked: order_by
  pages: order_by
  prompt_answers_aggregate: prompt_answers_aggregate_order_by
  prompt_summaries_aggregate: prompt_books_summary_aggregate_order_by
  prompts_count: order_by
  rating: order_by
  ratings_count: order_by
  ratings_distribution: order_by
  recommendations_aggregate: recommendations_aggregate_order_by
  release_date: order_by
  release_year: order_by
  reviews_count: order_by
  slug: order_by
  state: order_by
  subtitle: order_by
  taggable_counts_aggregate: taggable_counts_aggregate_order_by
  taggings_aggregate: taggings_aggregate_order_by
  title: order_by
  updated_at: order_by
  user_added: order_by
  user_books_aggregate: user_books_aggregate_order_by
  users_count: order_by
  users_read_count: order_by
}

"""
select columns of table "books"
"""
enum books_select_column {
  activities_count
  alternative_titles
  audio_seconds
  book_category_id
  book_status_id
  cached_contributors
  cached_featured_series
  cached_header_image
  cached_image
  cached_tags
  canonical_id
  compilation
  created_at
  created_by_user_id
  default_audio_edition_id
  default_cover_edition_id
  default_ebook_edition_id
  default_physical_edition_id
  description
  dto
  dto_combined
  dto_external
  editions_count
  featured_book_series_id
  header_image_id
  headline
  id
  image_id
  import_platform_id
  journals_count
  links
  lists_count
  literary_type_id
  locked
  pages
  prompts_count
  rating
  ratings_count
  ratings_distribution
  release_date
  release_year
  reviews_count
  slug
  state
  subtitle
  title
  updated_at
  user_added
  users_count
  users_read_count
}

"""
select "books_aggregate_bool_exp_bool_and_arguments_columns" columns of table "books"
"""
enum books_select_column_books_aggregate_bool_exp_bool_and_arguments_columns {
  compilation
  locked
  user_added
}

"""
select "books_aggregate_bool_exp_bool_or_arguments_columns" columns of table "books"
"""
enum books_select_column_books_aggregate_bool_exp_bool_or_arguments_columns {
  compilation
  locked
  user_added
}

"""
aggregate stddev on columns
"""
type books_stddev_fields {
  activities_count: Float
  audio_seconds: Float
  book_category_id: Float
  book_status_id: Float
  canonical_id: Float
  created_by_user_id: Float
  default_audio_edition_id: Float
  default_cover_edition_id: Float
  default_ebook_edition_id: Float
  default_physical_edition_id: Float
  editions_count: Float
  featured_book_series_id: Float
  header_image_id: Float
  id: Float
  image_id: Float
  import_platform_id: Float
  journals_count: Float
  lists_count: Float
  literary_type_id: Float
  pages: Float
  prompts_count: Float
  rating: Float
  ratings_count: Float
  release_year: Float
  reviews_count: Float
  users_count: Float
  users_read_count: Float
}

"""
order by stddev() on columns of table "books"
"""
input books_stddev_order_by {
  activities_count: order_by
  audio_seconds: order_by
  book_category_id: order_by
  book_status_id: order_by
  canonical_id: order_by
  created_by_user_id: order_by
  default_audio_edition_id: order_by
  default_cover_edition_id: order_by
  default_ebook_edition_id: order_by
  default_physical_edition_id: order_by
  editions_count: order_by
  featured_book_series_id: order_by
  header_image_id: order_by
  id: order_by
  image_id: order_by
  import_platform_id: order_by
  journals_count: order_by
  lists_count: order_by
  literary_type_id: order_by
  pages: order_by
  prompts_count: order_by
  rating: order_by
  ratings_count: order_by
  release_year: order_by
  reviews_count: order_by
  users_count: order_by
  users_read_count: order_by
}

"""
aggregate stddev_pop on columns
"""
type books_stddev_pop_fields {
  activities_count: Float
  audio_seconds: Float
  book_category_id: Float
  book_status_id: Float
  canonical_id: Float
  created_by_user_id: Float
  default_audio_edition_id: Float
  default_cover_edition_id: Float
  default_ebook_edition_id: Float
  default_physical_edition_id: Float
  editions_count: Float
  featured_book_series_id: Float
  header_image_id: Float
  id: Float
  image_id: Float
  import_platform_id: Float
  journals_count: Float
  lists_count: Float
  literary_type_id: Float
  pages: Float
  prompts_count: Float
  rating: Float
  ratings_count: Float
  release_year: Float
  reviews_count: Float
  users_count: Float
  users_read_count: Float
}

"""
order by stddev_pop() on columns of table "books"
"""
input books_stddev_pop_order_by {
  activities_count: order_by
  audio_seconds: order_by
  book_category_id: order_by
  book_status_id: order_by
  canonical_id: order_by
  created_by_user_id: order_by
  default_audio_edition_id: order_by
  default_cover_edition_id: order_by
  default_ebook_edition_id: order_by
  default_physical_edition_id: order_by
  editions_count: order_by
  featured_book_series_id: order_by
  header_image_id: order_by
  id: order_by
  image_id: order_by
  import_platform_id: order_by
  journals_count: order_by
  lists_count: order_by
  literary_type_id: order_by
  pages: order_by
  prompts_count: order_by
  rating: order_by
  ratings_count: order_by
  release_year: order_by
  reviews_count: order_by
  users_count: order_by
  users_read_count: order_by
}

"""
aggregate stddev_samp on columns
"""
type books_stddev_samp_fields {
  activities_count: Float
  audio_seconds: Float
  book_category_id: Float
  book_status_id: Float
  canonical_id: Float
  created_by_user_id: Float
  default_audio_edition_id: Float
  default_cover_edition_id: Float
  default_ebook_edition_id: Float
  default_physical_edition_id: Float
  editions_count: Float
  featured_book_series_id: Float
  header_image_id: Float
  id: Float
  image_id: Float
  import_platform_id: Float
  journals_count: Float
  lists_count: Float
  literary_type_id: Float
  pages: Float
  prompts_count: Float
  rating: Float
  ratings_count: Float
  release_year: Float
  reviews_count: Float
  users_count: Float
  users_read_count: Float
}

"""
order by stddev_samp() on columns of table "books"
"""
input books_stddev_samp_order_by {
  activities_count: order_by
  audio_seconds: order_by
  book_category_id: order_by
  book_status_id: order_by
  canonical_id: order_by
  created_by_user_id: order_by
  default_audio_edition_id: order_by
  default_cover_edition_id: order_by
  default_ebook_edition_id: order_by
  default_physical_edition_id: order_by
  editions_count: order_by
  featured_book_series_id: order_by
  header_image_id: order_by
  id: order_by
  image_id: order_by
  import_platform_id: order_by
  journals_count: order_by
  lists_count: order_by
  literary_type_id: order_by
  pages: order_by
  prompts_count: order_by
  rating: order_by
  ratings_count: order_by
  release_year: order_by
  reviews_count: order_by
  users_count: order_by
  users_read_count: order_by
}

"""
Streaming cursor of the table "books"
"""
input books_stream_cursor_input {
  initial_value: books_stream_cursor_value_input!
  ordering: cursor_ordering
}

"""
Initial value of the column from where the streaming should start
"""
input books_stream_cursor_value_input {
  activities_count: Int
  alternative_titles: json
  audio_seconds: Int
  book_category_id: Int
  book_status_id: smallint
  cached_contributors: json
  cached_featured_series: jsonb
  cached_header_image: jsonb
  cached_image: jsonb
  cached_tags: json
  canonical_id: Int
  compilation: Boolean
  created_at: timestamp
  created_by_user_id: Int
  default_audio_edition_id: Int
  default_cover_edition_id: Int
  default_ebook_edition_id: Int
  default_physical_edition_id: Int
  description: String
  dto: json
  dto_combined: json
  dto_external: json
  editions_count: Int
  featured_book_series_id: Int
  header_image_id: Int
  headline: String
  id: Int
  image_id: Int
  import_platform_id: Int
  journals_count: Int
  links: jsonb
  lists_count: Int
  literary_type_id: Int
  locked: Boolean
  pages: Int
  prompts_count: Int
  rating: numeric
  ratings_count: Int
  ratings_distribution: jsonb
  release_date: date
  release_year: Int
  reviews_count: Int
  slug: String
  state: String
  subtitle: String
  title: String
  updated_at: timestamptz
  user_added: Boolean
  users_count: Int
  users_read_count: Int
}

"""
aggregate sum on columns
"""
type books_sum_fields {
  activities_count: Int
  audio_seconds: Int
  book_category_id: Int
  book_status_id: smallint
  canonical_id: Int
  created_by_user_id: Int
  default_audio_edition_id: Int
  default_cover_edition_id: Int
  default_ebook_edition_id: Int
  default_physical_edition_id: Int
  editions_count: Int
  featured_book_series_id: Int
  header_image_id: Int
  id: Int
  image_id: Int
  import_platform_id: Int
  journals_count: Int
  lists_count: Int
  literary_type_id: Int
  pages: Int
  prompts_count: Int
  rating: numeric
  ratings_count: Int
  release_year: Int
  reviews_count: Int
  users_count: Int
  users_read_count: Int
}

"""
order by sum() on columns of table "books"
"""
input books_sum_order_by {
  activities_count: order_by
  audio_seconds: order_by
  book_category_id: order_by
  book_status_id: order_by
  canonical_id: order_by
  created_by_user_id: order_by
  default_audio_edition_id: order_by
  default_cover_edition_id: order_by
  default_ebook_edition_id: order_by
  default_physical_edition_id: order_by
  editions_count: order_by
  featured_book_series_id: order_by
  header_image_id: order_by
  id: order_by
  image_id: order_by
  import_platform_id: order_by
  journals_count: order_by
  lists_count: order_by
  literary_type_id: order_by
  pages: order_by
  prompts_count: order_by
  rating: order_by
  ratings_count: order_by
  release_year: order_by
  reviews_count: order_by
  users_count: order_by
  users_read_count: order_by
}

"""
aggregate var_pop on columns
"""
type books_var_pop_fields {
  activities_count: Float
  audio_seconds: Float
  book_category_id: Float
  book_status_id: Float
  canonical_id: Float
  created_by_user_id: Float
  default_audio_edition_id: Float
  default_cover_edition_id: Float
  default_ebook_edition_id: Float
  default_physical_edition_id: Float
  editions_count: Float
  featured_book_series_id: Float
  header_image_id: Float
  id: Float
  image_id: Float
  import_platform_id: Float
  journals_count: Float
  lists_count: Float
  literary_type_id: Float
  pages: Float
  prompts_count: Float
  rating: Float
  ratings_count: Float
  release_year: Float
  reviews_count: Float
  users_count: Float
  users_read_count: Float
}

"""
order by var_pop() on columns of table "books"
"""
input books_var_pop_order_by {
  activities_count: order_by
  audio_seconds: order_by
  book_category_id: order_by
  book_status_id: order_by
  canonical_id: order_by
  created_by_user_id: order_by
  default_audio_edition_id: order_by
  default_cover_edition_id: order_by
  default_ebook_edition_id: order_by
  default_physical_edition_id: order_by
  editions_count: order_by
  featured_book_series_id: order_by
  header_image_id: order_by
  id: order_by
  image_id: order_by
  import_platform_id: order_by
  journals_count: order_by
  lists_count: order_by
  literary_type_id: order_by
  pages: order_by
  prompts_count: order_by
  rating: order_by
  ratings_count: order_by
  release_year: order_by
  reviews_count: order_by
  users_count: order_by
  users_read_count: order_by
}

"""
aggregate var_samp on columns
"""
type books_var_samp_fields {
  activities_count: Float
  audio_seconds: Float
  book_category_id: Float
  book_status_id: Float
  canonical_id: Float
  created_by_user_id: Float
  default_audio_edition_id: Float
  default_cover_edition_id: Float
  default_ebook_edition_id: Float
  default_physical_edition_id: Float
  editions_count: Float
  featured_book_series_id: Float
  header_image_id: Float
  id: Float
  image_id: Float
  import_platform_id: Float
  journals_count: Float
  lists_count: Float
  literary_type_id: Float
  pages: Float
  prompts_count: Float
  rating: Float
  ratings_count: Float
  release_year: Float
  reviews_count: Float
  users_count: Float
  users_read_count: Float
}

"""
order by var_samp() on columns of table "books"
"""
input books_var_samp_order_by {
  activities_count: order_by
  audio_seconds: order_by
  book_category_id: order_by
  book_status_id: order_by
  canonical_id: order_by
  created_by_user_id: order_by
  default_audio_edition_id: order_by
  default_cover_edition_id: order_by
  default_ebook_edition_id: order_by
  default_physical_edition_id: order_by
  editions_count: order_by
  featured_book_series_id: order_by
  header_image_id: order_by
  id: order_by
  image_id: order_by
  import_platform_id: order_by
  journals_count: order_by
  lists_count: order_by
  literary_type_id: order_by
  pages: order_by
  prompts_count: order_by
  rating: order_by
  ratings_count: order_by
  release_year: order_by
  reviews_count: order_by
  users_count: order_by
  users_read_count: order_by
}

"""
aggregate variance on columns
"""
type books_variance_fields {
  activities_count: Float
  audio_seconds: Float
  book_category_id: Float
  book_status_id: Float
  canonical_id: Float
  created_by_user_id: Float
  default_audio_edition_id: Float
  default_cover_edition_id: Float
  default_ebook_edition_id: Float
  default_physical_edition_id: Float
  editions_count: Float
  featured_book_series_id: Float
  header_image_id: Float
  id: Float
  image_id: Float
  import_platform_id: Float
  journals_count: Float
  lists_count: Float
  literary_type_id: Float
  pages: Float
  prompts_count: Float
  rating: Float
  ratings_count: Float
  release_year: Float
  reviews_count: Float
  users_count: Float
  users_read_count: Float
}

"""
order by variance() on columns of table "books"
"""
input books_variance_order_by {
  activities_count: order_by
  audio_seconds: order_by
  book_category_id: order_by
  book_status_id: order_by
  canonical_id: order_by
  created_by_user_id: order_by
  default_audio_edition_id: order_by
  default_cover_edition_id: order_by
  default_ebook_edition_id: order_by
  default_physical_edition_id: order_by
  editions_count: order_by
  featured_book_series_id: order_by
  header_image_id: order_by
  id: order_by
  image_id: order_by
  import_platform_id: order_by
  journals_count: order_by
  lists_count: order_by
  literary_type_id: order_by
  pages: order_by
  prompts_count: order_by
  rating: order_by
  ratings_count: order_by
  release_year: order_by
  reviews_count: order_by
  users_count: order_by
  users_read_count: order_by
}

"""
columns and relationships of "characters"
"""
type characters {
  biography: String
  book_characters: [book_characters!]!
  books_count: Int!
  cached_tags: json!
  canonical: characters
  canonical_books_count: Int!
  canonical_id: Int
  contributions: [contributions!]!
  contributions_aggregate: contributions_aggregate!
  created_at: timestamp!
  gender_id: bigint
  has_disability: Boolean
  id: bigint!
  image_id: Int
  is_lgbtq: Boolean
  is_poc: Boolean
  locked: Boolean
  name: String!
  object_type: String!
  openlibrary_url: String
  slug: String!
  state: String!
  updated_at: timestamp!
  user_id: Int
}

"""
Boolean expression to filter rows from the table "characters". All fields are combined with a logical 'AND'.
"""
input characters_bool_exp {
  _and: [characters_bool_exp!]
  _not: characters_bool_exp
  _or: [characters_bool_exp!]
  biography: String_comparison_exp
  book_characters: book_characters_bool_exp
  books_count: Int_comparison_exp
  cached_tags: json_comparison_exp
  canonical: characters_bool_exp
  canonical_books_count: Int_comparison_exp
  canonical_id: Int_comparison_exp
  contributions: contributions_bool_exp
  contributions_aggregate: contributions_aggregate_bool_exp
  created_at: timestamp_comparison_exp
  gender_id: bigint_comparison_exp
  has_disability: Boolean_comparison_exp
  id: bigint_comparison_exp
  image_id: Int_comparison_exp
  is_lgbtq: Boolean_comparison_exp
  is_poc: Boolean_comparison_exp
  locked: Boolean_comparison_exp
  name: String_comparison_exp
  object_type: String_comparison_exp
  openlibrary_url: String_comparison_exp
  slug: String_comparison_exp
  state: String_comparison_exp
  updated_at: timestamp_comparison_exp
  user_id: Int_comparison_exp
}

"""
Ordering options when selecting data from "characters".
"""
input characters_order_by {
  biography: order_by
  book_characters_aggregate: book_characters_aggregate_order_by
  books_count: order_by
  cached_tags: order_by
  canonical: characters_order_by
  canonical_books_count: order_by
  canonical_id: order_by
  contributions_aggregate: contributions_aggregate_order_by
  created_at: order_by
  gender_id: order_by
  has_disability: order_by
  id: order_by
  image_id: order_by
  is_lgbtq: order_by
  is_poc: order_by
  locked: order_by
  name: order_by
  object_type: order_by
  openlibrary_url: order_by
  slug: order_by
  state: order_by
  updated_at: order_by
  user_id: order_by
}

"""
select columns of table "characters"
"""
enum characters_select_column {
  biography
  books_count
  cached_tags
  canonical_books_count
  canonical_id
  created_at
  gender_id
  has_disability
  id
  image_id
  is_lgbtq
  is_poc
  locked
  name
  object_type
  openlibrary_url
  slug
  state
  updated_at
  user_id
}

"""
Streaming cursor of the table "characters"
"""
input characters_stream_cursor_input {
  initial_value: characters_stream_cursor_value_input!
  ordering: cursor_ordering
}

"""
Initial value of the column from where the streaming should start
"""
input characters_stream_cursor_value_input {
  biography: String
  books_count: Int
  cached_tags: json
  canonical_books_count: Int
  canonical_id: Int
  created_at: timestamp
  gender_id: bigint
  has_disability: Boolean
  id: bigint
  image_id: Int
  is_lgbtq: Boolean
  is_poc: Boolean
  locked: Boolean
  name: String
  object_type: String
  openlibrary_url: String
  slug: String
  state: String
  updated_at: timestamp
  user_id: Int
}

scalar citext

"""
Boolean expression to compare columns of type "citext". All fields are combined with logical 'AND'.
"""
input citext_comparison_exp {
  _eq: citext
  _gt: citext
  _gte: citext
  _ilike: citext
  _in: [citext!]
  _iregex: citext
  _is_null: Boolean
  _like: citext
  _lt: citext
  _lte: citext
  _neq: citext
  _nilike: citext
  _nin: [citext!]
  _niregex: citext
  _nlike: citext
  _nregex: citext
  _nsimilar: citext
  _regex: citext
  _similar: citext
}

"""
columns and relationships of "collection_import_results"
"""
type collection_import_results {
  author: String
  book: books
  book_found_method: String
  book_id: Int
  collection_import: collection_imports!
  collection_import_id: Int!
  contents: jsonb!
  external_id: String!
  id: Int!
  report: Int
  state: String!
  title: String!
}

"""
order by aggregate values of table "collection_import_results"
"""
input collection_import_results_aggregate_order_by {
  avg: collection_import_results_avg_order_by
  count: order_by
  max: collection_import_results_max_order_by
  min: collection_import_results_min_order_by
  stddev: collection_import_results_stddev_order_by
  stddev_pop: collection_import_results_stddev_pop_order_by
  stddev_samp: collection_import_results_stddev_samp_order_by
  sum: collection_import_results_sum_order_by
  var_pop: collection_import_results_var_pop_order_by
  var_samp: collection_import_results_var_samp_order_by
  variance: collection_import_results_variance_order_by
}

"""
order by avg() on columns of table "collection_import_results"
"""
input collection_import_results_avg_order_by {
  book_id: order_by
  collection_import_id: order_by
  id: order_by
  report: order_by
}

"""
Boolean expression to filter rows from the table "collection_import_results". All fields are combined with a logical 'AND'.
"""
input collection_import_results_bool_exp {
  _and: [collection_import_results_bool_exp!]
  _not: collection_import_results_bool_exp
  _or: [collection_import_results_bool_exp!]
  author: String_comparison_exp
  book: books_bool_exp
  book_found_method: String_comparison_exp
  book_id: Int_comparison_exp
  collection_import: collection_imports_bool_exp
  collection_import_id: Int_comparison_exp
  contents: jsonb_comparison_exp
  external_id: String_comparison_exp
  id: Int_comparison_exp
  report: Int_comparison_exp
  state: String_comparison_exp
  title: String_comparison_exp
}

"""
input type for incrementing numeric columns in table "collection_import_results"
"""
input collection_import_results_inc_input {
  report: Int
}

"""
order by max() on columns of table "collection_import_results"
"""
input collection_import_results_max_order_by {
  author: order_by
  book_found_method: order_by
  book_id: order_by
  collection_import_id: order_by
  external_id: order_by
  id: order_by
  report: order_by
  state: order_by
  title: order_by
}

"""
order by min() on columns of table "collection_import_results"
"""
input collection_import_results_min_order_by {
  author: order_by
  book_found_method: order_by
  book_id: order_by
  collection_import_id: order_by
  external_id: order_by
  id: order_by
  report: order_by
  state: order_by
  title: order_by
}

"""
response of any mutation on the table "collection_import_results"
"""
type collection_import_results_mutation_response {
  affected_rows: Int!
  returning: [collection_import_results!]!
}

"""
Ordering options when selecting data from "collection_import_results".
"""
input collection_import_results_order_by {
  author: order_by
  book: books_order_by
  book_found_method: order_by
  book_id: order_by
  collection_import: collection_imports_order_by
  collection_import_id: order_by
  contents: order_by
  external_id: order_by
  id: order_by
  report: order_by
  state: order_by
  title: order_by
}

"""
primary key columns input for table: collection_import_results
"""
input collection_import_results_pk_columns_input {
  id: Int!
}

"""
select columns of table "collection_import_results"
"""
enum collection_import_results_select_column {
  author
  book_found_method
  book_id
  collection_import_id
  contents
  external_id
  id
  report
  state
  title
}

"""
input type for updating data in table "collection_import_results"
"""
input collection_import_results_set_input {
  report: Int
  state: String
}

"""
order by stddev() on columns of table "collection_import_results"
"""
input collection_import_results_stddev_order_by {
  book_id: order_by
  collection_import_id: order_by
  id: order_by
  report: order_by
}

"""
order by stddev_pop() on columns of table "collection_import_results"
"""
input collection_import_results_stddev_pop_order_by {
  book_id: order_by
  collection_import_id: order_by
  id: order_by
  report: order_by
}

"""
order by stddev_samp() on columns of table "collection_import_results"
"""
input collection_import_results_stddev_samp_order_by {
  book_id: order_by
  collection_import_id: order_by
  id: order_by
  report: order_by
}

"""
Streaming cursor of the table "collection_import_results"
"""
input collection_import_results_stream_cursor_input {
  initial_value: collection_import_results_stream_cursor_value_input!
  ordering: cursor_ordering
}

"""
Initial value of the column from where the streaming should start
"""
input collection_import_results_stream_cursor_value_input {
  author: String
  book_found_method: String
  book_id: Int
  collection_import_id: Int
  contents: jsonb
  external_id: String
  id: Int
  report: Int
  state: String
  title: String
}

"""
order by sum() on columns of table "collection_import_results"
"""
input collection_import_results_sum_order_by {
  book_id: order_by
  collection_import_id: order_by
  id: order_by
  report: order_by
}

input collection_import_results_updates {
  _inc: collection_import_results_inc_input
  _set: collection_import_results_set_input
  where: collection_import_results_bool_exp!
}

"""
order by var_pop() on columns of table "collection_import_results"
"""
input collection_import_results_var_pop_order_by {
  book_id: order_by
  collection_import_id: order_by
  id: order_by
  report: order_by
}

"""
order by var_samp() on columns of table "collection_import_results"
"""
input collection_import_results_var_samp_order_by {
  book_id: order_by
  collection_import_id: order_by
  id: order_by
  report: order_by
}

"""
order by variance() on columns of table "collection_import_results"
"""
input collection_import_results_variance_order_by {
  book_id: order_by
  collection_import_id: order_by
  id: order_by
  report: order_by
}

"""
columns and relationships of "collection_imports"
"""
type collection_imports {
  collection_import_results: [collection_import_results!]!
  completed_at: timestamptz
  contents_key: String
  created_at: timestamptz
  current_book: String
  error_message: String
  failure_count: Int!
  id: Int!
  override_date_read: Boolean
  override_ratings: Boolean!
  override_shelves: Boolean!
  platform_id: Int
  processed_count: Int!
  reimport_count: Int!
  started_at: timestamptz
  state: String!
  success_count: Int!
  tag_resolution: Int!
  total_count: Int!
  updated_at: timestamptz
  user: users!
  user_id: Int!
}

"""
order by aggregate values of table "collection_imports"
"""
input collection_imports_aggregate_order_by {
  avg: collection_imports_avg_order_by
  count: order_by
  max: collection_imports_max_order_by
  min: collection_imports_min_order_by
  stddev: collection_imports_stddev_order_by
  stddev_pop: collection_imports_stddev_pop_order_by
  stddev_samp: collection_imports_stddev_samp_order_by
  sum: collection_imports_sum_order_by
  var_pop: collection_imports_var_pop_order_by
  var_samp: collection_imports_var_samp_order_by
  variance: collection_imports_variance_order_by
}

"""
order by avg() on columns of table "collection_imports"
"""
input collection_imports_avg_order_by {
  failure_count: order_by
  id: order_by
  platform_id: order_by
  processed_count: order_by
  reimport_count: order_by
  success_count: order_by
  tag_resolution: order_by
  total_count: order_by
  user_id: order_by
}

"""
Boolean expression to filter rows from the table "collection_imports". All fields are combined with a logical 'AND'.
"""
input collection_imports_bool_exp {
  _and: [collection_imports_bool_exp!]
  _not: collection_imports_bool_exp
  _or: [collection_imports_bool_exp!]
  collection_import_results: collection_import_results_bool_exp
  completed_at: timestamptz_comparison_exp
  contents_key: String_comparison_exp
  created_at: timestamptz_comparison_exp
  current_book: String_comparison_exp
  error_message: String_comparison_exp
  failure_count: Int_comparison_exp
  id: Int_comparison_exp
  override_date_read: Boolean_comparison_exp
  override_ratings: Boolean_comparison_exp
  override_shelves: Boolean_comparison_exp
  platform_id: Int_comparison_exp
  processed_count: Int_comparison_exp
  reimport_count: Int_comparison_exp
  started_at: timestamptz_comparison_exp
  state: String_comparison_exp
  success_count: Int_comparison_exp
  tag_resolution: Int_comparison_exp
  total_count: Int_comparison_exp
  updated_at: timestamptz_comparison_exp
  user: users_bool_exp
  user_id: Int_comparison_exp
}

"""
order by max() on columns of table "collection_imports"
"""
input collection_imports_max_order_by {
  completed_at: order_by
  contents_key: order_by
  created_at: order_by
  current_book: order_by
  error_message: order_by
  failure_count: order_by
  id: order_by
  platform_id: order_by
  processed_count: order_by
  reimport_count: order_by
  started_at: order_by
  state: order_by
  success_count: order_by
  tag_resolution: order_by
  total_count: order_by
  updated_at: order_by
  user_id: order_by
}

"""
order by min() on columns of table "collection_imports"
"""
input collection_imports_min_order_by {
  completed_at: order_by
  contents_key: order_by
  created_at: order_by
  current_book: order_by
  error_message: order_by
  failure_count: order_by
  id: order_by
  platform_id: order_by
  processed_count: order_by
  reimport_count: order_by
  started_at: order_by
  state: order_by
  success_count: order_by
  tag_resolution: order_by
  total_count: order_by
  updated_at: order_by
  user_id: order_by
}

"""
Ordering options when selecting data from "collection_imports".
"""
input collection_imports_order_by {
  collection_import_results_aggregate: collection_import_results_aggregate_order_by
  completed_at: order_by
  contents_key: order_by
  created_at: order_by
  current_book: order_by
  error_message: order_by
  failure_count: order_by
  id: order_by
  override_date_read: order_by
  override_ratings: order_by
  override_shelves: order_by
  platform_id: order_by
  processed_count: order_by
  reimport_count: order_by
  started_at: order_by
  state: order_by
  success_count: order_by
  tag_resolution: order_by
  total_count: order_by
  updated_at: order_by
  user: users_order_by
  user_id: order_by
}

"""
select columns of table "collection_imports"
"""
enum collection_imports_select_column {
  completed_at
  contents_key
  created_at
  current_book
  error_message
  failure_count
  id
  override_date_read
  override_ratings
  override_shelves
  platform_id
  processed_count
  reimport_count
  started_at
  state
  success_count
  tag_resolution
  total_count
  updated_at
  user_id
}

"""
order by stddev() on columns of table "collection_imports"
"""
input collection_imports_stddev_order_by {
  failure_count: order_by
  id: order_by
  platform_id: order_by
  processed_count: order_by
  reimport_count: order_by
  success_count: order_by
  tag_resolution: order_by
  total_count: order_by
  user_id: order_by
}

"""
order by stddev_pop() on columns of table "collection_imports"
"""
input collection_imports_stddev_pop_order_by {
  failure_count: order_by
  id: order_by
  platform_id: order_by
  processed_count: order_by
  reimport_count: order_by
  success_count: order_by
  tag_resolution: order_by
  total_count: order_by
  user_id: order_by
}

"""
order by stddev_samp() on columns of table "collection_imports"
"""
input collection_imports_stddev_samp_order_by {
  failure_count: order_by
  id: order_by
  platform_id: order_by
  processed_count: order_by
  reimport_count: order_by
  success_count: order_by
  tag_resolution: order_by
  total_count: order_by
  user_id: order_by
}

"""
Streaming cursor of the table "collection_imports"
"""
input collection_imports_stream_cursor_input {
  initial_value: collection_imports_stream_cursor_value_input!
  ordering: cursor_ordering
}

"""
Initial value of the column from where the streaming should start
"""
input collection_imports_stream_cursor_value_input {
  completed_at: timestamptz
  contents_key: String
  created_at: timestamptz
  current_book: String
  error_message: String
  failure_count: Int
  id: Int
  override_date_read: Boolean
  override_ratings: Boolean
  override_shelves: Boolean
  platform_id: Int
  processed_count: Int
  reimport_count: Int
  started_at: timestamptz
  state: String
  success_count: Int
  tag_resolution: Int
  total_count: Int
  updated_at: timestamptz
  user_id: Int
}

"""
order by sum() on columns of table "collection_imports"
"""
input collection_imports_sum_order_by {
  failure_count: order_by
  id: order_by
  platform_id: order_by
  processed_count: order_by
  reimport_count: order_by
  success_count: order_by
  tag_resolution: order_by
  total_count: order_by
  user_id: order_by
}

"""
order by var_pop() on columns of table "collection_imports"
"""
input collection_imports_var_pop_order_by {
  failure_count: order_by
  id: order_by
  platform_id: order_by
  processed_count: order_by
  reimport_count: order_by
  success_count: order_by
  tag_resolution: order_by
  total_count: order_by
  user_id: order_by
}

"""
order by var_samp() on columns of table "collection_imports"
"""
input collection_imports_var_samp_order_by {
  failure_count: order_by
  id: order_by
  platform_id: order_by
  processed_count: order_by
  reimport_count: order_by
  success_count: order_by
  tag_resolution: order_by
  total_count: order_by
  user_id: order_by
}

"""
order by variance() on columns of table "collection_imports"
"""
input collection_imports_variance_order_by {
  failure_count: order_by
  id: order_by
  platform_id: order_by
  processed_count: order_by
  reimport_count: order_by
  success_count: order_by
  tag_resolution: order_by
  total_count: order_by
  user_id: order_by
}

"""
columns and relationships of "contributions"
"""
type contributions {
  author: authors
  author_id: Int!
  book: books
  contributable_id: Int!
  contributable_type: String!
  contribution: String
  created_at: timestamp!
  id: bigint!
  updated_at: timestamp!
}

"""
aggregated selection of "contributions"
"""
type contributions_aggregate {
  aggregate: contributions_aggregate_fields
  nodes: [contributions!]!
}

input contributions_aggregate_bool_exp {
  count: contributions_aggregate_bool_exp_count
}

input contributions_aggregate_bool_exp_count {
  arguments: [contributions_select_column!]
  distinct: Boolean
  filter: contributions_bool_exp
  predicate: Int_comparison_exp!
}

"""
aggregate fields of "contributions"
"""
type contributions_aggregate_fields {
  avg: contributions_avg_fields
  count: Int!
  max: contributions_max_fields
  min: contributions_min_fields
  stddev: contributions_stddev_fields
  stddev_pop: contributions_stddev_pop_fields
  stddev_samp: contributions_stddev_samp_fields
  sum: contributions_sum_fields
  var_pop: contributions_var_pop_fields
  var_samp: contributions_var_samp_fields
  variance: contributions_variance_fields
}

"""
order by aggregate values of table "contributions"
"""
input contributions_aggregate_order_by {
  avg: contributions_avg_order_by
  count: order_by
  max: contributions_max_order_by
  min: contributions_min_order_by
  stddev: contributions_stddev_order_by
  stddev_pop: contributions_stddev_pop_order_by
  stddev_samp: contributions_stddev_samp_order_by
  sum: contributions_sum_order_by
  var_pop: contributions_var_pop_order_by
  var_samp: contributions_var_samp_order_by
  variance: contributions_variance_order_by
}

"""
aggregate avg on columns
"""
type contributions_avg_fields {
  author_id: Float
  contributable_id: Float
  id: Float
}

"""
order by avg() on columns of table "contributions"
"""
input contributions_avg_order_by {
  author_id: order_by
  contributable_id: order_by
  id: order_by
}

"""
Boolean expression to filter rows from the table "contributions". All fields are combined with a logical 'AND'.
"""
input contributions_bool_exp {
  _and: [contributions_bool_exp!]
  _not: contributions_bool_exp
  _or: [contributions_bool_exp!]
  author: authors_bool_exp
  author_id: Int_comparison_exp
  book: books_bool_exp
  contributable_id: Int_comparison_exp
  contributable_type: String_comparison_exp
  contribution: String_comparison_exp
  created_at: timestamp_comparison_exp
  id: bigint_comparison_exp
  updated_at: timestamp_comparison_exp
}

"""
aggregate max on columns
"""
type contributions_max_fields {
  author_id: Int
  contributable_id: Int
  contributable_type: String
  contribution: String
  created_at: timestamp
  id: bigint
  updated_at: timestamp
}

"""
order by max() on columns of table "contributions"
"""
input contributions_max_order_by {
  author_id: order_by
  contributable_id: order_by
  contributable_type: order_by
  contribution: order_by
  created_at: order_by
  id: order_by
  updated_at: order_by
}

"""
aggregate min on columns
"""
type contributions_min_fields {
  author_id: Int
  contributable_id: Int
  contributable_type: String
  contribution: String
  created_at: timestamp
  id: bigint
  updated_at: timestamp
}

"""
order by min() on columns of table "contributions"
"""
input contributions_min_order_by {
  author_id: order_by
  contributable_id: order_by
  contributable_type: order_by
  contribution: order_by
  created_at: order_by
  id: order_by
  updated_at: order_by
}

"""
Ordering options when selecting data from "contributions".
"""
input contributions_order_by {
  author: authors_order_by
  author_id: order_by
  book: books_order_by
  contributable_id: order_by
  contributable_type: order_by
  contribution: order_by
  created_at: order_by
  id: order_by
  updated_at: order_by
}

"""
select columns of table "contributions"
"""
enum contributions_select_column {
  author_id
  contributable_id
  contributable_type
  contribution
  created_at
  id
  updated_at
}

"""
aggregate stddev on columns
"""
type contributions_stddev_fields {
  author_id: Float
  contributable_id: Float
  id: Float
}

"""
order by stddev() on columns of table "contributions"
"""
input contributions_stddev_order_by {
  author_id: order_by
  contributable_id: order_by
  id: order_by
}

"""
aggregate stddev_pop on columns
"""
type contributions_stddev_pop_fields {
  author_id: Float
  contributable_id: Float
  id: Float
}

"""
order by stddev_pop() on columns of table "contributions"
"""
input contributions_stddev_pop_order_by {
  author_id: order_by
  contributable_id: order_by
  id: order_by
}

"""
aggregate stddev_samp on columns
"""
type contributions_stddev_samp_fields {
  author_id: Float
  contributable_id: Float
  id: Float
}

"""
order by stddev_samp() on columns of table "contributions"
"""
input contributions_stddev_samp_order_by {
  author_id: order_by
  contributable_id: order_by
  id: order_by
}

"""
Streaming cursor of the table "contributions"
"""
input contributions_stream_cursor_input {
  initial_value: contributions_stream_cursor_value_input!
  ordering: cursor_ordering
}

"""
Initial value of the column from where the streaming should start
"""
input contributions_stream_cursor_value_input {
  author_id: Int
  contributable_id: Int
  contributable_type: String
  contribution: String
  created_at: timestamp
  id: bigint
  updated_at: timestamp
}

"""
aggregate sum on columns
"""
type contributions_sum_fields {
  author_id: Int
  contributable_id: Int
  id: bigint
}

"""
order by sum() on columns of table "contributions"
"""
input contributions_sum_order_by {
  author_id: order_by
  contributable_id: order_by
  id: order_by
}

"""
aggregate var_pop on columns
"""
type contributions_var_pop_fields {
  author_id: Float
  contributable_id: Float
  id: Float
}

"""
order by var_pop() on columns of table "contributions"
"""
input contributions_var_pop_order_by {
  author_id: order_by
  contributable_id: order_by
  id: order_by
}

"""
aggregate var_samp on columns
"""
type contributions_var_samp_fields {
  author_id: Float
  contributable_id: Float
  id: Float
}

"""
order by var_samp() on columns of table "contributions"
"""
input contributions_var_samp_order_by {
  author_id: order_by
  contributable_id: order_by
  id: order_by
}

"""
aggregate variance on columns
"""
type contributions_variance_fields {
  author_id: Float
  contributable_id: Float
  id: Float
}

"""
order by variance() on columns of table "contributions"
"""
input contributions_variance_order_by {
  author_id: order_by
  contributable_id: order_by
  id: order_by
}

"""
columns and relationships of "countries"
"""
type countries {
  code2: String
  code3: String
  created_at: timestamp!
  editions: [editions!]!
  id: bigint!
  intermediate_region: String
  intermediate_region_code: String
  iso_3166: String
  name: String
  phone_code: String
  region: String
  region_code: String
  sub_region: String
  sub_region_code: String
  updated_at: timestamp!
}

"""
Boolean expression to filter rows from the table "countries". All fields are combined with a logical 'AND'.
"""
input countries_bool_exp {
  _and: [countries_bool_exp!]
  _not: countries_bool_exp
  _or: [countries_bool_exp!]
  code2: String_comparison_exp
  code3: String_comparison_exp
  created_at: timestamp_comparison_exp
  editions: editions_bool_exp
  id: bigint_comparison_exp
  intermediate_region: String_comparison_exp
  intermediate_region_code: String_comparison_exp
  iso_3166: String_comparison_exp
  name: String_comparison_exp
  phone_code: String_comparison_exp
  region: String_comparison_exp
  region_code: String_comparison_exp
  sub_region: String_comparison_exp
  sub_region_code: String_comparison_exp
  updated_at: timestamp_comparison_exp
}

"""
Ordering options when selecting data from "countries".
"""
input countries_order_by {
  code2: order_by
  code3: order_by
  created_at: order_by
  editions_aggregate: editions_aggregate_order_by
  id: order_by
  intermediate_region: order_by
  intermediate_region_code: order_by
  iso_3166: order_by
  name: order_by
  phone_code: order_by
  region: order_by
  region_code: order_by
  sub_region: order_by
  sub_region_code: order_by
  updated_at: order_by
}

"""
select columns of table "countries"
"""
enum countries_select_column {
  code2
  code3
  created_at
  id
  intermediate_region
  intermediate_region_code
  iso_3166
  name
  phone_code
  region
  region_code
  sub_region
  sub_region_code
  updated_at
}

"""
Streaming cursor of the table "countries"
"""
input countries_stream_cursor_input {
  initial_value: countries_stream_cursor_value_input!
  ordering: cursor_ordering
}

"""
Initial value of the column from where the streaming should start
"""
input countries_stream_cursor_value_input {
  code2: String
  code3: String
  created_at: timestamp
  id: bigint
  intermediate_region: String
  intermediate_region_code: String
  iso_3166: String
  name: String
  phone_code: String
  region: String
  region_code: String
  sub_region: String
  sub_region_code: String
  updated_at: timestamp
}

"""
ordering argument of a cursor
"""
enum cursor_ordering {
  ASC
  DESC
}

scalar date

"""
Boolean expression to compare columns of type "date". All fields are combined with logical 'AND'.
"""
input date_comparison_exp {
  _eq: date
  _gt: date
  _gte: date
  _in: [date!]
  _is_null: Boolean
  _lt: date
  _lte: date
  _neq: date
  _nin: [date!]
}

"""
columns and relationships of "editions"
"""
type editions {
  alternative_titles: json!
  asin: String
  audio_seconds: Int
  book: books!
  book_id: Int!
  book_mappings: [book_mappings!]!
  cached_contributors: json!
  cached_image: jsonb!
  cached_tags: json!
  compilation: Boolean!
  contributions: [contributions!]!
  contributions_aggregate: contributions_aggregate!
  country: countries
  country_id: Int
  created_at: timestamp!
  created_by_user_id: Int
  dto: json!
  dto_combined: json!
  dto_external: json!
  edition_format: String
  edition_information: String
  id: Int!
  image: images
  image_id: Int
  images: [images!]!
  isbn_10: String
  isbn_13: String
  language: languages
  language_id: Int
  list_books: [list_books!]!
  list_books_aggregate: list_books_aggregate!
  lists_count: Int!
  locked: Boolean!
  normalized_at: timestamp
  object_type: String!
  original_book_id: Int
  pages: Int
  physical_format: String
  physical_information: String
  publisher: publishers
  publisher_id: Int
  rating: numeric
  reading_format: reading_formats
  reading_format_id: Int!
  release_date: date
  release_year: Int
  score: Int!
  source: String
  state: String!
  subtitle: String
  title: String
  updated_at: timestamp!
  user_added: Boolean!
  users_count: Int!
  users_read_count: Int!
}

"""
order by aggregate values of table "editions"
"""
input editions_aggregate_order_by {
  avg: editions_avg_order_by
  count: order_by
  max: editions_max_order_by
  min: editions_min_order_by
  stddev: editions_stddev_order_by
  stddev_pop: editions_stddev_pop_order_by
  stddev_samp: editions_stddev_samp_order_by
  sum: editions_sum_order_by
  var_pop: editions_var_pop_order_by
  var_samp: editions_var_samp_order_by
  variance: editions_variance_order_by
}

"""
order by avg() on columns of table "editions"
"""
input editions_avg_order_by {
  audio_seconds: order_by
  book_id: order_by
  country_id: order_by
  created_by_user_id: order_by
  id: order_by
  image_id: order_by
  language_id: order_by
  lists_count: order_by
  original_book_id: order_by
  pages: order_by
  publisher_id: order_by
  rating: order_by
  reading_format_id: order_by
  release_year: order_by
  score: order_by
  users_count: order_by
  users_read_count: order_by
}

"""
Boolean expression to filter rows from the table "editions". All fields are combined with a logical 'AND'.
"""
input editions_bool_exp {
  _and: [editions_bool_exp!]
  _not: editions_bool_exp
  _or: [editions_bool_exp!]
  alternative_titles: json_comparison_exp
  asin: String_comparison_exp
  audio_seconds: Int_comparison_exp
  book: books_bool_exp
  book_id: Int_comparison_exp
  book_mappings: book_mappings_bool_exp
  cached_contributors: json_comparison_exp
  cached_image: jsonb_comparison_exp
  cached_tags: json_comparison_exp
  compilation: Boolean_comparison_exp
  contributions: contributions_bool_exp
  contributions_aggregate: contributions_aggregate_bool_exp
  country: countries_bool_exp
  country_id: Int_comparison_exp
  created_at: timestamp_comparison_exp
  created_by_user_id: Int_comparison_exp
  dto: json_comparison_exp
  dto_combined: json_comparison_exp
  dto_external: json_comparison_exp
  edition_format: String_comparison_exp
  edition_information: String_comparison_exp
  id: Int_comparison_exp
  image: images_bool_exp
  image_id: Int_comparison_exp
  images: images_bool_exp
  isbn_10: String_comparison_exp
  isbn_13: String_comparison_exp
  language: languages_bool_exp
  language_id: Int_comparison_exp
  list_books: list_books_bool_exp
  list_books_aggregate: list_books_aggregate_bool_exp
  lists_count: Int_comparison_exp
  locked: Boolean_comparison_exp
  normalized_at: timestamp_comparison_exp
  object_type: String_comparison_exp
  original_book_id: Int_comparison_exp
  pages: Int_comparison_exp
  physical_format: String_comparison_exp
  physical_information: String_comparison_exp
  publisher: publishers_bool_exp
  publisher_id: Int_comparison_exp
  rating: numeric_comparison_exp
  reading_format: reading_formats_bool_exp
  reading_format_id: Int_comparison_exp
  release_date: date_comparison_exp
  release_year: Int_comparison_exp
  score: Int_comparison_exp
  source: String_comparison_exp
  state: String_comparison_exp
  subtitle: String_comparison_exp
  title: String_comparison_exp
  updated_at: timestamp_comparison_exp
  user_added: Boolean_comparison_exp
  users_count: Int_comparison_exp
  users_read_count: Int_comparison_exp
}

"""
order by max() on columns of table "editions"
"""
input editions_max_order_by {
  asin: order_by
  audio_seconds: order_by
  book_id: order_by
  country_id: order_by
  created_at: order_by
  created_by_user_id: order_by
  edition_format: order_by
  edition_information: order_by
  id: order_by
  image_id: order_by
  isbn_10: order_by
  isbn_13: order_by
  language_id: order_by
  lists_count: order_by
  normalized_at: order_by
  object_type: order_by
  original_book_id: order_by
  pages: order_by
  physical_format: order_by
  physical_information: order_by
  publisher_id: order_by
  rating: order_by
  reading_format_id: order_by
  release_date: order_by
  release_year: order_by
  score: order_by
  source: order_by
  state: order_by
  subtitle: order_by
  title: order_by
  updated_at: order_by
  users_count: order_by
  users_read_count: order_by
}

"""
order by min() on columns of table "editions"
"""
input editions_min_order_by {
  asin: order_by
  audio_seconds: order_by
  book_id: order_by
  country_id: order_by
  created_at: order_by
  created_by_user_id: order_by
  edition_format: order_by
  edition_information: order_by
  id: order_by
  image_id: order_by
  isbn_10: order_by
  isbn_13: order_by
  language_id: order_by
  lists_count: order_by
  normalized_at: order_by
  object_type: order_by
  original_book_id: order_by
  pages: order_by
  physical_format: order_by
  physical_information: order_by
  publisher_id: order_by
  rating: order_by
  reading_format_id: order_by
  release_date: order_by
  release_year: order_by
  score: order_by
  source: order_by
  state: order_by
  subtitle: order_by
  title: order_by
  updated_at: order_by
  users_count: order_by
  users_read_count: order_by
}

"""
Ordering options when selecting data from "editions".
"""
input editions_order_by {
  alternative_titles: order_by
  asin: order_by
  audio_seconds: order_by
  book: books_order_by
  book_id: order_by
  book_mappings_aggregate: book_mappings_aggregate_order_by
  cached_contributors: order_by
  cached_image: order_by
  cached_tags: order_by
  compilation: order_by
  contributions_aggregate: contributions_aggregate_order_by
  country: countries_order_by
  country_id: order_by
  created_at: order_by
  created_by_user_id: order_by
  dto: order_by
  dto_combined: order_by
  dto_external: order_by
  edition_format: order_by
  edition_information: order_by
  id: order_by
  image: images_order_by
  image_id: order_by
  images_aggregate: images_aggregate_order_by
  isbn_10: order_by
  isbn_13: order_by
  language: languages_order_by
  language_id: order_by
  list_books_aggregate: list_books_aggregate_order_by
  lists_count: order_by
  locked: order_by
  normalized_at: order_by
  object_type: order_by
  original_book_id: order_by
  pages: order_by
  physical_format: order_by
  physical_information: order_by
  publisher: publishers_order_by
  publisher_id: order_by
  rating: order_by
  reading_format: reading_formats_order_by
  reading_format_id: order_by
  release_date: order_by
  release_year: order_by
  score: order_by
  source: order_by
  state: order_by
  subtitle: order_by
  title: order_by
  updated_at: order_by
  user_added: order_by
  users_count: order_by
  users_read_count: order_by
}

"""
select columns of table "editions"
"""
enum editions_select_column {
  alternative_titles
  asin
  audio_seconds
  book_id
  cached_contributors
  cached_image
  cached_tags
  compilation
  country_id
  created_at
  created_by_user_id
  dto
  dto_combined
  dto_external
  edition_format
  edition_information
  id
  image_id
  isbn_10
  isbn_13
  language_id
  lists_count
  locked
  normalized_at
  object_type
  original_book_id
  pages
  physical_format
  physical_information
  publisher_id
  rating
  reading_format_id
  release_date
  release_year
  score
  source
  state
  subtitle
  title
  updated_at
  user_added
  users_count
  users_read_count
}

"""
order by stddev() on columns of table "editions"
"""
input editions_stddev_order_by {
  audio_seconds: order_by
  book_id: order_by
  country_id: order_by
  created_by_user_id: order_by
  id: order_by
  image_id: order_by
  language_id: order_by
  lists_count: order_by
  original_book_id: order_by
  pages: order_by
  publisher_id: order_by
  rating: order_by
  reading_format_id: order_by
  release_year: order_by
  score: order_by
  users_count: order_by
  users_read_count: order_by
}

"""
order by stddev_pop() on columns of table "editions"
"""
input editions_stddev_pop_order_by {
  audio_seconds: order_by
  book_id: order_by
  country_id: order_by
  created_by_user_id: order_by
  id: order_by
  image_id: order_by
  language_id: order_by
  lists_count: order_by
  original_book_id: order_by
  pages: order_by
  publisher_id: order_by
  rating: order_by
  reading_format_id: order_by
  release_year: order_by
  score: order_by
  users_count: order_by
  users_read_count: order_by
}

"""
order by stddev_samp() on columns of table "editions"
"""
input editions_stddev_samp_order_by {
  audio_seconds: order_by
  book_id: order_by
  country_id: order_by
  created_by_user_id: order_by
  id: order_by
  image_id: order_by
  language_id: order_by
  lists_count: order_by
  original_book_id: order_by
  pages: order_by
  publisher_id: order_by
  rating: order_by
  reading_format_id: order_by
  release_year: order_by
  score: order_by
  users_count: order_by
  users_read_count: order_by
}

"""
Streaming cursor of the table "editions"
"""
input editions_stream_cursor_input {
  initial_value: editions_stream_cursor_value_input!
  ordering: cursor_ordering
}

"""
Initial value of the column from where the streaming should start
"""
input editions_stream_cursor_value_input {
  alternative_titles: json
  asin: String
  audio_seconds: Int
  book_id: Int
  cached_contributors: json
  cached_image: jsonb
  cached_tags: json
  compilation: Boolean
  country_id: Int
  created_at: timestamp
  created_by_user_id: Int
  dto: json
  dto_combined: json
  dto_external: json
  edition_format: String
  edition_information: String
  id: Int
  image_id: Int
  isbn_10: String
  isbn_13: String
  language_id: Int
  lists_count: Int
  locked: Boolean
  normalized_at: timestamp
  object_type: String
  original_book_id: Int
  pages: Int
  physical_format: String
  physical_information: String
  publisher_id: Int
  rating: numeric
  reading_format_id: Int
  release_date: date
  release_year: Int
  score: Int
  source: String
  state: String
  subtitle: String
  title: String
  updated_at: timestamp
  user_added: Boolean
  users_count: Int
  users_read_count: Int
}

"""
order by sum() on columns of table "editions"
"""
input editions_sum_order_by {
  audio_seconds: order_by
  book_id: order_by
  country_id: order_by
  created_by_user_id: order_by
  id: order_by
  image_id: order_by
  language_id: order_by
  lists_count: order_by
  original_book_id: order_by
  pages: order_by
  publisher_id: order_by
  rating: order_by
  reading_format_id: order_by
  release_year: order_by
  score: order_by
  users_count: order_by
  users_read_count: order_by
}

"""
order by var_pop() on columns of table "editions"
"""
input editions_var_pop_order_by {
  audio_seconds: order_by
  book_id: order_by
  country_id: order_by
  created_by_user_id: order_by
  id: order_by
  image_id: order_by
  language_id: order_by
  lists_count: order_by
  original_book_id: order_by
  pages: order_by
  publisher_id: order_by
  rating: order_by
  reading_format_id: order_by
  release_year: order_by
  score: order_by
  users_count: order_by
  users_read_count: order_by
}

"""
order by var_samp() on columns of table "editions"
"""
input editions_var_samp_order_by {
  audio_seconds: order_by
  book_id: order_by
  country_id: order_by
  created_by_user_id: order_by
  id: order_by
  image_id: order_by
  language_id: order_by
  lists_count: order_by
  original_book_id: order_by
  pages: order_by
  publisher_id: order_by
  rating: order_by
  reading_format_id: order_by
  release_year: order_by
  score: order_by
  users_count: order_by
  users_read_count: order_by
}

"""
order by variance() on columns of table "editions"
"""
input editions_variance_order_by {
  audio_seconds: order_by
  book_id: order_by
  country_id: order_by
  created_by_user_id: order_by
  id: order_by
  image_id: order_by
  language_id: order_by
  lists_count: order_by
  original_book_id: order_by
  pages: order_by
  publisher_id: order_by
  rating: order_by
  reading_format_id: order_by
  release_year: order_by
  score: order_by
  users_count: order_by
  users_read_count: order_by
}

"""
columns and relationships of "flag_statuses"
"""
type flag_statuses {
  id: Int!
  status: String!
  user_flags: [user_flags!]!
}

"""
Boolean expression to filter rows from the table "flag_statuses". All fields are combined with a logical 'AND'.
"""
input flag_statuses_bool_exp {
  _and: [flag_statuses_bool_exp!]
  _not: flag_statuses_bool_exp
  _or: [flag_statuses_bool_exp!]
  id: Int_comparison_exp
  status: String_comparison_exp
  user_flags: user_flags_bool_exp
}

"""
Ordering options when selecting data from "flag_statuses".
"""
input flag_statuses_order_by {
  id: order_by
  status: order_by
  user_flags_aggregate: user_flags_aggregate_order_by
}

"""
select columns of table "flag_statuses"
"""
enum flag_statuses_select_column {
  id
  status
}

"""
Streaming cursor of the table "flag_statuses"
"""
input flag_statuses_stream_cursor_input {
  initial_value: flag_statuses_stream_cursor_value_input!
  ordering: cursor_ordering
}

"""
Initial value of the column from where the streaming should start
"""
input flag_statuses_stream_cursor_value_input {
  id: Int
  status: String
}

scalar float8

"""
Boolean expression to compare columns of type "float8". All fields are combined with logical 'AND'.
"""
input float8_comparison_exp {
  _eq: float8
  _gt: float8
  _gte: float8
  _in: [float8!]
  _is_null: Boolean
  _lt: float8
  _lte: float8
  _neq: float8
  _nin: [float8!]
}

"""
columns and relationships of "followed_lists"
"""
type followed_lists {
  created_at: timestamptz!
  id: Int!
  list: lists!
  list_id: Int!
  user: users!
  user_id: Int!
}

"""
order by aggregate values of table "followed_lists"
"""
input followed_lists_aggregate_order_by {
  avg: followed_lists_avg_order_by
  count: order_by
  max: followed_lists_max_order_by
  min: followed_lists_min_order_by
  stddev: followed_lists_stddev_order_by
  stddev_pop: followed_lists_stddev_pop_order_by
  stddev_samp: followed_lists_stddev_samp_order_by
  sum: followed_lists_sum_order_by
  var_pop: followed_lists_var_pop_order_by
  var_samp: followed_lists_var_samp_order_by
  variance: followed_lists_variance_order_by
}

"""
order by avg() on columns of table "followed_lists"
"""
input followed_lists_avg_order_by {
  id: order_by
  list_id: order_by
  user_id: order_by
}

"""
Boolean expression to filter rows from the table "followed_lists". All fields are combined with a logical 'AND'.
"""
input followed_lists_bool_exp {
  _and: [followed_lists_bool_exp!]
  _not: followed_lists_bool_exp
  _or: [followed_lists_bool_exp!]
  created_at: timestamptz_comparison_exp
  id: Int_comparison_exp
  list: lists_bool_exp
  list_id: Int_comparison_exp
  user: users_bool_exp
  user_id: Int_comparison_exp
}

"""
order by max() on columns of table "followed_lists"
"""
input followed_lists_max_order_by {
  created_at: order_by
  id: order_by
  list_id: order_by
  user_id: order_by
}

"""
order by min() on columns of table "followed_lists"
"""
input followed_lists_min_order_by {
  created_at: order_by
  id: order_by
  list_id: order_by
  user_id: order_by
}

"""
Ordering options when selecting data from "followed_lists".
"""
input followed_lists_order_by {
  created_at: order_by
  id: order_by
  list: lists_order_by
  list_id: order_by
  user: users_order_by
  user_id: order_by
}

"""
select columns of table "followed_lists"
"""
enum followed_lists_select_column {
  created_at
  id
  list_id
  user_id
}

"""
order by stddev() on columns of table "followed_lists"
"""
input followed_lists_stddev_order_by {
  id: order_by
  list_id: order_by
  user_id: order_by
}

"""
order by stddev_pop() on columns of table "followed_lists"
"""
input followed_lists_stddev_pop_order_by {
  id: order_by
  list_id: order_by
  user_id: order_by
}

"""
order by stddev_samp() on columns of table "followed_lists"
"""
input followed_lists_stddev_samp_order_by {
  id: order_by
  list_id: order_by
  user_id: order_by
}

"""
Streaming cursor of the table "followed_lists"
"""
input followed_lists_stream_cursor_input {
  initial_value: followed_lists_stream_cursor_value_input!
  ordering: cursor_ordering
}

"""
Initial value of the column from where the streaming should start
"""
input followed_lists_stream_cursor_value_input {
  created_at: timestamptz
  id: Int
  list_id: Int
  user_id: Int
}

"""
order by sum() on columns of table "followed_lists"
"""
input followed_lists_sum_order_by {
  id: order_by
  list_id: order_by
  user_id: order_by
}

"""
order by var_pop() on columns of table "followed_lists"
"""
input followed_lists_var_pop_order_by {
  id: order_by
  list_id: order_by
  user_id: order_by
}

"""
order by var_samp() on columns of table "followed_lists"
"""
input followed_lists_var_samp_order_by {
  id: order_by
  list_id: order_by
  user_id: order_by
}

"""
order by variance() on columns of table "followed_lists"
"""
input followed_lists_variance_order_by {
  id: order_by
  list_id: order_by
  user_id: order_by
}

"""
columns and relationships of "followed_prompts"
"""
type followed_prompts {
  created_at: timestamptz
  id: Int!
  order: Int!
  prompt: prompts!
  prompt_id: Int!
  user: users!
  user_id: Int!
}

"""
order by aggregate values of table "followed_prompts"
"""
input followed_prompts_aggregate_order_by {
  avg: followed_prompts_avg_order_by
  count: order_by
  max: followed_prompts_max_order_by
  min: followed_prompts_min_order_by
  stddev: followed_prompts_stddev_order_by
  stddev_pop: followed_prompts_stddev_pop_order_by
  stddev_samp: followed_prompts_stddev_samp_order_by
  sum: followed_prompts_sum_order_by
  var_pop: followed_prompts_var_pop_order_by
  var_samp: followed_prompts_var_samp_order_by
  variance: followed_prompts_variance_order_by
}

"""
order by avg() on columns of table "followed_prompts"
"""
input followed_prompts_avg_order_by {
  id: order_by
  order: order_by
  prompt_id: order_by
  user_id: order_by
}

"""
Boolean expression to filter rows from the table "followed_prompts". All fields are combined with a logical 'AND'.
"""
input followed_prompts_bool_exp {
  _and: [followed_prompts_bool_exp!]
  _not: followed_prompts_bool_exp
  _or: [followed_prompts_bool_exp!]
  created_at: timestamptz_comparison_exp
  id: Int_comparison_exp
  order: Int_comparison_exp
  prompt: prompts_bool_exp
  prompt_id: Int_comparison_exp
  user: users_bool_exp
  user_id: Int_comparison_exp
}

"""
unique or primary key constraints on table "followed_prompts"
"""
enum followed_prompts_constraint {
  followed_prompts_pkey
  question_features_id_key
  question_features_userId_questionId_key
}

"""
input type for incrementing numeric columns in table "followed_prompts"
"""
input followed_prompts_inc_input {
  order: Int
}

"""
input type for inserting data into table "followed_prompts"
"""
input followed_prompts_insert_input {
  order: Int
  prompt_id: Int
  user_id: Int
}

"""
order by max() on columns of table "followed_prompts"
"""
input followed_prompts_max_order_by {
  created_at: order_by
  id: order_by
  order: order_by
  prompt_id: order_by
  user_id: order_by
}

"""
order by min() on columns of table "followed_prompts"
"""
input followed_prompts_min_order_by {
  created_at: order_by
  id: order_by
  order: order_by
  prompt_id: order_by
  user_id: order_by
}

"""
response of any mutation on the table "followed_prompts"
"""
type followed_prompts_mutation_response {
  affected_rows: Int!
  returning: [followed_prompts!]!
}

"""
on_conflict condition type for table "followed_prompts"
"""
input followed_prompts_on_conflict {
  constraint: followed_prompts_constraint!
  update_columns: [followed_prompts_update_column!]!
  where: followed_prompts_bool_exp
}

"""
Ordering options when selecting data from "followed_prompts".
"""
input followed_prompts_order_by {
  created_at: order_by
  id: order_by
  order: order_by
  prompt: prompts_order_by
  prompt_id: order_by
  user: users_order_by
  user_id: order_by
}

"""
primary key columns input for table: followed_prompts
"""
input followed_prompts_pk_columns_input {
  id: Int!
}

"""
select columns of table "followed_prompts"
"""
enum followed_prompts_select_column {
  created_at
  id
  order
  prompt_id
  user_id
}

"""
input type for updating data in table "followed_prompts"
"""
input followed_prompts_set_input {
  order: Int
}

"""
order by stddev() on columns of table "followed_prompts"
"""
input followed_prompts_stddev_order_by {
  id: order_by
  order: order_by
  prompt_id: order_by
  user_id: order_by
}

"""
order by stddev_pop() on columns of table "followed_prompts"
"""
input followed_prompts_stddev_pop_order_by {
  id: order_by
  order: order_by
  prompt_id: order_by
  user_id: order_by
}

"""
order by stddev_samp() on columns of table "followed_prompts"
"""
input followed_prompts_stddev_samp_order_by {
  id: order_by
  order: order_by
  prompt_id: order_by
  user_id: order_by
}

"""
Streaming cursor of the table "followed_prompts"
"""
input followed_prompts_stream_cursor_input {
  initial_value: followed_prompts_stream_cursor_value_input!
  ordering: cursor_ordering
}

"""
Initial value of the column from where the streaming should start
"""
input followed_prompts_stream_cursor_value_input {
  created_at: timestamptz
  id: Int
  order: Int
  prompt_id: Int
  user_id: Int
}

"""
order by sum() on columns of table "followed_prompts"
"""
input followed_prompts_sum_order_by {
  id: order_by
  order: order_by
  prompt_id: order_by
  user_id: order_by
}

"""
update columns of table "followed_prompts"
"""
enum followed_prompts_update_column {
  order
}

input followed_prompts_updates {
  _inc: followed_prompts_inc_input
  _set: followed_prompts_set_input
  where: followed_prompts_bool_exp!
}

"""
order by var_pop() on columns of table "followed_prompts"
"""
input followed_prompts_var_pop_order_by {
  id: order_by
  order: order_by
  prompt_id: order_by
  user_id: order_by
}

"""
order by var_samp() on columns of table "followed_prompts"
"""
input followed_prompts_var_samp_order_by {
  id: order_by
  order: order_by
  prompt_id: order_by
  user_id: order_by
}

"""
order by variance() on columns of table "followed_prompts"
"""
input followed_prompts_variance_order_by {
  id: order_by
  order: order_by
  prompt_id: order_by
  user_id: order_by
}

"""
columns and relationships of "followed_user_books"
"""
type followed_user_books {
  book: books
  book_id: Int
  follower_user: users
  follower_user_id: Int
  user: users
  user_book: user_books
  user_book_id: Int
  user_id: Int
}

"""
aggregated selection of "followed_user_books"
"""
type followed_user_books_aggregate {
  aggregate: followed_user_books_aggregate_fields
  nodes: [followed_user_books!]!
}

"""
aggregate fields of "followed_user_books"
"""
type followed_user_books_aggregate_fields {
  avg: followed_user_books_avg_fields
  count: Int!
  max: followed_user_books_max_fields
  min: followed_user_books_min_fields
  stddev: followed_user_books_stddev_fields
  stddev_pop: followed_user_books_stddev_pop_fields
  stddev_samp: followed_user_books_stddev_samp_fields
  sum: followed_user_books_sum_fields
  var_pop: followed_user_books_var_pop_fields
  var_samp: followed_user_books_var_samp_fields
  variance: followed_user_books_variance_fields
}

"""
aggregate avg on columns
"""
type followed_user_books_avg_fields {
  book_id: Float
  follower_user_id: Float
  user_book_id: Float
  user_id: Float
}

"""
Boolean expression to filter rows from the table "followed_user_books". All fields are combined with a logical 'AND'.
"""
input followed_user_books_bool_exp {
  _and: [followed_user_books_bool_exp!]
  _not: followed_user_books_bool_exp
  _or: [followed_user_books_bool_exp!]
  book: books_bool_exp
  book_id: Int_comparison_exp
  follower_user: users_bool_exp
  follower_user_id: Int_comparison_exp
  user: users_bool_exp
  user_book: user_books_bool_exp
  user_book_id: Int_comparison_exp
  user_id: Int_comparison_exp
}

"""
aggregate max on columns
"""
type followed_user_books_max_fields {
  book_id: Int
  follower_user_id: Int
  user_book_id: Int
  user_id: Int
}

"""
aggregate min on columns
"""
type followed_user_books_min_fields {
  book_id: Int
  follower_user_id: Int
  user_book_id: Int
  user_id: Int
}

"""
Ordering options when selecting data from "followed_user_books".
"""
input followed_user_books_order_by {
  book: books_order_by
  book_id: order_by
  follower_user: users_order_by
  follower_user_id: order_by
  user: users_order_by
  user_book: user_books_order_by
  user_book_id: order_by
  user_id: order_by
}

"""
select columns of table "followed_user_books"
"""
enum followed_user_books_select_column {
  book_id
  follower_user_id
  user_book_id
  user_id
}

"""
aggregate stddev on columns
"""
type followed_user_books_stddev_fields {
  book_id: Float
  follower_user_id: Float
  user_book_id: Float
  user_id: Float
}

"""
aggregate stddev_pop on columns
"""
type followed_user_books_stddev_pop_fields {
  book_id: Float
  follower_user_id: Float
  user_book_id: Float
  user_id: Float
}

"""
aggregate stddev_samp on columns
"""
type followed_user_books_stddev_samp_fields {
  book_id: Float
  follower_user_id: Float
  user_book_id: Float
  user_id: Float
}

"""
Streaming cursor of the table "followed_user_books"
"""
input followed_user_books_stream_cursor_input {
  initial_value: followed_user_books_stream_cursor_value_input!
  ordering: cursor_ordering
}

"""
Initial value of the column from where the streaming should start
"""
input followed_user_books_stream_cursor_value_input {
  book_id: Int
  follower_user_id: Int
  user_book_id: Int
  user_id: Int
}

"""
aggregate sum on columns
"""
type followed_user_books_sum_fields {
  book_id: Int
  follower_user_id: Int
  user_book_id: Int
  user_id: Int
}

"""
aggregate var_pop on columns
"""
type followed_user_books_var_pop_fields {
  book_id: Float
  follower_user_id: Float
  user_book_id: Float
  user_id: Float
}

"""
aggregate var_samp on columns
"""
type followed_user_books_var_samp_fields {
  book_id: Float
  follower_user_id: Float
  user_book_id: Float
  user_id: Float
}

"""
aggregate variance on columns
"""
type followed_user_books_variance_fields {
  book_id: Float
  follower_user_id: Float
  user_book_id: Float
  user_id: Float
}

"""
columns and relationships of "followed_users"
"""
type followed_users {
  created_at: timestamptz
  followed_user: users!
  followed_user_id: Int!
  id: Int!
  user: users!
  user_id: Int!
}

"""
order by aggregate values of table "followed_users"
"""
input followed_users_aggregate_order_by {
  avg: followed_users_avg_order_by
  count: order_by
  max: followed_users_max_order_by
  min: followed_users_min_order_by
  stddev: followed_users_stddev_order_by
  stddev_pop: followed_users_stddev_pop_order_by
  stddev_samp: followed_users_stddev_samp_order_by
  sum: followed_users_sum_order_by
  var_pop: followed_users_var_pop_order_by
  var_samp: followed_users_var_samp_order_by
  variance: followed_users_variance_order_by
}

"""
order by avg() on columns of table "followed_users"
"""
input followed_users_avg_order_by {
  followed_user_id: order_by
  id: order_by
  user_id: order_by
}

"""
Boolean expression to filter rows from the table "followed_users". All fields are combined with a logical 'AND'.
"""
input followed_users_bool_exp {
  _and: [followed_users_bool_exp!]
  _not: followed_users_bool_exp
  _or: [followed_users_bool_exp!]
  created_at: timestamptz_comparison_exp
  followed_user: users_bool_exp
  followed_user_id: Int_comparison_exp
  id: Int_comparison_exp
  user: users_bool_exp
  user_id: Int_comparison_exp
}

"""
order by max() on columns of table "followed_users"
"""
input followed_users_max_order_by {
  created_at: order_by
  followed_user_id: order_by
  id: order_by
  user_id: order_by
}

"""
order by min() on columns of table "followed_users"
"""
input followed_users_min_order_by {
  created_at: order_by
  followed_user_id: order_by
  id: order_by
  user_id: order_by
}

"""
response of any mutation on the table "followed_users"
"""
type followed_users_mutation_response {
  affected_rows: Int!
  returning: [followed_users!]!
}

"""
Ordering options when selecting data from "followed_users".
"""
input followed_users_order_by {
  created_at: order_by
  followed_user: users_order_by
  followed_user_id: order_by
  id: order_by
  user: users_order_by
  user_id: order_by
}

"""
select columns of table "followed_users"
"""
enum followed_users_select_column {
  created_at
  followed_user_id
  id
  user_id
}

"""
order by stddev() on columns of table "followed_users"
"""
input followed_users_stddev_order_by {
  followed_user_id: order_by
  id: order_by
  user_id: order_by
}

"""
order by stddev_pop() on columns of table "followed_users"
"""
input followed_users_stddev_pop_order_by {
  followed_user_id: order_by
  id: order_by
  user_id: order_by
}

"""
order by stddev_samp() on columns of table "followed_users"
"""
input followed_users_stddev_samp_order_by {
  followed_user_id: order_by
  id: order_by
  user_id: order_by
}

"""
Streaming cursor of the table "followed_users"
"""
input followed_users_stream_cursor_input {
  initial_value: followed_users_stream_cursor_value_input!
  ordering: cursor_ordering
}

"""
Initial value of the column from where the streaming should start
"""
input followed_users_stream_cursor_value_input {
  created_at: timestamptz
  followed_user_id: Int
  id: Int
  user_id: Int
}

"""
order by sum() on columns of table "followed_users"
"""
input followed_users_sum_order_by {
  followed_user_id: order_by
  id: order_by
  user_id: order_by
}

"""
order by var_pop() on columns of table "followed_users"
"""
input followed_users_var_pop_order_by {
  followed_user_id: order_by
  id: order_by
  user_id: order_by
}

"""
order by var_samp() on columns of table "followed_users"
"""
input followed_users_var_samp_order_by {
  followed_user_id: order_by
  id: order_by
  user_id: order_by
}

"""
order by variance() on columns of table "followed_users"
"""
input followed_users_variance_order_by {
  followed_user_id: order_by
  id: order_by
  user_id: order_by
}

"""
columns and relationships of "following_user_books"
"""
type following_user_books {
  book: books
  book_id: Int
  followed_user_id: Int
  following_user: users
  user: users
  user_book: user_books
  user_book_id: Int
  user_id: Int
}

"""
aggregated selection of "following_user_books"
"""
type following_user_books_aggregate {
  aggregate: following_user_books_aggregate_fields
  nodes: [following_user_books!]!
}

"""
aggregate fields of "following_user_books"
"""
type following_user_books_aggregate_fields {
  avg: following_user_books_avg_fields
  count: Int!
  max: following_user_books_max_fields
  min: following_user_books_min_fields
  stddev: following_user_books_stddev_fields
  stddev_pop: following_user_books_stddev_pop_fields
  stddev_samp: following_user_books_stddev_samp_fields
  sum: following_user_books_sum_fields
  var_pop: following_user_books_var_pop_fields
  var_samp: following_user_books_var_samp_fields
  variance: following_user_books_variance_fields
}

"""
aggregate avg on columns
"""
type following_user_books_avg_fields {
  book_id: Float
  followed_user_id: Float
  user_book_id: Float
  user_id: Float
}

"""
Boolean expression to filter rows from the table "following_user_books". All fields are combined with a logical 'AND'.
"""
input following_user_books_bool_exp {
  _and: [following_user_books_bool_exp!]
  _not: following_user_books_bool_exp
  _or: [following_user_books_bool_exp!]
  book: books_bool_exp
  book_id: Int_comparison_exp
  followed_user_id: Int_comparison_exp
  following_user: users_bool_exp
  user: users_bool_exp
  user_book: user_books_bool_exp
  user_book_id: Int_comparison_exp
  user_id: Int_comparison_exp
}

"""
aggregate max on columns
"""
type following_user_books_max_fields {
  book_id: Int
  followed_user_id: Int
  user_book_id: Int
  user_id: Int
}

"""
aggregate min on columns
"""
type following_user_books_min_fields {
  book_id: Int
  followed_user_id: Int
  user_book_id: Int
  user_id: Int
}

"""
Ordering options when selecting data from "following_user_books".
"""
input following_user_books_order_by {
  book: books_order_by
  book_id: order_by
  followed_user_id: order_by
  following_user: users_order_by
  user: users_order_by
  user_book: user_books_order_by
  user_book_id: order_by
  user_id: order_by
}

"""
select columns of table "following_user_books"
"""
enum following_user_books_select_column {
  book_id
  followed_user_id
  user_book_id
  user_id
}

"""
aggregate stddev on columns
"""
type following_user_books_stddev_fields {
  book_id: Float
  followed_user_id: Float
  user_book_id: Float
  user_id: Float
}

"""
aggregate stddev_pop on columns
"""
type following_user_books_stddev_pop_fields {
  book_id: Float
  followed_user_id: Float
  user_book_id: Float
  user_id: Float
}

"""
aggregate stddev_samp on columns
"""
type following_user_books_stddev_samp_fields {
  book_id: Float
  followed_user_id: Float
  user_book_id: Float
  user_id: Float
}

"""
Streaming cursor of the table "following_user_books"
"""
input following_user_books_stream_cursor_input {
  initial_value: following_user_books_stream_cursor_value_input!
  ordering: cursor_ordering
}

"""
Initial value of the column from where the streaming should start
"""
input following_user_books_stream_cursor_value_input {
  book_id: Int
  followed_user_id: Int
  user_book_id: Int
  user_id: Int
}

"""
aggregate sum on columns
"""
type following_user_books_sum_fields {
  book_id: Int
  followed_user_id: Int
  user_book_id: Int
  user_id: Int
}

"""
aggregate var_pop on columns
"""
type following_user_books_var_pop_fields {
  book_id: Float
  followed_user_id: Float
  user_book_id: Float
  user_id: Float
}

"""
aggregate var_samp on columns
"""
type following_user_books_var_samp_fields {
  book_id: Float
  followed_user_id: Float
  user_book_id: Float
  user_id: Float
}

"""
aggregate variance on columns
"""
type following_user_books_variance_fields {
  book_id: Float
  followed_user_id: Float
  user_book_id: Float
  user_id: Float
}

"""
columns and relationships of "goals"
"""
type goals {
  archived: Boolean!
  completed_at: timestamptz
  conditions: jsonb!
  description: String
  end_date: date!
  followers: [followed_users!]!
  goal: Int!
  id: Int!
  metric: String!
  privacy_setting_id: Int
  progress: numeric!
  start_date: date!
  state: String!
  user: users!
  user_id: Int!
}

"""
order by aggregate values of table "goals"
"""
input goals_aggregate_order_by {
  avg: goals_avg_order_by
  count: order_by
  max: goals_max_order_by
  min: goals_min_order_by
  stddev: goals_stddev_order_by
  stddev_pop: goals_stddev_pop_order_by
  stddev_samp: goals_stddev_samp_order_by
  sum: goals_sum_order_by
  var_pop: goals_var_pop_order_by
  var_samp: goals_var_samp_order_by
  variance: goals_variance_order_by
}

"""
order by avg() on columns of table "goals"
"""
input goals_avg_order_by {
  goal: order_by
  id: order_by
  privacy_setting_id: order_by
  progress: order_by
  user_id: order_by
}

"""
Boolean expression to filter rows from the table "goals". All fields are combined with a logical 'AND'.
"""
input goals_bool_exp {
  _and: [goals_bool_exp!]
  _not: goals_bool_exp
  _or: [goals_bool_exp!]
  archived: Boolean_comparison_exp
  completed_at: timestamptz_comparison_exp
  conditions: jsonb_comparison_exp
  description: String_comparison_exp
  end_date: date_comparison_exp
  followers: followed_users_bool_exp
  goal: Int_comparison_exp
  id: Int_comparison_exp
  metric: String_comparison_exp
  privacy_setting_id: Int_comparison_exp
  progress: numeric_comparison_exp
  start_date: date_comparison_exp
  state: String_comparison_exp
  user: users_bool_exp
  user_id: Int_comparison_exp
}

"""
order by max() on columns of table "goals"
"""
input goals_max_order_by {
  completed_at: order_by
  description: order_by
  end_date: order_by
  goal: order_by
  id: order_by
  metric: order_by
  privacy_setting_id: order_by
  progress: order_by
  start_date: order_by
  state: order_by
  user_id: order_by
}

"""
order by min() on columns of table "goals"
"""
input goals_min_order_by {
  completed_at: order_by
  description: order_by
  end_date: order_by
  goal: order_by
  id: order_by
  metric: order_by
  privacy_setting_id: order_by
  progress: order_by
  start_date: order_by
  state: order_by
  user_id: order_by
}

"""
response of any mutation on the table "goals"
"""
type goals_mutation_response {
  affected_rows: Int!
  returning: [goals!]!
}

"""
Ordering options when selecting data from "goals".
"""
input goals_order_by {
  archived: order_by
  completed_at: order_by
  conditions: order_by
  description: order_by
  end_date: order_by
  followers_aggregate: followed_users_aggregate_order_by
  goal: order_by
  id: order_by
  metric: order_by
  privacy_setting_id: order_by
  progress: order_by
  start_date: order_by
  state: order_by
  user: users_order_by
  user_id: order_by
}

"""
select columns of table "goals"
"""
enum goals_select_column {
  archived
  completed_at
  conditions
  description
  end_date
  goal
  id
  metric
  privacy_setting_id
  progress
  start_date
  state
  user_id
}

"""
order by stddev() on columns of table "goals"
"""
input goals_stddev_order_by {
  goal: order_by
  id: order_by
  privacy_setting_id: order_by
  progress: order_by
  user_id: order_by
}

"""
order by stddev_pop() on columns of table "goals"
"""
input goals_stddev_pop_order_by {
  goal: order_by
  id: order_by
  privacy_setting_id: order_by
  progress: order_by
  user_id: order_by
}

"""
order by stddev_samp() on columns of table "goals"
"""
input goals_stddev_samp_order_by {
  goal: order_by
  id: order_by
  privacy_setting_id: order_by
  progress: order_by
  user_id: order_by
}

"""
Streaming cursor of the table "goals"
"""
input goals_stream_cursor_input {
  initial_value: goals_stream_cursor_value_input!
  ordering: cursor_ordering
}

"""
Initial value of the column from where the streaming should start
"""
input goals_stream_cursor_value_input {
  archived: Boolean
  completed_at: timestamptz
  conditions: jsonb
  description: String
  end_date: date
  goal: Int
  id: Int
  metric: String
  privacy_setting_id: Int
  progress: numeric
  start_date: date
  state: String
  user_id: Int
}

"""
order by sum() on columns of table "goals"
"""
input goals_sum_order_by {
  goal: order_by
  id: order_by
  privacy_setting_id: order_by
  progress: order_by
  user_id: order_by
}

"""
order by var_pop() on columns of table "goals"
"""
input goals_var_pop_order_by {
  goal: order_by
  id: order_by
  privacy_setting_id: order_by
  progress: order_by
  user_id: order_by
}

"""
order by var_samp() on columns of table "goals"
"""
input goals_var_samp_order_by {
  goal: order_by
  id: order_by
  privacy_setting_id: order_by
  progress: order_by
  user_id: order_by
}

"""
order by variance() on columns of table "goals"
"""
input goals_variance_order_by {
  goal: order_by
  id: order_by
  privacy_setting_id: order_by
  progress: order_by
  user_id: order_by
}

"""
columns and relationships of "images"
"""
type images {
  color: String
  colors: jsonb
  height: Int
  id: bigint!
  imageable_id: Int
  imageable_type: String
  ratio: float8
  url: String
  width: Int
}

"""
order by aggregate values of table "images"
"""
input images_aggregate_order_by {
  avg: images_avg_order_by
  count: order_by
  max: images_max_order_by
  min: images_min_order_by
  stddev: images_stddev_order_by
  stddev_pop: images_stddev_pop_order_by
  stddev_samp: images_stddev_samp_order_by
  sum: images_sum_order_by
  var_pop: images_var_pop_order_by
  var_samp: images_var_samp_order_by
  variance: images_variance_order_by
}

"""
order by avg() on columns of table "images"
"""
input images_avg_order_by {
  height: order_by
  id: order_by
  imageable_id: order_by
  ratio: order_by
  width: order_by
}

"""
Boolean expression to filter rows from the table "images". All fields are combined with a logical 'AND'.
"""
input images_bool_exp {
  _and: [images_bool_exp!]
  _not: images_bool_exp
  _or: [images_bool_exp!]
  color: String_comparison_exp
  colors: jsonb_comparison_exp
  height: Int_comparison_exp
  id: bigint_comparison_exp
  imageable_id: Int_comparison_exp
  imageable_type: String_comparison_exp
  ratio: float8_comparison_exp
  url: String_comparison_exp
  width: Int_comparison_exp
}

"""
order by max() on columns of table "images"
"""
input images_max_order_by {
  color: order_by
  height: order_by
  id: order_by
  imageable_id: order_by
  imageable_type: order_by
  ratio: order_by
  url: order_by
  width: order_by
}

"""
order by min() on columns of table "images"
"""
input images_min_order_by {
  color: order_by
  height: order_by
  id: order_by
  imageable_id: order_by
  imageable_type: order_by
  ratio: order_by
  url: order_by
  width: order_by
}

"""
Ordering options when selecting data from "images".
"""
input images_order_by {
  color: order_by
  colors: order_by
  height: order_by
  id: order_by
  imageable_id: order_by
  imageable_type: order_by
  ratio: order_by
  url: order_by
  width: order_by
}

"""
select columns of table "images"
"""
enum images_select_column {
  color
  colors
  height
  id
  imageable_id
  imageable_type
  ratio
  url
  width
}

"""
order by stddev() on columns of table "images"
"""
input images_stddev_order_by {
  height: order_by
  id: order_by
  imageable_id: order_by
  ratio: order_by
  width: order_by
}

"""
order by stddev_pop() on columns of table "images"
"""
input images_stddev_pop_order_by {
  height: order_by
  id: order_by
  imageable_id: order_by
  ratio: order_by
  width: order_by
}

"""
order by stddev_samp() on columns of table "images"
"""
input images_stddev_samp_order_by {
  height: order_by
  id: order_by
  imageable_id: order_by
  ratio: order_by
  width: order_by
}

"""
Streaming cursor of the table "images"
"""
input images_stream_cursor_input {
  initial_value: images_stream_cursor_value_input!
  ordering: cursor_ordering
}

"""
Initial value of the column from where the streaming should start
"""
input images_stream_cursor_value_input {
  color: String
  colors: jsonb
  height: Int
  id: bigint
  imageable_id: Int
  imageable_type: String
  ratio: float8
  url: String
  width: Int
}

"""
order by sum() on columns of table "images"
"""
input images_sum_order_by {
  height: order_by
  id: order_by
  imageable_id: order_by
  ratio: order_by
  width: order_by
}

"""
order by var_pop() on columns of table "images"
"""
input images_var_pop_order_by {
  height: order_by
  id: order_by
  imageable_id: order_by
  ratio: order_by
  width: order_by
}

"""
order by var_samp() on columns of table "images"
"""
input images_var_samp_order_by {
  height: order_by
  id: order_by
  imageable_id: order_by
  ratio: order_by
  width: order_by
}

"""
order by variance() on columns of table "images"
"""
input images_variance_order_by {
  height: order_by
  id: order_by
  imageable_id: order_by
  ratio: order_by
  width: order_by
}

scalar json

"""
Boolean expression to compare columns of type "json". All fields are combined with logical 'AND'.
"""
input json_comparison_exp {
  _eq: json
  _gt: json
  _gte: json
  _in: [json!]
  _is_null: Boolean
  _lt: json
  _lte: json
  _neq: json
  _nin: [json!]
}

scalar jsonb

input jsonb_cast_exp {
  String: String_comparison_exp
}

"""
Boolean expression to compare columns of type "jsonb". All fields are combined with logical 'AND'.
"""
input jsonb_comparison_exp {
  _cast: jsonb_cast_exp
  _contained_in: jsonb
  _contains: jsonb
  _eq: jsonb
  _gt: jsonb
  _gte: jsonb
  _has_key: String
  _has_keys_all: [String!]
  _has_keys_any: [String!]
  _in: [jsonb!]
  _is_null: Boolean
  _lt: jsonb
  _lte: jsonb
  _neq: jsonb
  _nin: [jsonb!]
}

"""
columns and relationships of "languages"
"""
type languages {
  code2: String
  code3: String
  id: Int!
  language: String!
}

"""
Boolean expression to filter rows from the table "languages". All fields are combined with a logical 'AND'.
"""
input languages_bool_exp {
  _and: [languages_bool_exp!]
  _not: languages_bool_exp
  _or: [languages_bool_exp!]
  code2: String_comparison_exp
  code3: String_comparison_exp
  id: Int_comparison_exp
  language: String_comparison_exp
}

"""
Ordering options when selecting data from "languages".
"""
input languages_order_by {
  code2: order_by
  code3: order_by
  id: order_by
  language: order_by
}

"""
select columns of table "languages"
"""
enum languages_select_column {
  code2
  code3
  id
  language
}

"""
Streaming cursor of the table "languages"
"""
input languages_stream_cursor_input {
  initial_value: languages_stream_cursor_value_input!
  ordering: cursor_ordering
}

"""
Initial value of the column from where the streaming should start
"""
input languages_stream_cursor_value_input {
  code2: String
  code3: String
  id: Int
  language: String
}

"""
columns and relationships of "likes"
"""
type likes {
  activity: activities
  created_at: timestamptz
  followers: [followed_users!]!
  id: Int!
  likeable_id: Int!
  likeable_type: String!
  list: lists
  user: users!
  user_book: user_books
  user_id: Int!
}

"""
order by aggregate values of table "likes"
"""
input likes_aggregate_order_by {
  avg: likes_avg_order_by
  count: order_by
  max: likes_max_order_by
  min: likes_min_order_by
  stddev: likes_stddev_order_by
  stddev_pop: likes_stddev_pop_order_by
  stddev_samp: likes_stddev_samp_order_by
  sum: likes_sum_order_by
  var_pop: likes_var_pop_order_by
  var_samp: likes_var_samp_order_by
  variance: likes_variance_order_by
}

"""
order by avg() on columns of table "likes"
"""
input likes_avg_order_by {
  id: order_by
  likeable_id: order_by
  user_id: order_by
}

"""
Boolean expression to filter rows from the table "likes". All fields are combined with a logical 'AND'.
"""
input likes_bool_exp {
  _and: [likes_bool_exp!]
  _not: likes_bool_exp
  _or: [likes_bool_exp!]
  activity: activities_bool_exp
  created_at: timestamptz_comparison_exp
  followers: followed_users_bool_exp
  id: Int_comparison_exp
  likeable_id: Int_comparison_exp
  likeable_type: String_comparison_exp
  list: lists_bool_exp
  user: users_bool_exp
  user_book: user_books_bool_exp
  user_id: Int_comparison_exp
}

"""
order by max() on columns of table "likes"
"""
input likes_max_order_by {
  created_at: order_by
  id: order_by
  likeable_id: order_by
  likeable_type: order_by
  user_id: order_by
}

"""
order by min() on columns of table "likes"
"""
input likes_min_order_by {
  created_at: order_by
  id: order_by
  likeable_id: order_by
  likeable_type: order_by
  user_id: order_by
}

"""
Ordering options when selecting data from "likes".
"""
input likes_order_by {
  activity: activities_order_by
  created_at: order_by
  followers_aggregate: followed_users_aggregate_order_by
  id: order_by
  likeable_id: order_by
  likeable_type: order_by
  list: lists_order_by
  user: users_order_by
  user_book: user_books_order_by
  user_id: order_by
}

"""
select columns of table "likes"
"""
enum likes_select_column {
  created_at
  id
  likeable_id
  likeable_type
  user_id
}

"""
order by stddev() on columns of table "likes"
"""
input likes_stddev_order_by {
  id: order_by
  likeable_id: order_by
  user_id: order_by
}

"""
order by stddev_pop() on columns of table "likes"
"""
input likes_stddev_pop_order_by {
  id: order_by
  likeable_id: order_by
  user_id: order_by
}

"""
order by stddev_samp() on columns of table "likes"
"""
input likes_stddev_samp_order_by {
  id: order_by
  likeable_id: order_by
  user_id: order_by
}

"""
Streaming cursor of the table "likes"
"""
input likes_stream_cursor_input {
  initial_value: likes_stream_cursor_value_input!
  ordering: cursor_ordering
}

"""
Initial value of the column from where the streaming should start
"""
input likes_stream_cursor_value_input {
  created_at: timestamptz
  id: Int
  likeable_id: Int
  likeable_type: String
  user_id: Int
}

"""
order by sum() on columns of table "likes"
"""
input likes_sum_order_by {
  id: order_by
  likeable_id: order_by
  user_id: order_by
}

"""
order by var_pop() on columns of table "likes"
"""
input likes_var_pop_order_by {
  id: order_by
  likeable_id: order_by
  user_id: order_by
}

"""
order by var_samp() on columns of table "likes"
"""
input likes_var_samp_order_by {
  id: order_by
  likeable_id: order_by
  user_id: order_by
}

"""
order by variance() on columns of table "likes"
"""
input likes_variance_order_by {
  id: order_by
  likeable_id: order_by
  user_id: order_by
}

"""
columns and relationships of "list_books"
"""
type list_books {
  book: books!
  book_id: Int!
  created_at: timestamp
  date_added: timestamptz
  edition: editions
  edition_id: Int
  id: Int!
  imported: Boolean
  list: lists!
  list_id: Int!
  merged_at: timestamp
  original_book_id: Int
  original_edition_id: Int
  position: Int
  reason: String
  updated_at: timestamptz
  user_books: [user_books!]!
  user_books_aggregate: user_books_aggregate!
}

"""
aggregated selection of "list_books"
"""
type list_books_aggregate {
  aggregate: list_books_aggregate_fields
  nodes: [list_books!]!
}

input list_books_aggregate_bool_exp {
  bool_and: list_books_aggregate_bool_exp_bool_and
  bool_or: list_books_aggregate_bool_exp_bool_or
  count: list_books_aggregate_bool_exp_count
}

input list_books_aggregate_bool_exp_bool_and {
  arguments: list_books_select_column_list_books_aggregate_bool_exp_bool_and_arguments_columns!
  distinct: Boolean
  filter: list_books_bool_exp
  predicate: Boolean_comparison_exp!
}

input list_books_aggregate_bool_exp_bool_or {
  arguments: list_books_select_column_list_books_aggregate_bool_exp_bool_or_arguments_columns!
  distinct: Boolean
  filter: list_books_bool_exp
  predicate: Boolean_comparison_exp!
}

input list_books_aggregate_bool_exp_count {
  arguments: [list_books_select_column!]
  distinct: Boolean
  filter: list_books_bool_exp
  predicate: Int_comparison_exp!
}

"""
aggregate fields of "list_books"
"""
type list_books_aggregate_fields {
  avg: list_books_avg_fields
  count: Int!
  max: list_books_max_fields
  min: list_books_min_fields
  stddev: list_books_stddev_fields
  stddev_pop: list_books_stddev_pop_fields
  stddev_samp: list_books_stddev_samp_fields
  sum: list_books_sum_fields
  var_pop: list_books_var_pop_fields
  var_samp: list_books_var_samp_fields
  variance: list_books_variance_fields
}

"""
order by aggregate values of table "list_books"
"""
input list_books_aggregate_order_by {
  avg: list_books_avg_order_by
  count: order_by
  max: list_books_max_order_by
  min: list_books_min_order_by
  stddev: list_books_stddev_order_by
  stddev_pop: list_books_stddev_pop_order_by
  stddev_samp: list_books_stddev_samp_order_by
  sum: list_books_sum_order_by
  var_pop: list_books_var_pop_order_by
  var_samp: list_books_var_samp_order_by
  variance: list_books_variance_order_by
}

"""
aggregate avg on columns
"""
type list_books_avg_fields {
  book_id: Float
  edition_id: Float
  id: Float
  list_id: Float
  original_book_id: Float
  original_edition_id: Float
  position: Float
}

"""
order by avg() on columns of table "list_books"
"""
input list_books_avg_order_by {
  book_id: order_by
  edition_id: order_by
  id: order_by
  list_id: order_by
  original_book_id: order_by
  original_edition_id: order_by
  position: order_by
}

"""
Boolean expression to filter rows from the table "list_books". All fields are combined with a logical 'AND'.
"""
input list_books_bool_exp {
  _and: [list_books_bool_exp!]
  _not: list_books_bool_exp
  _or: [list_books_bool_exp!]
  book: books_bool_exp
  book_id: Int_comparison_exp
  created_at: timestamp_comparison_exp
  date_added: timestamptz_comparison_exp
  edition: editions_bool_exp
  edition_id: Int_comparison_exp
  id: Int_comparison_exp
  imported: Boolean_comparison_exp
  list: lists_bool_exp
  list_id: Int_comparison_exp
  merged_at: timestamp_comparison_exp
  original_book_id: Int_comparison_exp
  original_edition_id: Int_comparison_exp
  position: Int_comparison_exp
  reason: String_comparison_exp
  updated_at: timestamptz_comparison_exp
  user_books: user_books_bool_exp
  user_books_aggregate: user_books_aggregate_bool_exp
}

"""
input type for incrementing numeric columns in table "list_books"
"""
input list_books_inc_input {
  position: Int
}

"""
aggregate max on columns
"""
type list_books_max_fields {
  book_id: Int
  created_at: timestamp
  date_added: timestamptz
  edition_id: Int
  id: Int
  list_id: Int
  merged_at: timestamp
  original_book_id: Int
  original_edition_id: Int
  position: Int
  reason: String
  updated_at: timestamptz
}

"""
order by max() on columns of table "list_books"
"""
input list_books_max_order_by {
  book_id: order_by
  created_at: order_by
  date_added: order_by
  edition_id: order_by
  id: order_by
  list_id: order_by
  merged_at: order_by
  original_book_id: order_by
  original_edition_id: order_by
  position: order_by
  reason: order_by
  updated_at: order_by
}

"""
aggregate min on columns
"""
type list_books_min_fields {
  book_id: Int
  created_at: timestamp
  date_added: timestamptz
  edition_id: Int
  id: Int
  list_id: Int
  merged_at: timestamp
  original_book_id: Int
  original_edition_id: Int
  position: Int
  reason: String
  updated_at: timestamptz
}

"""
order by min() on columns of table "list_books"
"""
input list_books_min_order_by {
  book_id: order_by
  created_at: order_by
  date_added: order_by
  edition_id: order_by
  id: order_by
  list_id: order_by
  merged_at: order_by
  original_book_id: order_by
  original_edition_id: order_by
  position: order_by
  reason: order_by
  updated_at: order_by
}

"""
response of any mutation on the table "list_books"
"""
type list_books_mutation_response {
  affected_rows: Int!
  returning: [list_books!]!
}

"""
Ordering options when selecting data from "list_books".
"""
input list_books_order_by {
  book: books_order_by
  book_id: order_by
  created_at: order_by
  date_added: order_by
  edition: editions_order_by
  edition_id: order_by
  id: order_by
  imported: order_by
  list: lists_order_by
  list_id: order_by
  merged_at: order_by
  original_book_id: order_by
  original_edition_id: order_by
  position: order_by
  reason: order_by
  updated_at: order_by
  user_books_aggregate: user_books_aggregate_order_by
}

"""
primary key columns input for table: list_books
"""
input list_books_pk_columns_input {
  id: Int!
}

"""
select columns of table "list_books"
"""
enum list_books_select_column {
  book_id
  created_at
  date_added
  edition_id
  id
  imported
  list_id
  merged_at
  original_book_id
  original_edition_id
  position
  reason
  updated_at
}

"""
select "list_books_aggregate_bool_exp_bool_and_arguments_columns" columns of table "list_books"
"""
enum list_books_select_column_list_books_aggregate_bool_exp_bool_and_arguments_columns {
  imported
}

"""
select "list_books_aggregate_bool_exp_bool_or_arguments_columns" columns of table "list_books"
"""
enum list_books_select_column_list_books_aggregate_bool_exp_bool_or_arguments_columns {
  imported
}

"""
input type for updating data in table "list_books"
"""
input list_books_set_input {
  position: Int
  reason: String
}

"""
aggregate stddev on columns
"""
type list_books_stddev_fields {
  book_id: Float
  edition_id: Float
  id: Float
  list_id: Float
  original_book_id: Float
  original_edition_id: Float
  position: Float
}

"""
order by stddev() on columns of table "list_books"
"""
input list_books_stddev_order_by {
  book_id: order_by
  edition_id: order_by
  id: order_by
  list_id: order_by
  original_book_id: order_by
  original_edition_id: order_by
  position: order_by
}

"""
aggregate stddev_pop on columns
"""
type list_books_stddev_pop_fields {
  book_id: Float
  edition_id: Float
  id: Float
  list_id: Float
  original_book_id: Float
  original_edition_id: Float
  position: Float
}

"""
order by stddev_pop() on columns of table "list_books"
"""
input list_books_stddev_pop_order_by {
  book_id: order_by
  edition_id: order_by
  id: order_by
  list_id: order_by
  original_book_id: order_by
  original_edition_id: order_by
  position: order_by
}

"""
aggregate stddev_samp on columns
"""
type list_books_stddev_samp_fields {
  book_id: Float
  edition_id: Float
  id: Float
  list_id: Float
  original_book_id: Float
  original_edition_id: Float
  position: Float
}

"""
order by stddev_samp() on columns of table "list_books"
"""
input list_books_stddev_samp_order_by {
  book_id: order_by
  edition_id: order_by
  id: order_by
  list_id: order_by
  original_book_id: order_by
  original_edition_id: order_by
  position: order_by
}

"""
Streaming cursor of the table "list_books"
"""
input list_books_stream_cursor_input {
  initial_value: list_books_stream_cursor_value_input!
  ordering: cursor_ordering
}

"""
Initial value of the column from where the streaming should start
"""
input list_books_stream_cursor_value_input {
  book_id: Int
  created_at: timestamp
  date_added: timestamptz
  edition_id: Int
  id: Int
  imported: Boolean
  list_id: Int
  merged_at: timestamp
  original_book_id: Int
  original_edition_id: Int
  position: Int
  reason: String
  updated_at: timestamptz
}

"""
aggregate sum on columns
"""
type list_books_sum_fields {
  book_id: Int
  edition_id: Int
  id: Int
  list_id: Int
  original_book_id: Int
  original_edition_id: Int
  position: Int
}

"""
order by sum() on columns of table "list_books"
"""
input list_books_sum_order_by {
  book_id: order_by
  edition_id: order_by
  id: order_by
  list_id: order_by
  original_book_id: order_by
  original_edition_id: order_by
  position: order_by
}

input list_books_updates {
  _inc: list_books_inc_input
  _set: list_books_set_input
  where: list_books_bool_exp!
}

"""
aggregate var_pop on columns
"""
type list_books_var_pop_fields {
  book_id: Float
  edition_id: Float
  id: Float
  list_id: Float
  original_book_id: Float
  original_edition_id: Float
  position: Float
}

"""
order by var_pop() on columns of table "list_books"
"""
input list_books_var_pop_order_by {
  book_id: order_by
  edition_id: order_by
  id: order_by
  list_id: order_by
  original_book_id: order_by
  original_edition_id: order_by
  position: order_by
}

"""
aggregate var_samp on columns
"""
type list_books_var_samp_fields {
  book_id: Float
  edition_id: Float
  id: Float
  list_id: Float
  original_book_id: Float
  original_edition_id: Float
  position: Float
}

"""
order by var_samp() on columns of table "list_books"
"""
input list_books_var_samp_order_by {
  book_id: order_by
  edition_id: order_by
  id: order_by
  list_id: order_by
  original_book_id: order_by
  original_edition_id: order_by
  position: order_by
}

"""
aggregate variance on columns
"""
type list_books_variance_fields {
  book_id: Float
  edition_id: Float
  id: Float
  list_id: Float
  original_book_id: Float
  original_edition_id: Float
  position: Float
}

"""
order by variance() on columns of table "list_books"
"""
input list_books_variance_order_by {
  book_id: order_by
  edition_id: order_by
  id: order_by
  list_id: order_by
  original_book_id: order_by
  original_edition_id: order_by
  position: order_by
}

"""
columns and relationships of "lists"
"""
type lists {
  books_count: Int!
  created_at: timestamp
  default_view: String!
  description: String
  featured: Boolean!
  featured_profile: Boolean!
  followed_lists: [followed_lists!]!
  followers: [followed_users!]!
  followers_count: Int
  id: Int!
  imported: Boolean!
  likes: [likes!]!
  likes_count: Int!
  list_books: [list_books!]!
  list_books_aggregate: list_books_aggregate!
  name: String!
  object_type: String!
  privacy_setting: privacy_settings!
  privacy_setting_id: Int!
  public: Boolean!
  ranked: Boolean!
  slug: String
  updated_at: timestamptz
  url: String
  user: users!
  user_id: Int!
}

"""
aggregated selection of "lists"
"""
type lists_aggregate {
  aggregate: lists_aggregate_fields
  nodes: [lists!]!
}

input lists_aggregate_bool_exp {
  bool_and: lists_aggregate_bool_exp_bool_and
  bool_or: lists_aggregate_bool_exp_bool_or
  count: lists_aggregate_bool_exp_count
}

input lists_aggregate_bool_exp_bool_and {
  arguments: lists_select_column_lists_aggregate_bool_exp_bool_and_arguments_columns!
  distinct: Boolean
  filter: lists_bool_exp
  predicate: Boolean_comparison_exp!
}

input lists_aggregate_bool_exp_bool_or {
  arguments: lists_select_column_lists_aggregate_bool_exp_bool_or_arguments_columns!
  distinct: Boolean
  filter: lists_bool_exp
  predicate: Boolean_comparison_exp!
}

input lists_aggregate_bool_exp_count {
  arguments: [lists_select_column!]
  distinct: Boolean
  filter: lists_bool_exp
  predicate: Int_comparison_exp!
}

"""
aggregate fields of "lists"
"""
type lists_aggregate_fields {
  avg: lists_avg_fields
  count: Int!
  max: lists_max_fields
  min: lists_min_fields
  stddev: lists_stddev_fields
  stddev_pop: lists_stddev_pop_fields
  stddev_samp: lists_stddev_samp_fields
  sum: lists_sum_fields
  var_pop: lists_var_pop_fields
  var_samp: lists_var_samp_fields
  variance: lists_variance_fields
}

"""
order by aggregate values of table "lists"
"""
input lists_aggregate_order_by {
  avg: lists_avg_order_by
  count: order_by
  max: lists_max_order_by
  min: lists_min_order_by
  stddev: lists_stddev_order_by
  stddev_pop: lists_stddev_pop_order_by
  stddev_samp: lists_stddev_samp_order_by
  sum: lists_sum_order_by
  var_pop: lists_var_pop_order_by
  var_samp: lists_var_samp_order_by
  variance: lists_variance_order_by
}

"""
aggregate avg on columns
"""
type lists_avg_fields {
  books_count: Float
  followers_count: Float
  id: Float
  likes_count: Float
  privacy_setting_id: Float
  user_id: Float
}

"""
order by avg() on columns of table "lists"
"""
input lists_avg_order_by {
  books_count: order_by
  followers_count: order_by
  id: order_by
  likes_count: order_by
  privacy_setting_id: order_by
  user_id: order_by
}

"""
Boolean expression to filter rows from the table "lists". All fields are combined with a logical 'AND'.
"""
input lists_bool_exp {
  _and: [lists_bool_exp!]
  _not: lists_bool_exp
  _or: [lists_bool_exp!]
  books_count: Int_comparison_exp
  created_at: timestamp_comparison_exp
  default_view: String_comparison_exp
  description: String_comparison_exp
  featured: Boolean_comparison_exp
  featured_profile: Boolean_comparison_exp
  followed_lists: followed_lists_bool_exp
  followers: followed_users_bool_exp
  followers_count: Int_comparison_exp
  id: Int_comparison_exp
  imported: Boolean_comparison_exp
  likes: likes_bool_exp
  likes_count: Int_comparison_exp
  list_books: list_books_bool_exp
  list_books_aggregate: list_books_aggregate_bool_exp
  name: String_comparison_exp
  object_type: String_comparison_exp
  privacy_setting: privacy_settings_bool_exp
  privacy_setting_id: Int_comparison_exp
  public: Boolean_comparison_exp
  ranked: Boolean_comparison_exp
  slug: String_comparison_exp
  updated_at: timestamptz_comparison_exp
  url: String_comparison_exp
  user: users_bool_exp
  user_id: Int_comparison_exp
}

"""
aggregate max on columns
"""
type lists_max_fields {
  books_count: Int
  created_at: timestamp
  default_view: String
  description: String
  followers_count: Int
  id: Int
  likes_count: Int
  name: String
  object_type: String
  privacy_setting_id: Int
  slug: String
  updated_at: timestamptz
  url: String
  user_id: Int
}

"""
order by max() on columns of table "lists"
"""
input lists_max_order_by {
  books_count: order_by
  created_at: order_by
  default_view: order_by
  description: order_by
  followers_count: order_by
  id: order_by
  likes_count: order_by
  name: order_by
  object_type: order_by
  privacy_setting_id: order_by
  slug: order_by
  updated_at: order_by
  url: order_by
  user_id: order_by
}

"""
aggregate min on columns
"""
type lists_min_fields {
  books_count: Int
  created_at: timestamp
  default_view: String
  description: String
  followers_count: Int
  id: Int
  likes_count: Int
  name: String
  object_type: String
  privacy_setting_id: Int
  slug: String
  updated_at: timestamptz
  url: String
  user_id: Int
}

"""
order by min() on columns of table "lists"
"""
input lists_min_order_by {
  books_count: order_by
  created_at: order_by
  default_view: order_by
  description: order_by
  followers_count: order_by
  id: order_by
  likes_count: order_by
  name: order_by
  object_type: order_by
  privacy_setting_id: order_by
  slug: order_by
  updated_at: order_by
  url: order_by
  user_id: order_by
}

"""
Ordering options when selecting data from "lists".
"""
input lists_order_by {
  books_count: order_by
  created_at: order_by
  default_view: order_by
  description: order_by
  featured: order_by
  featured_profile: order_by
  followed_lists_aggregate: followed_lists_aggregate_order_by
  followers_aggregate: followed_users_aggregate_order_by
  followers_count: order_by
  id: order_by
  imported: order_by
  likes_aggregate: likes_aggregate_order_by
  likes_count: order_by
  list_books_aggregate: list_books_aggregate_order_by
  name: order_by
  object_type: order_by
  privacy_setting: privacy_settings_order_by
  privacy_setting_id: order_by
  public: order_by
  ranked: order_by
  slug: order_by
  updated_at: order_by
  url: order_by
  user: users_order_by
  user_id: order_by
}

"""
select columns of table "lists"
"""
enum lists_select_column {
  books_count
  created_at
  default_view
  description
  featured
  featured_profile
  followers_count
  id
  imported
  likes_count
  name
  object_type
  privacy_setting_id
  public
  ranked
  slug
  updated_at
  url
  user_id
}

"""
select "lists_aggregate_bool_exp_bool_and_arguments_columns" columns of table "lists"
"""
enum lists_select_column_lists_aggregate_bool_exp_bool_and_arguments_columns {
  featured
  featured_profile
  imported
  public
  ranked
}

"""
select "lists_aggregate_bool_exp_bool_or_arguments_columns" columns of table "lists"
"""
enum lists_select_column_lists_aggregate_bool_exp_bool_or_arguments_columns {
  featured
  featured_profile
  imported
  public
  ranked
}

"""
aggregate stddev on columns
"""
type lists_stddev_fields {
  books_count: Float
  followers_count: Float
  id: Float
  likes_count: Float
  privacy_setting_id: Float
  user_id: Float
}

"""
order by stddev() on columns of table "lists"
"""
input lists_stddev_order_by {
  books_count: order_by
  followers_count: order_by
  id: order_by
  likes_count: order_by
  privacy_setting_id: order_by
  user_id: order_by
}

"""
aggregate stddev_pop on columns
"""
type lists_stddev_pop_fields {
  books_count: Float
  followers_count: Float
  id: Float
  likes_count: Float
  privacy_setting_id: Float
  user_id: Float
}

"""
order by stddev_pop() on columns of table "lists"
"""
input lists_stddev_pop_order_by {
  books_count: order_by
  followers_count: order_by
  id: order_by
  likes_count: order_by
  privacy_setting_id: order_by
  user_id: order_by
}

"""
aggregate stddev_samp on columns
"""
type lists_stddev_samp_fields {
  books_count: Float
  followers_count: Float
  id: Float
  likes_count: Float
  privacy_setting_id: Float
  user_id: Float
}

"""
order by stddev_samp() on columns of table "lists"
"""
input lists_stddev_samp_order_by {
  books_count: order_by
  followers_count: order_by
  id: order_by
  likes_count: order_by
  privacy_setting_id: order_by
  user_id: order_by
}

"""
Streaming cursor of the table "lists"
"""
input lists_stream_cursor_input {
  initial_value: lists_stream_cursor_value_input!
  ordering: cursor_ordering
}

"""
Initial value of the column from where the streaming should start
"""
input lists_stream_cursor_value_input {
  books_count: Int
  created_at: timestamp
  default_view: String
  description: String
  featured: Boolean
  featured_profile: Boolean
  followers_count: Int
  id: Int
  imported: Boolean
  likes_count: Int
  name: String
  object_type: String
  privacy_setting_id: Int
  public: Boolean
  ranked: Boolean
  slug: String
  updated_at: timestamptz
  url: String
  user_id: Int
}

"""
aggregate sum on columns
"""
type lists_sum_fields {
  books_count: Int
  followers_count: Int
  id: Int
  likes_count: Int
  privacy_setting_id: Int
  user_id: Int
}

"""
order by sum() on columns of table "lists"
"""
input lists_sum_order_by {
  books_count: order_by
  followers_count: order_by
  id: order_by
  likes_count: order_by
  privacy_setting_id: order_by
  user_id: order_by
}

"""
aggregate var_pop on columns
"""
type lists_var_pop_fields {
  books_count: Float
  followers_count: Float
  id: Float
  likes_count: Float
  privacy_setting_id: Float
  user_id: Float
}

"""
order by var_pop() on columns of table "lists"
"""
input lists_var_pop_order_by {
  books_count: order_by
  followers_count: order_by
  id: order_by
  likes_count: order_by
  privacy_setting_id: order_by
  user_id: order_by
}

"""
aggregate var_samp on columns
"""
type lists_var_samp_fields {
  books_count: Float
  followers_count: Float
  id: Float
  likes_count: Float
  privacy_setting_id: Float
  user_id: Float
}

"""
order by var_samp() on columns of table "lists"
"""
input lists_var_samp_order_by {
  books_count: order_by
  followers_count: order_by
  id: order_by
  likes_count: order_by
  privacy_setting_id: order_by
  user_id: order_by
}

"""
aggregate variance on columns
"""
type lists_variance_fields {
  books_count: Float
  followers_count: Float
  id: Float
  likes_count: Float
  privacy_setting_id: Float
  user_id: Float
}

"""
order by variance() on columns of table "lists"
"""
input lists_variance_order_by {
  books_count: order_by
  followers_count: order_by
  id: order_by
  likes_count: order_by
  privacy_setting_id: order_by
  user_id: order_by
}

"""
mutation root
"""
type mutation_root {
  book_mapping_normalize: BookMappingIdType
  book_normalize: BookIdType
  collection_import_result_reimport: CollectionImportResultIdType
  collection_import_retry: CollectionImportIdType
  delete_activities: activities_mutation_response
  delete_activities_by_pk: activities
  delete_book_mapping: BookMappingIdType
  delete_followed_list: DeleteListType
  delete_followed_prompt: DeleteFollowedPromptType
  delete_followed_prompts: followed_prompts_mutation_response
  delete_followed_prompts_by_pk: followed_prompts
  delete_followed_user: FollowedUserType
  delete_followed_users: followed_users_mutation_response
  delete_followed_users_by_pk: followed_users
  delete_goals: goals_mutation_response
  delete_goals_by_pk: goals
  delete_like: LikeDeleteType
  delete_list: ListDeleteType
  delete_list_book: ListBookDeleteType
  delete_prompt_answer: PromptAnswerIdType
  delete_prompts: prompts_mutation_response
  delete_prompts_by_pk: prompts
  delete_reading_journal: DeleteReadingJournalOutput
  delete_reading_journals_for_book: DeleteReadingJournalsOutput
  delete_user_blocks: user_blocks_mutation_response
  delete_user_blocks_by_pk: user_blocks
  delete_user_book: UserBookDeleteType
  delete_user_book_read: UserBookReadIdType
  edition_normalize: EditionIdType
  edition_owned: ListBookIdType
  email_user_delete_confirmation: SuccessType
  insert_author: AuthorIdType
  insert_block: InsertBlockOutput
  insert_book: OptionalEditionIdType
  insert_book_mapping: BookMappingIdType
  insert_character: CharacterIdType
  insert_collection_import: CollectionImportIdType
  insert_edition: EditionIdType
  insert_followed_prompts: followed_prompts_mutation_response
  insert_followed_prompts_one: followed_prompts
  insert_followed_user: FollowedUserType
  insert_goal: GoalIdType
  insert_image: ImageIdType
  insert_list: ListIdType
  insert_list_book: ListBookIdType
  insert_notification_settings: notification_settings_mutation_response
  insert_notification_settings_one: notification_settings
  insert_prompt: PromptIdType
  insert_prompt_answer: PromptAnswerIdType
  insert_publisher: PublisherIdType
  insert_reading_journal: ReadingJournalOutput
  insert_report: ReportOutput
  insert_serie: SeriesIdType
  insert_user: UserIdType
  insert_user_blocks: user_blocks_mutation_response
  insert_user_blocks_one: user_blocks
  insert_user_book: UserBookIdType
  insert_user_book_read: UserBookReadIdType
  insert_user_flags: user_flags_mutation_response
  insert_user_flags_one: user_flags
  receipt_validate: ValidateReceiptType
  update_author: AuthorIdType
  update_book: BookIdType
  update_character: CharacterIdType
  update_collection_import_results: collection_import_results_mutation_response
  update_collection_import_results_by_pk: collection_import_results
  update_collection_import_results_many: [collection_import_results_mutation_response]
  update_edition: EditionIdType
  update_followed_prompts: followed_prompts_mutation_response
  update_followed_prompts_by_pk: followed_prompts
  update_followed_prompts_many: [followed_prompts_mutation_response]
  update_goal: GoalIdType
  update_goal_progress: GoalIdType
  update_list: ListIdType
  update_list_books: list_books_mutation_response
  update_list_books_by_pk: list_books
  update_list_books_many: [list_books_mutation_response]
  update_newsletter: NewsletterStatusType
  update_notification_deliveries: notification_deliveries_mutation_response
  update_notification_deliveries_by_pk: notification_deliveries
  update_notification_deliveries_many: [notification_deliveries_mutation_response]
  update_notification_settings: notification_settings_mutation_response
  update_notification_settings_by_pk: notification_settings
  update_notification_settings_many: [notification_settings_mutation_response]
  update_prompt: PromptIdType
  update_prompt_answers: prompt_answers_mutation_response
  update_prompt_answers_by_pk: prompt_answers
  update_prompt_answers_many: [prompt_answers_mutation_response]
  update_publisher: PublisherIdType
  update_reading_journal: ReadingJournalOutput
  update_serie: SeriesIdType
  update_user: UserIdType
  update_user_book: UserBookIdType
  update_user_book_read: UserBookReadIdType
  update_user_privacy_setting: UserIdType
  upsert_book: NewBookIdType
  upsert_followed_list: FollowedListType
  upsert_followed_prompt: FollowedPromptType
  upsert_like: LikeType
  upsert_tags: TagsType
  upsert_user_book_reads: UserBooksReadUpsertType
  user_login: UserIdType
}

"""
columns and relationships of "notification_channels"
"""
type notification_channels {
  channel: String!
  id: bigint!
}

"""
Boolean expression to filter rows from the table "notification_channels". All fields are combined with a logical 'AND'.
"""
input notification_channels_bool_exp {
  _and: [notification_channels_bool_exp!]
  _not: notification_channels_bool_exp
  _or: [notification_channels_bool_exp!]
  channel: String_comparison_exp
  id: bigint_comparison_exp
}

"""
Ordering options when selecting data from "notification_channels".
"""
input notification_channels_order_by {
  channel: order_by
  id: order_by
}

"""
select columns of table "notification_channels"
"""
enum notification_channels_select_column {
  channel
  id
}

"""
Streaming cursor of the table "notification_channels"
"""
input notification_channels_stream_cursor_input {
  initial_value: notification_channels_stream_cursor_value_input!
  ordering: cursor_ordering
}

"""
Initial value of the column from where the streaming should start
"""
input notification_channels_stream_cursor_value_input {
  channel: String
  id: bigint
}

"""
columns and relationships of "notification_deliveries"
"""
type notification_deliveries {
  channel: notification_channels
  channel_id: Int!
  id: bigint!
  notification: notifications
  notification_id: Int!
  read: Boolean!
  read_at: timestamp
  sent_at: timestamp
  user: users
  user_id: Int!
}

"""
aggregated selection of "notification_deliveries"
"""
type notification_deliveries_aggregate {
  aggregate: notification_deliveries_aggregate_fields
  nodes: [notification_deliveries!]!
}

input notification_deliveries_aggregate_bool_exp {
  bool_and: notification_deliveries_aggregate_bool_exp_bool_and
  bool_or: notification_deliveries_aggregate_bool_exp_bool_or
  count: notification_deliveries_aggregate_bool_exp_count
}

input notification_deliveries_aggregate_bool_exp_bool_and {
  arguments: notification_deliveries_select_column_notification_deliveries_aggregate_bool_exp_bool_and_arguments_columns!
  distinct: Boolean
  filter: notification_deliveries_bool_exp
  predicate: Boolean_comparison_exp!
}

input notification_deliveries_aggregate_bool_exp_bool_or {
  arguments: notification_deliveries_select_column_notification_deliveries_aggregate_bool_exp_bool_or_arguments_columns!
  distinct: Boolean
  filter: notification_deliveries_bool_exp
  predicate: Boolean_comparison_exp!
}

input notification_deliveries_aggregate_bool_exp_count {
  arguments: [notification_deliveries_select_column!]
  distinct: Boolean
  filter: notification_deliveries_bool_exp
  predicate: Int_comparison_exp!
}

"""
aggregate fields of "notification_deliveries"
"""
type notification_deliveries_aggregate_fields {
  avg: notification_deliveries_avg_fields
  count: Int!
  max: notification_deliveries_max_fields
  min: notification_deliveries_min_fields
  stddev: notification_deliveries_stddev_fields
  stddev_pop: notification_deliveries_stddev_pop_fields
  stddev_samp: notification_deliveries_stddev_samp_fields
  sum: notification_deliveries_sum_fields
  var_pop: notification_deliveries_var_pop_fields
  var_samp: notification_deliveries_var_samp_fields
  variance: notification_deliveries_variance_fields
}

"""
order by aggregate values of table "notification_deliveries"
"""
input notification_deliveries_aggregate_order_by {
  avg: notification_deliveries_avg_order_by
  count: order_by
  max: notification_deliveries_max_order_by
  min: notification_deliveries_min_order_by
  stddev: notification_deliveries_stddev_order_by
  stddev_pop: notification_deliveries_stddev_pop_order_by
  stddev_samp: notification_deliveries_stddev_samp_order_by
  sum: notification_deliveries_sum_order_by
  var_pop: notification_deliveries_var_pop_order_by
  var_samp: notification_deliveries_var_samp_order_by
  variance: notification_deliveries_variance_order_by
}

"""
aggregate avg on columns
"""
type notification_deliveries_avg_fields {
  channel_id: Float
  id: Float
  notification_id: Float
  user_id: Float
}

"""
order by avg() on columns of table "notification_deliveries"
"""
input notification_deliveries_avg_order_by {
  channel_id: order_by
  id: order_by
  notification_id: order_by
  user_id: order_by
}

"""
Boolean expression to filter rows from the table "notification_deliveries". All fields are combined with a logical 'AND'.
"""
input notification_deliveries_bool_exp {
  _and: [notification_deliveries_bool_exp!]
  _not: notification_deliveries_bool_exp
  _or: [notification_deliveries_bool_exp!]
  channel: notification_channels_bool_exp
  channel_id: Int_comparison_exp
  id: bigint_comparison_exp
  notification: notifications_bool_exp
  notification_id: Int_comparison_exp
  read: Boolean_comparison_exp
  read_at: timestamp_comparison_exp
  sent_at: timestamp_comparison_exp
  user: users_bool_exp
  user_id: Int_comparison_exp
}

"""
aggregate max on columns
"""
type notification_deliveries_max_fields {
  channel_id: Int
  id: bigint
  notification_id: Int
  read_at: timestamp
  sent_at: timestamp
  user_id: Int
}

"""
order by max() on columns of table "notification_deliveries"
"""
input notification_deliveries_max_order_by {
  channel_id: order_by
  id: order_by
  notification_id: order_by
  read_at: order_by
  sent_at: order_by
  user_id: order_by
}

"""
aggregate min on columns
"""
type notification_deliveries_min_fields {
  channel_id: Int
  id: bigint
  notification_id: Int
  read_at: timestamp
  sent_at: timestamp
  user_id: Int
}

"""
order by min() on columns of table "notification_deliveries"
"""
input notification_deliveries_min_order_by {
  channel_id: order_by
  id: order_by
  notification_id: order_by
  read_at: order_by
  sent_at: order_by
  user_id: order_by
}

"""
response of any mutation on the table "notification_deliveries"
"""
type notification_deliveries_mutation_response {
  affected_rows: Int!
  returning: [notification_deliveries!]!
}

"""
Ordering options when selecting data from "notification_deliveries".
"""
input notification_deliveries_order_by {
  channel: notification_channels_order_by
  channel_id: order_by
  id: order_by
  notification: notifications_order_by
  notification_id: order_by
  read: order_by
  read_at: order_by
  sent_at: order_by
  user: users_order_by
  user_id: order_by
}

"""
primary key columns input for table: notification_deliveries
"""
input notification_deliveries_pk_columns_input {
  id: bigint!
}

"""
select columns of table "notification_deliveries"
"""
enum notification_deliveries_select_column {
  channel_id
  id
  notification_id
  read
  read_at
  sent_at
  user_id
}

"""
select "notification_deliveries_aggregate_bool_exp_bool_and_arguments_columns" columns of table "notification_deliveries"
"""
enum notification_deliveries_select_column_notification_deliveries_aggregate_bool_exp_bool_and_arguments_columns {
  read
}

"""
select "notification_deliveries_aggregate_bool_exp_bool_or_arguments_columns" columns of table "notification_deliveries"
"""
enum notification_deliveries_select_column_notification_deliveries_aggregate_bool_exp_bool_or_arguments_columns {
  read
}

"""
input type for updating data in table "notification_deliveries"
"""
input notification_deliveries_set_input {
  read: Boolean
  read_at: timestamp
}

"""
aggregate stddev on columns
"""
type notification_deliveries_stddev_fields {
  channel_id: Float
  id: Float
  notification_id: Float
  user_id: Float
}

"""
order by stddev() on columns of table "notification_deliveries"
"""
input notification_deliveries_stddev_order_by {
  channel_id: order_by
  id: order_by
  notification_id: order_by
  user_id: order_by
}

"""
aggregate stddev_pop on columns
"""
type notification_deliveries_stddev_pop_fields {
  channel_id: Float
  id: Float
  notification_id: Float
  user_id: Float
}

"""
order by stddev_pop() on columns of table "notification_deliveries"
"""
input notification_deliveries_stddev_pop_order_by {
  channel_id: order_by
  id: order_by
  notification_id: order_by
  user_id: order_by
}

"""
aggregate stddev_samp on columns
"""
type notification_deliveries_stddev_samp_fields {
  channel_id: Float
  id: Float
  notification_id: Float
  user_id: Float
}

"""
order by stddev_samp() on columns of table "notification_deliveries"
"""
input notification_deliveries_stddev_samp_order_by {
  channel_id: order_by
  id: order_by
  notification_id: order_by
  user_id: order_by
}

"""
Streaming cursor of the table "notification_deliveries"
"""
input notification_deliveries_stream_cursor_input {
  initial_value: notification_deliveries_stream_cursor_value_input!
  ordering: cursor_ordering
}

"""
Initial value of the column from where the streaming should start
"""
input notification_deliveries_stream_cursor_value_input {
  channel_id: Int
  id: bigint
  notification_id: Int
  read: Boolean
  read_at: timestamp
  sent_at: timestamp
  user_id: Int
}

"""
aggregate sum on columns
"""
type notification_deliveries_sum_fields {
  channel_id: Int
  id: bigint
  notification_id: Int
  user_id: Int
}

"""
order by sum() on columns of table "notification_deliveries"
"""
input notification_deliveries_sum_order_by {
  channel_id: order_by
  id: order_by
  notification_id: order_by
  user_id: order_by
}

input notification_deliveries_updates {
  _set: notification_deliveries_set_input
  where: notification_deliveries_bool_exp!
}

"""
aggregate var_pop on columns
"""
type notification_deliveries_var_pop_fields {
  channel_id: Float
  id: Float
  notification_id: Float
  user_id: Float
}

"""
order by var_pop() on columns of table "notification_deliveries"
"""
input notification_deliveries_var_pop_order_by {
  channel_id: order_by
  id: order_by
  notification_id: order_by
  user_id: order_by
}

"""
aggregate var_samp on columns
"""
type notification_deliveries_var_samp_fields {
  channel_id: Float
  id: Float
  notification_id: Float
  user_id: Float
}

"""
order by var_samp() on columns of table "notification_deliveries"
"""
input notification_deliveries_var_samp_order_by {
  channel_id: order_by
  id: order_by
  notification_id: order_by
  user_id: order_by
}

"""
aggregate variance on columns
"""
type notification_deliveries_variance_fields {
  channel_id: Float
  id: Float
  notification_id: Float
  user_id: Float
}

"""
order by variance() on columns of table "notification_deliveries"
"""
input notification_deliveries_variance_order_by {
  channel_id: order_by
  id: order_by
  notification_id: order_by
  user_id: order_by
}

"""
columns and relationships of "notification_settings"
"""
type notification_settings {
  channel_ids: json!
  id: bigint!
  notification_type_id: Int!
  user: users
  user_id: Int!
}

"""
order by aggregate values of table "notification_settings"
"""
input notification_settings_aggregate_order_by {
  avg: notification_settings_avg_order_by
  count: order_by
  max: notification_settings_max_order_by
  min: notification_settings_min_order_by
  stddev: notification_settings_stddev_order_by
  stddev_pop: notification_settings_stddev_pop_order_by
  stddev_samp: notification_settings_stddev_samp_order_by
  sum: notification_settings_sum_order_by
  var_pop: notification_settings_var_pop_order_by
  var_samp: notification_settings_var_samp_order_by
  variance: notification_settings_variance_order_by
}

"""
order by avg() on columns of table "notification_settings"
"""
input notification_settings_avg_order_by {
  id: order_by
  notification_type_id: order_by
  user_id: order_by
}

"""
Boolean expression to filter rows from the table "notification_settings". All fields are combined with a logical 'AND'.
"""
input notification_settings_bool_exp {
  _and: [notification_settings_bool_exp!]
  _not: notification_settings_bool_exp
  _or: [notification_settings_bool_exp!]
  channel_ids: json_comparison_exp
  id: bigint_comparison_exp
  notification_type_id: Int_comparison_exp
  user: users_bool_exp
  user_id: Int_comparison_exp
}

"""
unique or primary key constraints on table "notification_settings"
"""
enum notification_settings_constraint {
  notification_settings_pkey
}

"""
input type for inserting data into table "notification_settings"
"""
input notification_settings_insert_input {
  channel_ids: json
  notification_type_id: Int
  user_id: Int
}

"""
order by max() on columns of table "notification_settings"
"""
input notification_settings_max_order_by {
  id: order_by
  notification_type_id: order_by
  user_id: order_by
}

"""
order by min() on columns of table "notification_settings"
"""
input notification_settings_min_order_by {
  id: order_by
  notification_type_id: order_by
  user_id: order_by
}

"""
response of any mutation on the table "notification_settings"
"""
type notification_settings_mutation_response {
  affected_rows: Int!
  returning: [notification_settings!]!
}

"""
on_conflict condition type for table "notification_settings"
"""
input notification_settings_on_conflict {
  constraint: notification_settings_constraint!
  update_columns: [notification_settings_update_column!]!
  where: notification_settings_bool_exp
}

"""
Ordering options when selecting data from "notification_settings".
"""
input notification_settings_order_by {
  channel_ids: order_by
  id: order_by
  notification_type_id: order_by
  user: users_order_by
  user_id: order_by
}

"""
primary key columns input for table: notification_settings
"""
input notification_settings_pk_columns_input {
  id: bigint!
}

"""
select columns of table "notification_settings"
"""
enum notification_settings_select_column {
  channel_ids
  id
  notification_type_id
  user_id
}

"""
input type for updating data in table "notification_settings"
"""
input notification_settings_set_input {
  channel_ids: json
}

"""
order by stddev() on columns of table "notification_settings"
"""
input notification_settings_stddev_order_by {
  id: order_by
  notification_type_id: order_by
  user_id: order_by
}

"""
order by stddev_pop() on columns of table "notification_settings"
"""
input notification_settings_stddev_pop_order_by {
  id: order_by
  notification_type_id: order_by
  user_id: order_by
}

"""
order by stddev_samp() on columns of table "notification_settings"
"""
input notification_settings_stddev_samp_order_by {
  id: order_by
  notification_type_id: order_by
  user_id: order_by
}

"""
Streaming cursor of the table "notification_settings"
"""
input notification_settings_stream_cursor_input {
  initial_value: notification_settings_stream_cursor_value_input!
  ordering: cursor_ordering
}

"""
Initial value of the column from where the streaming should start
"""
input notification_settings_stream_cursor_value_input {
  channel_ids: json
  id: bigint
  notification_type_id: Int
  user_id: Int
}

"""
order by sum() on columns of table "notification_settings"
"""
input notification_settings_sum_order_by {
  id: order_by
  notification_type_id: order_by
  user_id: order_by
}

"""
update columns of table "notification_settings"
"""
enum notification_settings_update_column {
  channel_ids
}

input notification_settings_updates {
  _set: notification_settings_set_input
  where: notification_settings_bool_exp!
}

"""
order by var_pop() on columns of table "notification_settings"
"""
input notification_settings_var_pop_order_by {
  id: order_by
  notification_type_id: order_by
  user_id: order_by
}

"""
order by var_samp() on columns of table "notification_settings"
"""
input notification_settings_var_samp_order_by {
  id: order_by
  notification_type_id: order_by
  user_id: order_by
}

"""
order by variance() on columns of table "notification_settings"
"""
input notification_settings_variance_order_by {
  id: order_by
  notification_type_id: order_by
  user_id: order_by
}

"""
columns and relationships of "notification_types"
"""
type notification_types {
  active: Boolean
  default_channel_ids: json!
  default_priority: Int
  description: String
  id: bigint!
  name: String!
  notification_settings: [notification_settings!]!
  uid: String!
}

"""
Boolean expression to filter rows from the table "notification_types". All fields are combined with a logical 'AND'.
"""
input notification_types_bool_exp {
  _and: [notification_types_bool_exp!]
  _not: notification_types_bool_exp
  _or: [notification_types_bool_exp!]
  active: Boolean_comparison_exp
  default_channel_ids: json_comparison_exp
  default_priority: Int_comparison_exp
  description: String_comparison_exp
  id: bigint_comparison_exp
  name: String_comparison_exp
  notification_settings: notification_settings_bool_exp
  uid: String_comparison_exp
}

"""
Ordering options when selecting data from "notification_types".
"""
input notification_types_order_by {
  active: order_by
  default_channel_ids: order_by
  default_priority: order_by
  description: order_by
  id: order_by
  name: order_by
  notification_settings_aggregate: notification_settings_aggregate_order_by
  uid: order_by
}

"""
select columns of table "notification_types"
"""
enum notification_types_select_column {
  active
  default_channel_ids
  default_priority
  description
  id
  name
  uid
}

"""
Streaming cursor of the table "notification_types"
"""
input notification_types_stream_cursor_input {
  initial_value: notification_types_stream_cursor_value_input!
  ordering: cursor_ordering
}

"""
Initial value of the column from where the streaming should start
"""
input notification_types_stream_cursor_value_input {
  active: Boolean
  default_channel_ids: json
  default_priority: Int
  description: String
  id: bigint
  name: String
  uid: String
}

"""
columns and relationships of "notifications"
"""
type notifications {
  created_at: timestamptz!
  description: String!
  id: Int!
  link: String
  link_text: String
  notification_deliveries: [notification_deliveries!]!
  notification_deliveries_aggregate: notification_deliveries_aggregate!
  notification_type_id: Int!
  notifierUser: users
  notifier_user_id: Int!
  priority: Int
  title: String!
  uid: String!
}

"""
Boolean expression to filter rows from the table "notifications". All fields are combined with a logical 'AND'.
"""
input notifications_bool_exp {
  _and: [notifications_bool_exp!]
  _not: notifications_bool_exp
  _or: [notifications_bool_exp!]
  created_at: timestamptz_comparison_exp
  description: String_comparison_exp
  id: Int_comparison_exp
  link: String_comparison_exp
  link_text: String_comparison_exp
  notification_deliveries: notification_deliveries_bool_exp
  notification_deliveries_aggregate: notification_deliveries_aggregate_bool_exp
  notification_type_id: Int_comparison_exp
  notifierUser: users_bool_exp
  notifier_user_id: Int_comparison_exp
  priority: Int_comparison_exp
  title: String_comparison_exp
  uid: String_comparison_exp
}

"""
Ordering options when selecting data from "notifications".
"""
input notifications_order_by {
  created_at: order_by
  description: order_by
  id: order_by
  link: order_by
  link_text: order_by
  notification_deliveries_aggregate: notification_deliveries_aggregate_order_by
  notification_type_id: order_by
  notifierUser: users_order_by
  notifier_user_id: order_by
  priority: order_by
  title: order_by
  uid: order_by
}

"""
select columns of table "notifications"
"""
enum notifications_select_column {
  created_at
  description
  id
  link
  link_text
  notification_type_id
  notifier_user_id
  priority
  title
  uid
}

"""
Streaming cursor of the table "notifications"
"""
input notifications_stream_cursor_input {
  initial_value: notifications_stream_cursor_value_input!
  ordering: cursor_ordering
}

"""
Initial value of the column from where the streaming should start
"""
input notifications_stream_cursor_value_input {
  created_at: timestamptz
  description: String
  id: Int
  link: String
  link_text: String
  notification_type_id: Int
  notifier_user_id: Int
  priority: Int
  title: String
  uid: String
}

scalar numeric

"""
Boolean expression to compare columns of type "numeric". All fields are combined with logical 'AND'.
"""
input numeric_comparison_exp {
  _eq: numeric
  _gt: numeric
  _gte: numeric
  _in: [numeric!]
  _is_null: Boolean
  _lt: numeric
  _lte: numeric
  _neq: numeric
  _nin: [numeric!]
}

"""
column ordering options
"""
enum order_by {
  asc
  asc_nulls_first
  asc_nulls_last
  desc
  desc_nulls_first
  desc_nulls_last
}

"""
columns and relationships of "platforms"
"""
type platforms {
  book_mappings: [book_mappings!]!
  id: Int!
  name: String!
  url: String
}

"""
Boolean expression to filter rows from the table "platforms". All fields are combined with a logical 'AND'.
"""
input platforms_bool_exp {
  _and: [platforms_bool_exp!]
  _not: platforms_bool_exp
  _or: [platforms_bool_exp!]
  book_mappings: book_mappings_bool_exp
  id: Int_comparison_exp
  name: String_comparison_exp
  url: String_comparison_exp
}

"""
Ordering options when selecting data from "platforms".
"""
input platforms_order_by {
  book_mappings_aggregate: book_mappings_aggregate_order_by
  id: order_by
  name: order_by
  url: order_by
}

"""
select columns of table "platforms"
"""
enum platforms_select_column {
  id
  name
  url
}

"""
Streaming cursor of the table "platforms"
"""
input platforms_stream_cursor_input {
  initial_value: platforms_stream_cursor_value_input!
  ordering: cursor_ordering
}

"""
Initial value of the column from where the streaming should start
"""
input platforms_stream_cursor_value_input {
  id: Int
  name: String
  url: String
}

"""
columns and relationships of "privacy_settings"
"""
type privacy_settings {
  activities: [activities!]!
  id: Int!
  lists: [lists!]!
  lists_aggregate: lists_aggregate!
  prompts: [prompts!]!
  setting: String!
  user_books: [user_books!]!
  user_books_aggregate: user_books_aggregate!
  users: [users!]!
  users_by_activity: [users!]!
}

"""
Boolean expression to filter rows from the table "privacy_settings". All fields are combined with a logical 'AND'.
"""
input privacy_settings_bool_exp {
  _and: [privacy_settings_bool_exp!]
  _not: privacy_settings_bool_exp
  _or: [privacy_settings_bool_exp!]
  activities: activities_bool_exp
  id: Int_comparison_exp
  lists: lists_bool_exp
  lists_aggregate: lists_aggregate_bool_exp
  prompts: prompts_bool_exp
  setting: String_comparison_exp
  user_books: user_books_bool_exp
  user_books_aggregate: user_books_aggregate_bool_exp
  users: users_bool_exp
  users_by_activity: users_bool_exp
}

"""
Ordering options when selecting data from "privacy_settings".
"""
input privacy_settings_order_by {
  activities_aggregate: activities_aggregate_order_by
  id: order_by
  lists_aggregate: lists_aggregate_order_by
  prompts_aggregate: prompts_aggregate_order_by
  setting: order_by
  user_books_aggregate: user_books_aggregate_order_by
  users_aggregate: users_aggregate_order_by
  users_by_activity_aggregate: users_aggregate_order_by
}

"""
select columns of table "privacy_settings"
"""
enum privacy_settings_select_column {
  id
  setting
}

"""
Streaming cursor of the table "privacy_settings"
"""
input privacy_settings_stream_cursor_input {
  initial_value: privacy_settings_stream_cursor_value_input!
  ordering: cursor_ordering
}

"""
Initial value of the column from where the streaming should start
"""
input privacy_settings_stream_cursor_value_input {
  id: Int
  setting: String
}

"""
columns and relationships of "prompt_answers"
"""
type prompt_answers {
  book: books!
  book_id: Int!
  created_at: timestamptz
  description: String
  id: Int!
  merged_at: timestamp
  original_book_id: Int
  prompt: prompts!
  prompt_book: prompt_books_summary
  prompt_id: Int!
  user: users!
  user_id: Int!
}

"""
aggregated selection of "prompt_answers"
"""
type prompt_answers_aggregate {
  aggregate: prompt_answers_aggregate_fields
  nodes: [prompt_answers!]!
}

input prompt_answers_aggregate_bool_exp {
  count: prompt_answers_aggregate_bool_exp_count
}

input prompt_answers_aggregate_bool_exp_count {
  arguments: [prompt_answers_select_column!]
  distinct: Boolean
  filter: prompt_answers_bool_exp
  predicate: Int_comparison_exp!
}

"""
aggregate fields of "prompt_answers"
"""
type prompt_answers_aggregate_fields {
  avg: prompt_answers_avg_fields
  count: Int!
  max: prompt_answers_max_fields
  min: prompt_answers_min_fields
  stddev: prompt_answers_stddev_fields
  stddev_pop: prompt_answers_stddev_pop_fields
  stddev_samp: prompt_answers_stddev_samp_fields
  sum: prompt_answers_sum_fields
  var_pop: prompt_answers_var_pop_fields
  var_samp: prompt_answers_var_samp_fields
  variance: prompt_answers_variance_fields
}

"""
order by aggregate values of table "prompt_answers"
"""
input prompt_answers_aggregate_order_by {
  avg: prompt_answers_avg_order_by
  count: order_by
  max: prompt_answers_max_order_by
  min: prompt_answers_min_order_by
  stddev: prompt_answers_stddev_order_by
  stddev_pop: prompt_answers_stddev_pop_order_by
  stddev_samp: prompt_answers_stddev_samp_order_by
  sum: prompt_answers_sum_order_by
  var_pop: prompt_answers_var_pop_order_by
  var_samp: prompt_answers_var_samp_order_by
  variance: prompt_answers_variance_order_by
}

"""
aggregate avg on columns
"""
type prompt_answers_avg_fields {
  book_id: Float
  id: Float
  original_book_id: Float
  prompt_id: Float
  user_id: Float
}

"""
order by avg() on columns of table "prompt_answers"
"""
input prompt_answers_avg_order_by {
  book_id: order_by
  id: order_by
  original_book_id: order_by
  prompt_id: order_by
  user_id: order_by
}

"""
Boolean expression to filter rows from the table "prompt_answers". All fields are combined with a logical 'AND'.
"""
input prompt_answers_bool_exp {
  _and: [prompt_answers_bool_exp!]
  _not: prompt_answers_bool_exp
  _or: [prompt_answers_bool_exp!]
  book: books_bool_exp
  book_id: Int_comparison_exp
  created_at: timestamptz_comparison_exp
  description: String_comparison_exp
  id: Int_comparison_exp
  merged_at: timestamp_comparison_exp
  original_book_id: Int_comparison_exp
  prompt: prompts_bool_exp
  prompt_book: prompt_books_summary_bool_exp
  prompt_id: Int_comparison_exp
  user: users_bool_exp
  user_id: Int_comparison_exp
}

"""
aggregate max on columns
"""
type prompt_answers_max_fields {
  book_id: Int
  created_at: timestamptz
  description: String
  id: Int
  merged_at: timestamp
  original_book_id: Int
  prompt_id: Int
  user_id: Int
}

"""
order by max() on columns of table "prompt_answers"
"""
input prompt_answers_max_order_by {
  book_id: order_by
  created_at: order_by
  description: order_by
  id: order_by
  merged_at: order_by
  original_book_id: order_by
  prompt_id: order_by
  user_id: order_by
}

"""
aggregate min on columns
"""
type prompt_answers_min_fields {
  book_id: Int
  created_at: timestamptz
  description: String
  id: Int
  merged_at: timestamp
  original_book_id: Int
  prompt_id: Int
  user_id: Int
}

"""
order by min() on columns of table "prompt_answers"
"""
input prompt_answers_min_order_by {
  book_id: order_by
  created_at: order_by
  description: order_by
  id: order_by
  merged_at: order_by
  original_book_id: order_by
  prompt_id: order_by
  user_id: order_by
}

"""
response of any mutation on the table "prompt_answers"
"""
type prompt_answers_mutation_response {
  affected_rows: Int!
  returning: [prompt_answers!]!
}

"""
Ordering options when selecting data from "prompt_answers".
"""
input prompt_answers_order_by {
  book: books_order_by
  book_id: order_by
  created_at: order_by
  description: order_by
  id: order_by
  merged_at: order_by
  original_book_id: order_by
  prompt: prompts_order_by
  prompt_book: prompt_books_summary_order_by
  prompt_id: order_by
  user: users_order_by
  user_id: order_by
}

"""
primary key columns input for table: prompt_answers
"""
input prompt_answers_pk_columns_input {
  id: Int!
}

"""
select columns of table "prompt_answers"
"""
enum prompt_answers_select_column {
  book_id
  created_at
  description
  id
  merged_at
  original_book_id
  prompt_id
  user_id
}

"""
input type for updating data in table "prompt_answers"
"""
input prompt_answers_set_input {
  description: String
}

"""
aggregate stddev on columns
"""
type prompt_answers_stddev_fields {
  book_id: Float
  id: Float
  original_book_id: Float
  prompt_id: Float
  user_id: Float
}

"""
order by stddev() on columns of table "prompt_answers"
"""
input prompt_answers_stddev_order_by {
  book_id: order_by
  id: order_by
  original_book_id: order_by
  prompt_id: order_by
  user_id: order_by
}

"""
aggregate stddev_pop on columns
"""
type prompt_answers_stddev_pop_fields {
  book_id: Float
  id: Float
  original_book_id: Float
  prompt_id: Float
  user_id: Float
}

"""
order by stddev_pop() on columns of table "prompt_answers"
"""
input prompt_answers_stddev_pop_order_by {
  book_id: order_by
  id: order_by
  original_book_id: order_by
  prompt_id: order_by
  user_id: order_by
}

"""
aggregate stddev_samp on columns
"""
type prompt_answers_stddev_samp_fields {
  book_id: Float
  id: Float
  original_book_id: Float
  prompt_id: Float
  user_id: Float
}

"""
order by stddev_samp() on columns of table "prompt_answers"
"""
input prompt_answers_stddev_samp_order_by {
  book_id: order_by
  id: order_by
  original_book_id: order_by
  prompt_id: order_by
  user_id: order_by
}

"""
Streaming cursor of the table "prompt_answers"
"""
input prompt_answers_stream_cursor_input {
  initial_value: prompt_answers_stream_cursor_value_input!
  ordering: cursor_ordering
}

"""
Initial value of the column from where the streaming should start
"""
input prompt_answers_stream_cursor_value_input {
  book_id: Int
  created_at: timestamptz
  description: String
  id: Int
  merged_at: timestamp
  original_book_id: Int
  prompt_id: Int
  user_id: Int
}

"""
aggregate sum on columns
"""
type prompt_answers_sum_fields {
  book_id: Int
  id: Int
  original_book_id: Int
  prompt_id: Int
  user_id: Int
}

"""
order by sum() on columns of table "prompt_answers"
"""
input prompt_answers_sum_order_by {
  book_id: order_by
  id: order_by
  original_book_id: order_by
  prompt_id: order_by
  user_id: order_by
}

input prompt_answers_updates {
  _set: prompt_answers_set_input
  where: prompt_answers_bool_exp!
}

"""
aggregate var_pop on columns
"""
type prompt_answers_var_pop_fields {
  book_id: Float
  id: Float
  original_book_id: Float
  prompt_id: Float
  user_id: Float
}

"""
order by var_pop() on columns of table "prompt_answers"
"""
input prompt_answers_var_pop_order_by {
  book_id: order_by
  id: order_by
  original_book_id: order_by
  prompt_id: order_by
  user_id: order_by
}

"""
aggregate var_samp on columns
"""
type prompt_answers_var_samp_fields {
  book_id: Float
  id: Float
  original_book_id: Float
  prompt_id: Float
  user_id: Float
}

"""
order by var_samp() on columns of table "prompt_answers"
"""
input prompt_answers_var_samp_order_by {
  book_id: order_by
  id: order_by
  original_book_id: order_by
  prompt_id: order_by
  user_id: order_by
}

"""
aggregate variance on columns
"""
type prompt_answers_variance_fields {
  book_id: Float
  id: Float
  original_book_id: Float
  prompt_id: Float
  user_id: Float
}

"""
order by variance() on columns of table "prompt_answers"
"""
input prompt_answers_variance_order_by {
  book_id: order_by
  id: order_by
  original_book_id: order_by
  prompt_id: order_by
  user_id: order_by
}

"""
columns and relationships of "prompt_books_summary"
"""
type prompt_books_summary {
  answers_count: bigint
  book: books
  book_id: Int
  prompt: prompts
  prompt_id: Int
}

"""
order by aggregate values of table "prompt_books_summary"
"""
input prompt_books_summary_aggregate_order_by {
  avg: prompt_books_summary_avg_order_by
  count: order_by
  max: prompt_books_summary_max_order_by
  min: prompt_books_summary_min_order_by
  stddev: prompt_books_summary_stddev_order_by
  stddev_pop: prompt_books_summary_stddev_pop_order_by
  stddev_samp: prompt_books_summary_stddev_samp_order_by
  sum: prompt_books_summary_sum_order_by
  var_pop: prompt_books_summary_var_pop_order_by
  var_samp: prompt_books_summary_var_samp_order_by
  variance: prompt_books_summary_variance_order_by
}

"""
order by avg() on columns of table "prompt_books_summary"
"""
input prompt_books_summary_avg_order_by {
  answers_count: order_by
  book_id: order_by
  prompt_id: order_by
}

"""
Boolean expression to filter rows from the table "prompt_books_summary". All fields are combined with a logical 'AND'.
"""
input prompt_books_summary_bool_exp {
  _and: [prompt_books_summary_bool_exp!]
  _not: prompt_books_summary_bool_exp
  _or: [prompt_books_summary_bool_exp!]
  answers_count: bigint_comparison_exp
  book: books_bool_exp
  book_id: Int_comparison_exp
  prompt: prompts_bool_exp
  prompt_id: Int_comparison_exp
}

"""
order by max() on columns of table "prompt_books_summary"
"""
input prompt_books_summary_max_order_by {
  answers_count: order_by
  book_id: order_by
  prompt_id: order_by
}

"""
order by min() on columns of table "prompt_books_summary"
"""
input prompt_books_summary_min_order_by {
  answers_count: order_by
  book_id: order_by
  prompt_id: order_by
}

"""
Ordering options when selecting data from "prompt_books_summary".
"""
input prompt_books_summary_order_by {
  answers_count: order_by
  book: books_order_by
  book_id: order_by
  prompt: prompts_order_by
  prompt_id: order_by
}

"""
select columns of table "prompt_books_summary"
"""
enum prompt_books_summary_select_column {
  answers_count
  book_id
  prompt_id
}

"""
order by stddev() on columns of table "prompt_books_summary"
"""
input prompt_books_summary_stddev_order_by {
  answers_count: order_by
  book_id: order_by
  prompt_id: order_by
}

"""
order by stddev_pop() on columns of table "prompt_books_summary"
"""
input prompt_books_summary_stddev_pop_order_by {
  answers_count: order_by
  book_id: order_by
  prompt_id: order_by
}

"""
order by stddev_samp() on columns of table "prompt_books_summary"
"""
input prompt_books_summary_stddev_samp_order_by {
  answers_count: order_by
  book_id: order_by
  prompt_id: order_by
}

"""
Streaming cursor of the table "prompt_books_summary"
"""
input prompt_books_summary_stream_cursor_input {
  initial_value: prompt_books_summary_stream_cursor_value_input!
  ordering: cursor_ordering
}

"""
Initial value of the column from where the streaming should start
"""
input prompt_books_summary_stream_cursor_value_input {
  answers_count: bigint
  book_id: Int
  prompt_id: Int
}

"""
order by sum() on columns of table "prompt_books_summary"
"""
input prompt_books_summary_sum_order_by {
  answers_count: order_by
  book_id: order_by
  prompt_id: order_by
}

"""
order by var_pop() on columns of table "prompt_books_summary"
"""
input prompt_books_summary_var_pop_order_by {
  answers_count: order_by
  book_id: order_by
  prompt_id: order_by
}

"""
order by var_samp() on columns of table "prompt_books_summary"
"""
input prompt_books_summary_var_samp_order_by {
  answers_count: order_by
  book_id: order_by
  prompt_id: order_by
}

"""
order by variance() on columns of table "prompt_books_summary"
"""
input prompt_books_summary_variance_order_by {
  answers_count: order_by
  book_id: order_by
  prompt_id: order_by
}

"""
columns and relationships of "prompts"
"""
type prompts {
  answers_count: Int!
  books_count: Int!
  created_at: timestamptz
  description: String!
  featured: Boolean!
  followed_prompts: [followed_prompts!]!
  followers: [followed_users!]!
  id: Int!
  privacy_setting: privacy_settings!
  privacy_setting_id: Int!
  prompt_answers: [prompt_answers!]!
  prompt_answers_aggregate: prompt_answers_aggregate!
  prompt_books: [prompt_books_summary!]!
  question: String!
  slug: String!
  user: users!
  user_id: Int!
  users_count: Int!
}

"""
order by aggregate values of table "prompts"
"""
input prompts_aggregate_order_by {
  avg: prompts_avg_order_by
  count: order_by
  max: prompts_max_order_by
  min: prompts_min_order_by
  stddev: prompts_stddev_order_by
  stddev_pop: prompts_stddev_pop_order_by
  stddev_samp: prompts_stddev_samp_order_by
  sum: prompts_sum_order_by
  var_pop: prompts_var_pop_order_by
  var_samp: prompts_var_samp_order_by
  variance: prompts_variance_order_by
}

"""
order by avg() on columns of table "prompts"
"""
input prompts_avg_order_by {
  answers_count: order_by
  books_count: order_by
  id: order_by
  privacy_setting_id: order_by
  user_id: order_by
  users_count: order_by
}

"""
Boolean expression to filter rows from the table "prompts". All fields are combined with a logical 'AND'.
"""
input prompts_bool_exp {
  _and: [prompts_bool_exp!]
  _not: prompts_bool_exp
  _or: [prompts_bool_exp!]
  answers_count: Int_comparison_exp
  books_count: Int_comparison_exp
  created_at: timestamptz_comparison_exp
  description: String_comparison_exp
  featured: Boolean_comparison_exp
  followed_prompts: followed_prompts_bool_exp
  followers: followed_users_bool_exp
  id: Int_comparison_exp
  privacy_setting: privacy_settings_bool_exp
  privacy_setting_id: Int_comparison_exp
  prompt_answers: prompt_answers_bool_exp
  prompt_answers_aggregate: prompt_answers_aggregate_bool_exp
  prompt_books: prompt_books_summary_bool_exp
  question: String_comparison_exp
  slug: String_comparison_exp
  user: users_bool_exp
  user_id: Int_comparison_exp
  users_count: Int_comparison_exp
}

"""
order by max() on columns of table "prompts"
"""
input prompts_max_order_by {
  answers_count: order_by
  books_count: order_by
  created_at: order_by
  description: order_by
  id: order_by
  privacy_setting_id: order_by
  question: order_by
  slug: order_by
  user_id: order_by
  users_count: order_by
}

"""
order by min() on columns of table "prompts"
"""
input prompts_min_order_by {
  answers_count: order_by
  books_count: order_by
  created_at: order_by
  description: order_by
  id: order_by
  privacy_setting_id: order_by
  question: order_by
  slug: order_by
  user_id: order_by
  users_count: order_by
}

"""
response of any mutation on the table "prompts"
"""
type prompts_mutation_response {
  affected_rows: Int!
  returning: [prompts!]!
}

"""
Ordering options when selecting data from "prompts".
"""
input prompts_order_by {
  answers_count: order_by
  books_count: order_by
  created_at: order_by
  description: order_by
  featured: order_by
  followed_prompts_aggregate: followed_prompts_aggregate_order_by
  followers_aggregate: followed_users_aggregate_order_by
  id: order_by
  privacy_setting: privacy_settings_order_by
  privacy_setting_id: order_by
  prompt_answers_aggregate: prompt_answers_aggregate_order_by
  prompt_books_aggregate: prompt_books_summary_aggregate_order_by
  question: order_by
  slug: order_by
  user: users_order_by
  user_id: order_by
  users_count: order_by
}

"""
select columns of table "prompts"
"""
enum prompts_select_column {
  answers_count
  books_count
  created_at
  description
  featured
  id
  privacy_setting_id
  question
  slug
  user_id
  users_count
}

"""
order by stddev() on columns of table "prompts"
"""
input prompts_stddev_order_by {
  answers_count: order_by
  books_count: order_by
  id: order_by
  privacy_setting_id: order_by
  user_id: order_by
  users_count: order_by
}

"""
order by stddev_pop() on columns of table "prompts"
"""
input prompts_stddev_pop_order_by {
  answers_count: order_by
  books_count: order_by
  id: order_by
  privacy_setting_id: order_by
  user_id: order_by
  users_count: order_by
}

"""
order by stddev_samp() on columns of table "prompts"
"""
input prompts_stddev_samp_order_by {
  answers_count: order_by
  books_count: order_by
  id: order_by
  privacy_setting_id: order_by
  user_id: order_by
  users_count: order_by
}

"""
Streaming cursor of the table "prompts"
"""
input prompts_stream_cursor_input {
  initial_value: prompts_stream_cursor_value_input!
  ordering: cursor_ordering
}

"""
Initial value of the column from where the streaming should start
"""
input prompts_stream_cursor_value_input {
  answers_count: Int
  books_count: Int
  created_at: timestamptz
  description: String
  featured: Boolean
  id: Int
  privacy_setting_id: Int
  question: String
  slug: String
  user_id: Int
  users_count: Int
}

"""
order by sum() on columns of table "prompts"
"""
input prompts_sum_order_by {
  answers_count: order_by
  books_count: order_by
  id: order_by
  privacy_setting_id: order_by
  user_id: order_by
  users_count: order_by
}

"""
order by var_pop() on columns of table "prompts"
"""
input prompts_var_pop_order_by {
  answers_count: order_by
  books_count: order_by
  id: order_by
  privacy_setting_id: order_by
  user_id: order_by
  users_count: order_by
}

"""
order by var_samp() on columns of table "prompts"
"""
input prompts_var_samp_order_by {
  answers_count: order_by
  books_count: order_by
  id: order_by
  privacy_setting_id: order_by
  user_id: order_by
  users_count: order_by
}

"""
order by variance() on columns of table "prompts"
"""
input prompts_variance_order_by {
  answers_count: order_by
  books_count: order_by
  id: order_by
  privacy_setting_id: order_by
  user_id: order_by
  users_count: order_by
}

"""
columns and relationships of "publishers"
"""
type publishers {
  canonical_id: Int
  created_at: timestamp!
  editions: [editions!]!
  editions_count: Int!
  id: bigint!
  locked: Boolean!
  name: String
  parent_id: Int
  parent_publisher: publishers
  slug: String!
  state: String!
  updated_at: timestamp!
  user_id: Int
}

"""
Boolean expression to filter rows from the table "publishers". All fields are combined with a logical 'AND'.
"""
input publishers_bool_exp {
  _and: [publishers_bool_exp!]
  _not: publishers_bool_exp
  _or: [publishers_bool_exp!]
  canonical_id: Int_comparison_exp
  created_at: timestamp_comparison_exp
  editions: editions_bool_exp
  editions_count: Int_comparison_exp
  id: bigint_comparison_exp
  locked: Boolean_comparison_exp
  name: String_comparison_exp
  parent_id: Int_comparison_exp
  parent_publisher: publishers_bool_exp
  slug: String_comparison_exp
  state: String_comparison_exp
  updated_at: timestamp_comparison_exp
  user_id: Int_comparison_exp
}

"""
Ordering options when selecting data from "publishers".
"""
input publishers_order_by {
  canonical_id: order_by
  created_at: order_by
  editions_aggregate: editions_aggregate_order_by
  editions_count: order_by
  id: order_by
  locked: order_by
  name: order_by
  parent_id: order_by
  parent_publisher: publishers_order_by
  slug: order_by
  state: order_by
  updated_at: order_by
  user_id: order_by
}

"""
select columns of table "publishers"
"""
enum publishers_select_column {
  canonical_id
  created_at
  editions_count
  id
  locked
  name
  parent_id
  slug
  state
  updated_at
  user_id
}

"""
Streaming cursor of the table "publishers"
"""
input publishers_stream_cursor_input {
  initial_value: publishers_stream_cursor_value_input!
  ordering: cursor_ordering
}

"""
Initial value of the column from where the streaming should start
"""
input publishers_stream_cursor_value_input {
  canonical_id: Int
  created_at: timestamp
  editions_count: Int
  id: bigint
  locked: Boolean
  name: String
  parent_id: Int
  slug: String
  state: String
  updated_at: timestamp
  user_id: Int
}

type Query {
  activities: [activities!]!
  activities_by_pk: activities
  activity_feed: [activities!]!
  activity_foryou_feed: [activities!]!
  authors: [authors!]!
  authors_by_pk: authors
  book_categories: [book_categories!]!
  book_categories_by_pk: book_categories
  book_characters: [book_characters!]!
  book_characters_by_pk: book_characters
  book_collections: [book_collections!]!
  book_collections_by_pk: book_collections
  book_mappings: [book_mappings!]!
  book_mappings_by_pk: book_mappings
  book_series: [book_series!]!
  book_series_aggregate: book_series_aggregate!
  book_series_by_pk: book_series
  book_statuses: [book_statuses!]!
  book_statuses_by_pk: book_statuses
  bookles: [bookles!]!
  bookles_by_pk: bookles
  books: [books!]!
  books_aggregate: books_aggregate!
  # PATCHED: Added missing id parameter to books_by_pk field
  books_by_pk(id: Int!): books
  books_trending: TrendingBookType
  characters: [characters!]!
  characters_by_pk: characters
  collection_import_results: [collection_import_results!]!
  collection_import_results_by_pk: collection_import_results
  collection_imports: [collection_imports!]!
  collection_imports_by_pk: collection_imports
  contributions: [contributions!]!
  contributions_aggregate: contributions_aggregate!
  contributions_by_pk: contributions
  countries: [countries!]!
  countries_by_pk: countries
  editions: [editions!]!
  editions_by_pk: editions
  flag_statuses: [flag_statuses!]!
  flag_statuses_by_pk: flag_statuses
  followed_lists: [followed_lists!]!
  followed_lists_by_pk: followed_lists
  followed_prompts: [followed_prompts!]!
  followed_prompts_by_pk: followed_prompts
  followed_user_books: [followed_user_books!]!
  followed_user_books_aggregate: followed_user_books_aggregate!
  followed_users: [followed_users!]!
  followed_users_by_pk: followed_users
  following_user_books: [following_user_books!]!
  following_user_books_aggregate: following_user_books_aggregate!
  goals: [goals!]!
  goals_by_pk: goals
  images: [images!]!
  images_by_pk: images
  languages: [languages!]!
  languages_by_pk: languages
  likes: [likes!]!
  likes_by_pk: likes
  list_books: [list_books!]!
  list_books_aggregate: list_books_aggregate!
  list_books_by_pk: list_books
  lists: [lists!]!
  lists_aggregate: lists_aggregate!
  lists_by_pk: lists
  me: [users!]!
  newsletter: NewsletterStatusType
  notification_channels: [notification_channels!]!
  notification_channels_by_pk: notification_channels
  notification_deliveries: [notification_deliveries!]!
  notification_deliveries_aggregate: notification_deliveries_aggregate!
  notification_deliveries_by_pk: notification_deliveries
  notification_settings: [notification_settings!]!
  notification_settings_by_pk: notification_settings
  notification_types: [notification_types!]!
  notification_types_by_pk: notification_types
  notifications: [notifications!]!
  notifications_by_pk: notifications
  platforms: [platforms!]!
  platforms_by_pk: platforms
  privacy_settings: [privacy_settings!]!
  privacy_settings_by_pk: privacy_settings
  prompt_answers: [prompt_answers!]!
  prompt_answers_aggregate: prompt_answers_aggregate!
  prompt_answers_by_pk: prompt_answers
  prompt_books_summary: [prompt_books_summary!]!
  prompts: [prompts!]!
  prompts_by_pk: prompts
  publishers: [publishers!]!
  publishers_by_pk: publishers
  reading_formats: [reading_formats!]!
  reading_formats_by_pk: reading_formats
  reading_journals: [reading_journals!]!
  reading_journals_by_pk: reading_journals
  reading_journals_summary: [reading_journals_summary!]!
  recommendations: [recommendations!]!
  recommendations_by_pk: recommendations
  referrals_for_user: [ReferralType]
  # PATCHED: Added missing parameters to search field to match API documentation
  # The introspection schema doesn't expose these parameters, but the API supports them
  # See: https://docs.hardcover.app/api/guides/searching/
  search(
    query: String!
    query_type: String
    per_page: Int
    page: Int
    sort: String
    fields: String
    weights: String
  ): SearchOutput
  series: [series!]!
  series_by_pk: series
  subscriptions: SubscriptionsType
  tag_categories: [tag_categories!]!
  tag_categories_by_pk: tag_categories
  taggable_counts: [taggable_counts!]!
  taggable_counts_by_pk: taggable_counts
  taggings: [taggings!]!
  taggings_aggregate: taggings_aggregate!
  taggings_by_pk: taggings
  tags: [tags!]!
  tags_aggregate: tags_aggregate!
  tags_by_pk: tags
  user_blocks: [user_blocks!]!
  user_blocks_by_pk: user_blocks
  user_book_reads: [user_book_reads!]!
  user_book_reads_aggregate: user_book_reads_aggregate!
  user_book_reads_by_pk: user_book_reads
  user_book_statuses: [user_book_statuses!]!
  user_book_statuses_aggregate: user_book_statuses_aggregate!
  user_book_statuses_by_pk: user_book_statuses
  user_books: [user_books!]!
  user_books_aggregate: user_books_aggregate!
  user_books_by_pk: user_books
  user_flags: [user_flags!]!
  user_flags_by_pk: user_flags
  user_referrals: [user_referrals!]!
  user_referrals_by_pk: user_referrals
  user_statuses: [user_statuses!]!
  user_statuses_by_pk: user_statuses
  users: [users!]!
  users_aggregate_by_created_at_date: [users_aggregate_by_created_at_date!]!
  users_by_pk: users
}

"""
columns and relationships of "reading_formats"
"""
type reading_formats {
  format: String!
  id: Int!
}

"""
Boolean expression to filter rows from the table "reading_formats". All fields are combined with a logical 'AND'.
"""
input reading_formats_bool_exp {
  _and: [reading_formats_bool_exp!]
  _not: reading_formats_bool_exp
  _or: [reading_formats_bool_exp!]
  format: String_comparison_exp
  id: Int_comparison_exp
}

"""
Ordering options when selecting data from "reading_formats".
"""
input reading_formats_order_by {
  format: order_by
  id: order_by
}

"""
select columns of table "reading_formats"
"""
enum reading_formats_select_column {
  format
  id
}

"""
Streaming cursor of the table "reading_formats"
"""
input reading_formats_stream_cursor_input {
  initial_value: reading_formats_stream_cursor_value_input!
  ordering: cursor_ordering
}

"""
Initial value of the column from where the streaming should start
"""
input reading_formats_stream_cursor_value_input {
  format: String
  id: Int
}

"""
columns and relationships of "reading_journals"
"""
type reading_journals {
  book: books
  book_id: Int
  created_at: timestamp!
  edition: editions
  edition_id: Int
  entry: String
  event: String
  followers: [followed_users!]!
  id: bigint!
  likes: [likes!]!
  likes_count: Int!
  metadata: jsonb!
  object_type: String!
  privacy_setting_id: Int!
  taggings: [taggings!]!
  taggings_aggregate: taggings_aggregate!
  updated_at: timestamp!
  user: users
  user_id: Int
}

"""
order by aggregate values of table "reading_journals"
"""
input reading_journals_aggregate_order_by {
  avg: reading_journals_avg_order_by
  count: order_by
  max: reading_journals_max_order_by
  min: reading_journals_min_order_by
  stddev: reading_journals_stddev_order_by
  stddev_pop: reading_journals_stddev_pop_order_by
  stddev_samp: reading_journals_stddev_samp_order_by
  sum: reading_journals_sum_order_by
  var_pop: reading_journals_var_pop_order_by
  var_samp: reading_journals_var_samp_order_by
  variance: reading_journals_variance_order_by
}

"""
order by avg() on columns of table "reading_journals"
"""
input reading_journals_avg_order_by {
  book_id: order_by
  edition_id: order_by
  id: order_by
  likes_count: order_by
  privacy_setting_id: order_by
  user_id: order_by
}

"""
Boolean expression to filter rows from the table "reading_journals". All fields are combined with a logical 'AND'.
"""
input reading_journals_bool_exp {
  _and: [reading_journals_bool_exp!]
  _not: reading_journals_bool_exp
  _or: [reading_journals_bool_exp!]
  book: books_bool_exp
  book_id: Int_comparison_exp
  created_at: timestamp_comparison_exp
  edition: editions_bool_exp
  edition_id: Int_comparison_exp
  entry: String_comparison_exp
  event: String_comparison_exp
  followers: followed_users_bool_exp
  id: bigint_comparison_exp
  likes: likes_bool_exp
  likes_count: Int_comparison_exp
  metadata: jsonb_comparison_exp
  object_type: String_comparison_exp
  privacy_setting_id: Int_comparison_exp
  taggings: taggings_bool_exp
  taggings_aggregate: taggings_aggregate_bool_exp
  updated_at: timestamp_comparison_exp
  user: users_bool_exp
  user_id: Int_comparison_exp
}

"""
order by max() on columns of table "reading_journals"
"""
input reading_journals_max_order_by {
  book_id: order_by
  created_at: order_by
  edition_id: order_by
  entry: order_by
  event: order_by
  id: order_by
  likes_count: order_by
  object_type: order_by
  privacy_setting_id: order_by
  updated_at: order_by
  user_id: order_by
}

"""
order by min() on columns of table "reading_journals"
"""
input reading_journals_min_order_by {
  book_id: order_by
  created_at: order_by
  edition_id: order_by
  entry: order_by
  event: order_by
  id: order_by
  likes_count: order_by
  object_type: order_by
  privacy_setting_id: order_by
  updated_at: order_by
  user_id: order_by
}

"""
Ordering options when selecting data from "reading_journals".
"""
input reading_journals_order_by {
  book: books_order_by
  book_id: order_by
  created_at: order_by
  edition: editions_order_by
  edition_id: order_by
  entry: order_by
  event: order_by
  followers_aggregate: followed_users_aggregate_order_by
  id: order_by
  likes_aggregate: likes_aggregate_order_by
  likes_count: order_by
  metadata: order_by
  object_type: order_by
  privacy_setting_id: order_by
  taggings_aggregate: taggings_aggregate_order_by
  updated_at: order_by
  user: users_order_by
  user_id: order_by
}

"""
select columns of table "reading_journals"
"""
enum reading_journals_select_column {
  book_id
  created_at
  edition_id
  entry
  event
  id
  likes_count
  metadata
  object_type
  privacy_setting_id
  updated_at
  user_id
}

"""
order by stddev() on columns of table "reading_journals"
"""
input reading_journals_stddev_order_by {
  book_id: order_by
  edition_id: order_by
  id: order_by
  likes_count: order_by
  privacy_setting_id: order_by
  user_id: order_by
}

"""
order by stddev_pop() on columns of table "reading_journals"
"""
input reading_journals_stddev_pop_order_by {
  book_id: order_by
  edition_id: order_by
  id: order_by
  likes_count: order_by
  privacy_setting_id: order_by
  user_id: order_by
}

"""
order by stddev_samp() on columns of table "reading_journals"
"""
input reading_journals_stddev_samp_order_by {
  book_id: order_by
  edition_id: order_by
  id: order_by
  likes_count: order_by
  privacy_setting_id: order_by
  user_id: order_by
}

"""
Streaming cursor of the table "reading_journals"
"""
input reading_journals_stream_cursor_input {
  initial_value: reading_journals_stream_cursor_value_input!
  ordering: cursor_ordering
}

"""
Initial value of the column from where the streaming should start
"""
input reading_journals_stream_cursor_value_input {
  book_id: Int
  created_at: timestamp
  edition_id: Int
  entry: String
  event: String
  id: bigint
  likes_count: Int
  metadata: jsonb
  object_type: String
  privacy_setting_id: Int
  updated_at: timestamp
  user_id: Int
}

"""
order by sum() on columns of table "reading_journals"
"""
input reading_journals_sum_order_by {
  book_id: order_by
  edition_id: order_by
  id: order_by
  likes_count: order_by
  privacy_setting_id: order_by
  user_id: order_by
}

"""
columns and relationships of "reading_journals_summary"
"""
type reading_journals_summary {
  book: books
  book_id: Int
  followers: [followed_users!]!
  journals_count: bigint
  last_updated_at: timestamp
  reading_journals: [reading_journals!]!
  user: users
  user_id: Int
}

"""
Boolean expression to filter rows from the table "reading_journals_summary". All fields are combined with a logical 'AND'.
"""
input reading_journals_summary_bool_exp {
  _and: [reading_journals_summary_bool_exp!]
  _not: reading_journals_summary_bool_exp
  _or: [reading_journals_summary_bool_exp!]
  book: books_bool_exp
  book_id: Int_comparison_exp
  followers: followed_users_bool_exp
  journals_count: bigint_comparison_exp
  last_updated_at: timestamp_comparison_exp
  reading_journals: reading_journals_bool_exp
  user: users_bool_exp
  user_id: Int_comparison_exp
}

"""
Ordering options when selecting data from "reading_journals_summary".
"""
input reading_journals_summary_order_by {
  book: books_order_by
  book_id: order_by
  followers_aggregate: followed_users_aggregate_order_by
  journals_count: order_by
  last_updated_at: order_by
  reading_journals_aggregate: reading_journals_aggregate_order_by
  user: users_order_by
  user_id: order_by
}

"""
select columns of table "reading_journals_summary"
"""
enum reading_journals_summary_select_column {
  book_id
  journals_count
  last_updated_at
  user_id
}

"""
Streaming cursor of the table "reading_journals_summary"
"""
input reading_journals_summary_stream_cursor_input {
  initial_value: reading_journals_summary_stream_cursor_value_input!
  ordering: cursor_ordering
}

"""
Initial value of the column from where the streaming should start
"""
input reading_journals_summary_stream_cursor_value_input {
  book_id: Int
  journals_count: bigint
  last_updated_at: timestamp
  user_id: Int
}

"""
order by var_pop() on columns of table "reading_journals"
"""
input reading_journals_var_pop_order_by {
  book_id: order_by
  edition_id: order_by
  id: order_by
  likes_count: order_by
  privacy_setting_id: order_by
  user_id: order_by
}

"""
order by var_samp() on columns of table "reading_journals"
"""
input reading_journals_var_samp_order_by {
  book_id: order_by
  edition_id: order_by
  id: order_by
  likes_count: order_by
  privacy_setting_id: order_by
  user_id: order_by
}

"""
order by variance() on columns of table "reading_journals"
"""
input reading_journals_variance_order_by {
  book_id: order_by
  edition_id: order_by
  id: order_by
  likes_count: order_by
  privacy_setting_id: order_by
  user_id: order_by
}

"""
columns and relationships of "disco_recommendations"
"""
type recommendations {
  context: String
  created_at: timestamp!
  id: bigint!
  item_book: books
  item_id: bigint
  item_type: String
  item_user: users
  score: float8
  subject_id: bigint
  subject_type: String
  subject_user: users
  updated_at: timestamp!
}

"""
order by aggregate values of table "disco_recommendations"
"""
input recommendations_aggregate_order_by {
  avg: recommendations_avg_order_by
  count: order_by
  max: recommendations_max_order_by
  min: recommendations_min_order_by
  stddev: recommendations_stddev_order_by
  stddev_pop: recommendations_stddev_pop_order_by
  stddev_samp: recommendations_stddev_samp_order_by
  sum: recommendations_sum_order_by
  var_pop: recommendations_var_pop_order_by
  var_samp: recommendations_var_samp_order_by
  variance: recommendations_variance_order_by
}

"""
order by avg() on columns of table "disco_recommendations"
"""
input recommendations_avg_order_by {
  id: order_by
  item_id: order_by
  score: order_by
  subject_id: order_by
}

"""
Boolean expression to filter rows from the table "disco_recommendations". All fields are combined with a logical 'AND'.
"""
input recommendations_bool_exp {
  _and: [recommendations_bool_exp!]
  _not: recommendations_bool_exp
  _or: [recommendations_bool_exp!]
  context: String_comparison_exp
  created_at: timestamp_comparison_exp
  id: bigint_comparison_exp
  item_book: books_bool_exp
  item_id: bigint_comparison_exp
  item_type: String_comparison_exp
  item_user: users_bool_exp
  score: float8_comparison_exp
  subject_id: bigint_comparison_exp
  subject_type: String_comparison_exp
  subject_user: users_bool_exp
  updated_at: timestamp_comparison_exp
}

"""
order by max() on columns of table "disco_recommendations"
"""
input recommendations_max_order_by {
  context: order_by
  created_at: order_by
  id: order_by
  item_id: order_by
  item_type: order_by
  score: order_by
  subject_id: order_by
  subject_type: order_by
  updated_at: order_by
}

"""
order by min() on columns of table "disco_recommendations"
"""
input recommendations_min_order_by {
  context: order_by
  created_at: order_by
  id: order_by
  item_id: order_by
  item_type: order_by
  score: order_by
  subject_id: order_by
  subject_type: order_by
  updated_at: order_by
}

"""
Ordering options when selecting data from "disco_recommendations".
"""
input recommendations_order_by {
  context: order_by
  created_at: order_by
  id: order_by
  item_book: books_order_by
  item_id: order_by
  item_type: order_by
  item_user: users_order_by
  score: order_by
  subject_id: order_by
  subject_type: order_by
  subject_user: users_order_by
  updated_at: order_by
}

"""
select columns of table "disco_recommendations"
"""
enum recommendations_select_column {
  context
  created_at
  id
  item_id
  item_type
  score
  subject_id
  subject_type
  updated_at
}

"""
order by stddev() on columns of table "disco_recommendations"
"""
input recommendations_stddev_order_by {
  id: order_by
  item_id: order_by
  score: order_by
  subject_id: order_by
}

"""
order by stddev_pop() on columns of table "disco_recommendations"
"""
input recommendations_stddev_pop_order_by {
  id: order_by
  item_id: order_by
  score: order_by
  subject_id: order_by
}

"""
order by stddev_samp() on columns of table "disco_recommendations"
"""
input recommendations_stddev_samp_order_by {
  id: order_by
  item_id: order_by
  score: order_by
  subject_id: order_by
}

"""
Streaming cursor of the table "recommendations"
"""
input recommendations_stream_cursor_input {
  initial_value: recommendations_stream_cursor_value_input!
  ordering: cursor_ordering
}

"""
Initial value of the column from where the streaming should start
"""
input recommendations_stream_cursor_value_input {
  context: String
  created_at: timestamp
  id: bigint
  item_id: bigint
  item_type: String
  score: float8
  subject_id: bigint
  subject_type: String
  updated_at: timestamp
}

"""
order by sum() on columns of table "disco_recommendations"
"""
input recommendations_sum_order_by {
  id: order_by
  item_id: order_by
  score: order_by
  subject_id: order_by
}

"""
order by var_pop() on columns of table "disco_recommendations"
"""
input recommendations_var_pop_order_by {
  id: order_by
  item_id: order_by
  score: order_by
  subject_id: order_by
}

"""
order by var_samp() on columns of table "disco_recommendations"
"""
input recommendations_var_samp_order_by {
  id: order_by
  item_id: order_by
  score: order_by
  subject_id: order_by
}

"""
order by variance() on columns of table "disco_recommendations"
"""
input recommendations_variance_order_by {
  id: order_by
  item_id: order_by
  score: order_by
  subject_id: order_by
}

"""
columns and relationships of "series"
"""
type series {
  author: authors
  author_id: Int
  book_series: [book_series!]!
  book_series_aggregate: book_series_aggregate!
  books_count: Int!
  canonical: series
  canonical_id: Int
  creator: users
  description: String
  id: Int!
  identifiers: jsonb!
  is_completed: Boolean
  locked: Boolean!
  name: String!
  primary_books_count: Int
  slug: String!
  state: String!
  user_id: Int
}

"""
Boolean expression to filter rows from the table "series". All fields are combined with a logical 'AND'.
"""
input series_bool_exp {
  _and: [series_bool_exp!]
  _not: series_bool_exp
  _or: [series_bool_exp!]
  author: authors_bool_exp
  author_id: Int_comparison_exp
  book_series: book_series_bool_exp
  book_series_aggregate: book_series_aggregate_bool_exp
  books_count: Int_comparison_exp
  canonical: series_bool_exp
  canonical_id: Int_comparison_exp
  creator: users_bool_exp
  description: String_comparison_exp
  id: Int_comparison_exp
  identifiers: jsonb_comparison_exp
  is_completed: Boolean_comparison_exp
  locked: Boolean_comparison_exp
  name: String_comparison_exp
  primary_books_count: Int_comparison_exp
  slug: String_comparison_exp
  state: String_comparison_exp
  user_id: Int_comparison_exp
}

"""
Ordering options when selecting data from "series".
"""
input series_order_by {
  author: authors_order_by
  author_id: order_by
  book_series_aggregate: book_series_aggregate_order_by
  books_count: order_by
  canonical: series_order_by
  canonical_id: order_by
  creator: users_order_by
  description: order_by
  id: order_by
  identifiers: order_by
  is_completed: order_by
  locked: order_by
  name: order_by
  primary_books_count: order_by
  slug: order_by
  state: order_by
  user_id: order_by
}

"""
select columns of table "series"
"""
enum series_select_column {
  author_id
  books_count
  canonical_id
  description
  id
  identifiers
  is_completed
  locked
  name
  primary_books_count
  slug
  state
  user_id
}

"""
Streaming cursor of the table "series"
"""
input series_stream_cursor_input {
  initial_value: series_stream_cursor_value_input!
  ordering: cursor_ordering
}

"""
Initial value of the column from where the streaming should start
"""
input series_stream_cursor_value_input {
  author_id: Int
  books_count: Int
  canonical_id: Int
  description: String
  id: Int
  identifiers: jsonb
  is_completed: Boolean
  locked: Boolean
  name: String
  primary_books_count: Int
  slug: String
  state: String
  user_id: Int
}

scalar smallint

"""
Boolean expression to compare columns of type "smallint". All fields are combined with logical 'AND'.
"""
input smallint_comparison_exp {
  _eq: smallint
  _gt: smallint
  _gte: smallint
  _in: [smallint!]
  _is_null: Boolean
  _lt: smallint
  _lte: smallint
  _neq: smallint
  _nin: [smallint!]
}

type subscription_root {
  activities: [activities!]!
  activities_by_pk: activities
  activities_stream: [activities!]!
  activity_feed: [activities!]!
  activity_foryou_feed: [activities!]!
  authors: [authors!]!
  authors_by_pk: authors
  authors_stream: [authors!]!
  book_categories: [book_categories!]!
  book_categories_by_pk: book_categories
  book_categories_stream: [book_categories!]!
  book_characters: [book_characters!]!
  book_characters_by_pk: book_characters
  book_characters_stream: [book_characters!]!
  book_collections: [book_collections!]!
  book_collections_by_pk: book_collections
  book_collections_stream: [book_collections!]!
  book_mappings: [book_mappings!]!
  book_mappings_by_pk: book_mappings
  book_mappings_stream: [book_mappings!]!
  book_series: [book_series!]!
  book_series_aggregate: book_series_aggregate!
  book_series_by_pk: book_series
  book_series_stream: [book_series!]!
  book_statuses: [book_statuses!]!
  book_statuses_by_pk: book_statuses
  book_statuses_stream: [book_statuses!]!
  bookles: [bookles!]!
  bookles_by_pk: bookles
  bookles_stream: [bookles!]!
  books: [books!]!
  books_aggregate: books_aggregate!
  books_by_pk: books
  books_stream: [books!]!
  characters: [characters!]!
  characters_by_pk: characters
  characters_stream: [characters!]!
  collection_import_results: [collection_import_results!]!
  collection_import_results_by_pk: collection_import_results
  collection_import_results_stream: [collection_import_results!]!
  collection_imports: [collection_imports!]!
  collection_imports_by_pk: collection_imports
  collection_imports_stream: [collection_imports!]!
  contributions: [contributions!]!
  contributions_aggregate: contributions_aggregate!
  contributions_by_pk: contributions
  contributions_stream: [contributions!]!
  countries: [countries!]!
  countries_by_pk: countries
  countries_stream: [countries!]!
  editions: [editions!]!
  editions_by_pk: editions
  editions_stream: [editions!]!
  flag_statuses: [flag_statuses!]!
  flag_statuses_by_pk: flag_statuses
  flag_statuses_stream: [flag_statuses!]!
  followed_lists: [followed_lists!]!
  followed_lists_by_pk: followed_lists
  followed_lists_stream: [followed_lists!]!
  followed_prompts: [followed_prompts!]!
  followed_prompts_by_pk: followed_prompts
  followed_prompts_stream: [followed_prompts!]!
  followed_user_books: [followed_user_books!]!
  followed_user_books_aggregate: followed_user_books_aggregate!
  followed_user_books_stream: [followed_user_books!]!
  followed_users: [followed_users!]!
  followed_users_by_pk: followed_users
  followed_users_stream: [followed_users!]!
  following_user_books: [following_user_books!]!
  following_user_books_aggregate: following_user_books_aggregate!
  following_user_books_stream: [following_user_books!]!
  goals: [goals!]!
  goals_by_pk: goals
  goals_stream: [goals!]!
  images: [images!]!
  images_by_pk: images
  images_stream: [images!]!
  languages: [languages!]!
  languages_by_pk: languages
  languages_stream: [languages!]!
  likes: [likes!]!
  likes_by_pk: likes
  likes_stream: [likes!]!
  list_books: [list_books!]!
  list_books_aggregate: list_books_aggregate!
  list_books_by_pk: list_books
  list_books_stream: [list_books!]!
  lists: [lists!]!
  lists_aggregate: lists_aggregate!
  lists_by_pk: lists
  lists_stream: [lists!]!
  me: [users!]!
  notification_channels: [notification_channels!]!
  notification_channels_by_pk: notification_channels
  notification_channels_stream: [notification_channels!]!
  notification_deliveries: [notification_deliveries!]!
  notification_deliveries_aggregate: notification_deliveries_aggregate!
  notification_deliveries_by_pk: notification_deliveries
  notification_deliveries_stream: [notification_deliveries!]!
  notification_settings: [notification_settings!]!
  notification_settings_by_pk: notification_settings
  notification_settings_stream: [notification_settings!]!
  notification_types: [notification_types!]!
  notification_types_by_pk: notification_types
  notification_types_stream: [notification_types!]!
  notifications: [notifications!]!
  notifications_by_pk: notifications
  notifications_stream: [notifications!]!
  platforms: [platforms!]!
  platforms_by_pk: platforms
  platforms_stream: [platforms!]!
  privacy_settings: [privacy_settings!]!
  privacy_settings_by_pk: privacy_settings
  privacy_settings_stream: [privacy_settings!]!
  prompt_answers: [prompt_answers!]!
  prompt_answers_aggregate: prompt_answers_aggregate!
  prompt_answers_by_pk: prompt_answers
  prompt_answers_stream: [prompt_answers!]!
  prompt_books_summary: [prompt_books_summary!]!
  prompt_books_summary_stream: [prompt_books_summary!]!
  prompts: [prompts!]!
  prompts_by_pk: prompts
  prompts_stream: [prompts!]!
  publishers: [publishers!]!
  publishers_by_pk: publishers
  publishers_stream: [publishers!]!
  reading_formats: [reading_formats!]!
  reading_formats_by_pk: reading_formats
  reading_formats_stream: [reading_formats!]!
  reading_journals: [reading_journals!]!
  reading_journals_by_pk: reading_journals
  reading_journals_stream: [reading_journals!]!
  reading_journals_summary: [reading_journals_summary!]!
  reading_journals_summary_stream: [reading_journals_summary!]!
  recommendations: [recommendations!]!
  recommendations_by_pk: recommendations
  recommendations_stream: [recommendations!]!
  series: [series!]!
  series_by_pk: series
  series_stream: [series!]!
  tag_categories: [tag_categories!]!
  tag_categories_by_pk: tag_categories
  tag_categories_stream: [tag_categories!]!
  taggable_counts: [taggable_counts!]!
  taggable_counts_by_pk: taggable_counts
  taggable_counts_stream: [taggable_counts!]!
  taggings: [taggings!]!
  taggings_aggregate: taggings_aggregate!
  taggings_by_pk: taggings
  taggings_stream: [taggings!]!
  tags: [tags!]!
  tags_aggregate: tags_aggregate!
  tags_by_pk: tags
  tags_stream: [tags!]!
  user_blocks: [user_blocks!]!
  user_blocks_by_pk: user_blocks
  user_blocks_stream: [user_blocks!]!
  user_book_reads: [user_book_reads!]!
  user_book_reads_aggregate: user_book_reads_aggregate!
  user_book_reads_by_pk: user_book_reads
  user_book_reads_stream: [user_book_reads!]!
  user_book_statuses: [user_book_statuses!]!
  user_book_statuses_aggregate: user_book_statuses_aggregate!
  user_book_statuses_by_pk: user_book_statuses
  user_book_statuses_stream: [user_book_statuses!]!
  user_books: [user_books!]!
  user_books_aggregate: user_books_aggregate!
  user_books_by_pk: user_books
  user_books_stream: [user_books!]!
  user_flags: [user_flags!]!
  user_flags_by_pk: user_flags
  user_flags_stream: [user_flags!]!
  user_referrals: [user_referrals!]!
  user_referrals_by_pk: user_referrals
  user_referrals_stream: [user_referrals!]!
  user_statuses: [user_statuses!]!
  user_statuses_by_pk: user_statuses
  user_statuses_stream: [user_statuses!]!
  users: [users!]!
  users_aggregate_by_created_at_date: [users_aggregate_by_created_at_date!]!
  users_aggregate_by_created_at_date_stream: [users_aggregate_by_created_at_date!]!
  users_by_pk: users
  users_stream: [users!]!
}

"""
columns and relationships of "tag_categories"
"""
type tag_categories {
  category: String
  created_at: timestamp
  id: bigint!
  slug: String
  tags: [tags!]!
  tags_aggregate: tags_aggregate!
}

"""
Boolean expression to filter rows from the table "tag_categories". All fields are combined with a logical 'AND'.
"""
input tag_categories_bool_exp {
  _and: [tag_categories_bool_exp!]
  _not: tag_categories_bool_exp
  _or: [tag_categories_bool_exp!]
  category: String_comparison_exp
  created_at: timestamp_comparison_exp
  id: bigint_comparison_exp
  slug: String_comparison_exp
  tags: tags_bool_exp
  tags_aggregate: tags_aggregate_bool_exp
}

"""
Ordering options when selecting data from "tag_categories".
"""
input tag_categories_order_by {
  category: order_by
  created_at: order_by
  id: order_by
  slug: order_by
  tags_aggregate: tags_aggregate_order_by
}

"""
select columns of table "tag_categories"
"""
enum tag_categories_select_column {
  category
  created_at
  id
  slug
}

"""
Streaming cursor of the table "tag_categories"
"""
input tag_categories_stream_cursor_input {
  initial_value: tag_categories_stream_cursor_value_input!
  ordering: cursor_ordering
}

"""
Initial value of the column from where the streaming should start
"""
input tag_categories_stream_cursor_value_input {
  category: String
  created_at: timestamp
  id: bigint
  slug: String
}

"""
columns and relationships of "taggable_counts"
"""
type taggable_counts {
  book: books
  count: Int!
  created_at: timestamp!
  hardcover_tagged: Boolean!
  id: bigint!
  spoiler_ratio: float8
  tag: tags
  tag_id: Int!
  taggable_id: bigint!
  taggable_type: String!
  updated_at: timestamp!
}

"""
order by aggregate values of table "taggable_counts"
"""
input taggable_counts_aggregate_order_by {
  avg: taggable_counts_avg_order_by
  count: order_by
  max: taggable_counts_max_order_by
  min: taggable_counts_min_order_by
  stddev: taggable_counts_stddev_order_by
  stddev_pop: taggable_counts_stddev_pop_order_by
  stddev_samp: taggable_counts_stddev_samp_order_by
  sum: taggable_counts_sum_order_by
  var_pop: taggable_counts_var_pop_order_by
  var_samp: taggable_counts_var_samp_order_by
  variance: taggable_counts_variance_order_by
}

"""
order by avg() on columns of table "taggable_counts"
"""
input taggable_counts_avg_order_by {
  count: order_by
  id: order_by
  spoiler_ratio: order_by
  tag_id: order_by
  taggable_id: order_by
}

"""
Boolean expression to filter rows from the table "taggable_counts". All fields are combined with a logical 'AND'.
"""
input taggable_counts_bool_exp {
  _and: [taggable_counts_bool_exp!]
  _not: taggable_counts_bool_exp
  _or: [taggable_counts_bool_exp!]
  book: books_bool_exp
  count: Int_comparison_exp
  created_at: timestamp_comparison_exp
  hardcover_tagged: Boolean_comparison_exp
  id: bigint_comparison_exp
  spoiler_ratio: float8_comparison_exp
  tag: tags_bool_exp
  tag_id: Int_comparison_exp
  taggable_id: bigint_comparison_exp
  taggable_type: String_comparison_exp
  updated_at: timestamp_comparison_exp
}

"""
order by max() on columns of table "taggable_counts"
"""
input taggable_counts_max_order_by {
  count: order_by
  created_at: order_by
  id: order_by
  spoiler_ratio: order_by
  tag_id: order_by
  taggable_id: order_by
  taggable_type: order_by
  updated_at: order_by
}

"""
order by min() on columns of table "taggable_counts"
"""
input taggable_counts_min_order_by {
  count: order_by
  created_at: order_by
  id: order_by
  spoiler_ratio: order_by
  tag_id: order_by
  taggable_id: order_by
  taggable_type: order_by
  updated_at: order_by
}

"""
Ordering options when selecting data from "taggable_counts".
"""
input taggable_counts_order_by {
  book: books_order_by
  count: order_by
  created_at: order_by
  hardcover_tagged: order_by
  id: order_by
  spoiler_ratio: order_by
  tag: tags_order_by
  tag_id: order_by
  taggable_id: order_by
  taggable_type: order_by
  updated_at: order_by
}

"""
select columns of table "taggable_counts"
"""
enum taggable_counts_select_column {
  count
  created_at
  hardcover_tagged
  id
  spoiler_ratio
  tag_id
  taggable_id
  taggable_type
  updated_at
}

"""
order by stddev() on columns of table "taggable_counts"
"""
input taggable_counts_stddev_order_by {
  count: order_by
  id: order_by
  spoiler_ratio: order_by
  tag_id: order_by
  taggable_id: order_by
}

"""
order by stddev_pop() on columns of table "taggable_counts"
"""
input taggable_counts_stddev_pop_order_by {
  count: order_by
  id: order_by
  spoiler_ratio: order_by
  tag_id: order_by
  taggable_id: order_by
}

"""
order by stddev_samp() on columns of table "taggable_counts"
"""
input taggable_counts_stddev_samp_order_by {
  count: order_by
  id: order_by
  spoiler_ratio: order_by
  tag_id: order_by
  taggable_id: order_by
}

"""
Streaming cursor of the table "taggable_counts"
"""
input taggable_counts_stream_cursor_input {
  initial_value: taggable_counts_stream_cursor_value_input!
  ordering: cursor_ordering
}

"""
Initial value of the column from where the streaming should start
"""
input taggable_counts_stream_cursor_value_input {
  count: Int
  created_at: timestamp
  hardcover_tagged: Boolean
  id: bigint
  spoiler_ratio: float8
  tag_id: Int
  taggable_id: bigint
  taggable_type: String
  updated_at: timestamp
}

"""
order by sum() on columns of table "taggable_counts"
"""
input taggable_counts_sum_order_by {
  count: order_by
  id: order_by
  spoiler_ratio: order_by
  tag_id: order_by
  taggable_id: order_by
}

"""
order by var_pop() on columns of table "taggable_counts"
"""
input taggable_counts_var_pop_order_by {
  count: order_by
  id: order_by
  spoiler_ratio: order_by
  tag_id: order_by
  taggable_id: order_by
}

"""
order by var_samp() on columns of table "taggable_counts"
"""
input taggable_counts_var_samp_order_by {
  count: order_by
  id: order_by
  spoiler_ratio: order_by
  tag_id: order_by
  taggable_id: order_by
}

"""
order by variance() on columns of table "taggable_counts"
"""
input taggable_counts_variance_order_by {
  count: order_by
  id: order_by
  spoiler_ratio: order_by
  tag_id: order_by
  taggable_id: order_by
}

"""
columns and relationships of "taggings"
"""
type taggings {
  book: books
  created_at: timestamp
  id: bigint!
  spoiler: Boolean!
  tag: tags!
  tag_id: Int!
  taggable_id: bigint
  taggable_type: String
  user: users!
  user_id: Int!
}

"""
aggregated selection of "taggings"
"""
type taggings_aggregate {
  aggregate: taggings_aggregate_fields
  nodes: [taggings!]!
}

input taggings_aggregate_bool_exp {
  bool_and: taggings_aggregate_bool_exp_bool_and
  bool_or: taggings_aggregate_bool_exp_bool_or
  count: taggings_aggregate_bool_exp_count
}

input taggings_aggregate_bool_exp_bool_and {
  arguments: taggings_select_column_taggings_aggregate_bool_exp_bool_and_arguments_columns!
  distinct: Boolean
  filter: taggings_bool_exp
  predicate: Boolean_comparison_exp!
}

input taggings_aggregate_bool_exp_bool_or {
  arguments: taggings_select_column_taggings_aggregate_bool_exp_bool_or_arguments_columns!
  distinct: Boolean
  filter: taggings_bool_exp
  predicate: Boolean_comparison_exp!
}

input taggings_aggregate_bool_exp_count {
  arguments: [taggings_select_column!]
  distinct: Boolean
  filter: taggings_bool_exp
  predicate: Int_comparison_exp!
}

"""
aggregate fields of "taggings"
"""
type taggings_aggregate_fields {
  avg: taggings_avg_fields
  count: Int!
  max: taggings_max_fields
  min: taggings_min_fields
  stddev: taggings_stddev_fields
  stddev_pop: taggings_stddev_pop_fields
  stddev_samp: taggings_stddev_samp_fields
  sum: taggings_sum_fields
  var_pop: taggings_var_pop_fields
  var_samp: taggings_var_samp_fields
  variance: taggings_variance_fields
}

"""
order by aggregate values of table "taggings"
"""
input taggings_aggregate_order_by {
  avg: taggings_avg_order_by
  count: order_by
  max: taggings_max_order_by
  min: taggings_min_order_by
  stddev: taggings_stddev_order_by
  stddev_pop: taggings_stddev_pop_order_by
  stddev_samp: taggings_stddev_samp_order_by
  sum: taggings_sum_order_by
  var_pop: taggings_var_pop_order_by
  var_samp: taggings_var_samp_order_by
  variance: taggings_variance_order_by
}

"""
aggregate avg on columns
"""
type taggings_avg_fields {
  id: Float
  tag_id: Float
  taggable_id: Float
  user_id: Float
}

"""
order by avg() on columns of table "taggings"
"""
input taggings_avg_order_by {
  id: order_by
  tag_id: order_by
  taggable_id: order_by
  user_id: order_by
}

"""
Boolean expression to filter rows from the table "taggings". All fields are combined with a logical 'AND'.
"""
input taggings_bool_exp {
  _and: [taggings_bool_exp!]
  _not: taggings_bool_exp
  _or: [taggings_bool_exp!]
  book: books_bool_exp
  created_at: timestamp_comparison_exp
  id: bigint_comparison_exp
  spoiler: Boolean_comparison_exp
  tag: tags_bool_exp
  tag_id: Int_comparison_exp
  taggable_id: bigint_comparison_exp
  taggable_type: String_comparison_exp
  user: users_bool_exp
  user_id: Int_comparison_exp
}

"""
aggregate max on columns
"""
type taggings_max_fields {
  created_at: timestamp
  id: bigint
  tag_id: Int
  taggable_id: bigint
  taggable_type: String
  user_id: Int
}

"""
order by max() on columns of table "taggings"
"""
input taggings_max_order_by {
  created_at: order_by
  id: order_by
  tag_id: order_by
  taggable_id: order_by
  taggable_type: order_by
  user_id: order_by
}

"""
aggregate min on columns
"""
type taggings_min_fields {
  created_at: timestamp
  id: bigint
  tag_id: Int
  taggable_id: bigint
  taggable_type: String
  user_id: Int
}

"""
order by min() on columns of table "taggings"
"""
input taggings_min_order_by {
  created_at: order_by
  id: order_by
  tag_id: order_by
  taggable_id: order_by
  taggable_type: order_by
  user_id: order_by
}

"""
Ordering options when selecting data from "taggings".
"""
input taggings_order_by {
  book: books_order_by
  created_at: order_by
  id: order_by
  spoiler: order_by
  tag: tags_order_by
  tag_id: order_by
  taggable_id: order_by
  taggable_type: order_by
  user: users_order_by
  user_id: order_by
}

"""
select columns of table "taggings"
"""
enum taggings_select_column {
  created_at
  id
  spoiler
  tag_id
  taggable_id
  taggable_type
  user_id
}

"""
select "taggings_aggregate_bool_exp_bool_and_arguments_columns" columns of table "taggings"
"""
enum taggings_select_column_taggings_aggregate_bool_exp_bool_and_arguments_columns {
  spoiler
}

"""
select "taggings_aggregate_bool_exp_bool_or_arguments_columns" columns of table "taggings"
"""
enum taggings_select_column_taggings_aggregate_bool_exp_bool_or_arguments_columns {
  spoiler
}

"""
aggregate stddev on columns
"""
type taggings_stddev_fields {
  id: Float
  tag_id: Float
  taggable_id: Float
  user_id: Float
}

"""
order by stddev() on columns of table "taggings"
"""
input taggings_stddev_order_by {
  id: order_by
  tag_id: order_by
  taggable_id: order_by
  user_id: order_by
}

"""
aggregate stddev_pop on columns
"""
type taggings_stddev_pop_fields {
  id: Float
  tag_id: Float
  taggable_id: Float
  user_id: Float
}

"""
order by stddev_pop() on columns of table "taggings"
"""
input taggings_stddev_pop_order_by {
  id: order_by
  tag_id: order_by
  taggable_id: order_by
  user_id: order_by
}

"""
aggregate stddev_samp on columns
"""
type taggings_stddev_samp_fields {
  id: Float
  tag_id: Float
  taggable_id: Float
  user_id: Float
}

"""
order by stddev_samp() on columns of table "taggings"
"""
input taggings_stddev_samp_order_by {
  id: order_by
  tag_id: order_by
  taggable_id: order_by
  user_id: order_by
}

"""
Streaming cursor of the table "taggings"
"""
input taggings_stream_cursor_input {
  initial_value: taggings_stream_cursor_value_input!
  ordering: cursor_ordering
}

"""
Initial value of the column from where the streaming should start
"""
input taggings_stream_cursor_value_input {
  created_at: timestamp
  id: bigint
  spoiler: Boolean
  tag_id: Int
  taggable_id: bigint
  taggable_type: String
  user_id: Int
}

"""
aggregate sum on columns
"""
type taggings_sum_fields {
  id: bigint
  tag_id: Int
  taggable_id: bigint
  user_id: Int
}

"""
order by sum() on columns of table "taggings"
"""
input taggings_sum_order_by {
  id: order_by
  tag_id: order_by
  taggable_id: order_by
  user_id: order_by
}

"""
aggregate var_pop on columns
"""
type taggings_var_pop_fields {
  id: Float
  tag_id: Float
  taggable_id: Float
  user_id: Float
}

"""
order by var_pop() on columns of table "taggings"
"""
input taggings_var_pop_order_by {
  id: order_by
  tag_id: order_by
  taggable_id: order_by
  user_id: order_by
}

"""
aggregate var_samp on columns
"""
type taggings_var_samp_fields {
  id: Float
  tag_id: Float
  taggable_id: Float
  user_id: Float
}

"""
order by var_samp() on columns of table "taggings"
"""
input taggings_var_samp_order_by {
  id: order_by
  tag_id: order_by
  taggable_id: order_by
  user_id: order_by
}

"""
aggregate variance on columns
"""
type taggings_variance_fields {
  id: Float
  tag_id: Float
  taggable_id: Float
  user_id: Float
}

"""
order by variance() on columns of table "taggings"
"""
input taggings_variance_order_by {
  id: order_by
  tag_id: order_by
  taggable_id: order_by
  user_id: order_by
}

"""
columns and relationships of "tags"
"""
type tags {
  count: Int!
  id: bigint!
  slug: String!
  tag: String!
  tag_category: tag_categories!
  tag_category_id: Int!
  taggings: [taggings!]!
  taggings_aggregate: taggings_aggregate!
}

"""
aggregated selection of "tags"
"""
type tags_aggregate {
  aggregate: tags_aggregate_fields
  nodes: [tags!]!
}

input tags_aggregate_bool_exp {
  count: tags_aggregate_bool_exp_count
}

input tags_aggregate_bool_exp_count {
  arguments: [tags_select_column!]
  distinct: Boolean
  filter: tags_bool_exp
  predicate: Int_comparison_exp!
}

"""
aggregate fields of "tags"
"""
type tags_aggregate_fields {
  avg: tags_avg_fields
  count: Int!
  max: tags_max_fields
  min: tags_min_fields
  stddev: tags_stddev_fields
  stddev_pop: tags_stddev_pop_fields
  stddev_samp: tags_stddev_samp_fields
  sum: tags_sum_fields
  var_pop: tags_var_pop_fields
  var_samp: tags_var_samp_fields
  variance: tags_variance_fields
}

"""
order by aggregate values of table "tags"
"""
input tags_aggregate_order_by {
  avg: tags_avg_order_by
  count: order_by
  max: tags_max_order_by
  min: tags_min_order_by
  stddev: tags_stddev_order_by
  stddev_pop: tags_stddev_pop_order_by
  stddev_samp: tags_stddev_samp_order_by
  sum: tags_sum_order_by
  var_pop: tags_var_pop_order_by
  var_samp: tags_var_samp_order_by
  variance: tags_variance_order_by
}

"""
aggregate avg on columns
"""
type tags_avg_fields {
  count: Float
  id: Float
  tag_category_id: Float
}

"""
order by avg() on columns of table "tags"
"""
input tags_avg_order_by {
  count: order_by
  id: order_by
  tag_category_id: order_by
}

"""
Boolean expression to filter rows from the table "tags". All fields are combined with a logical 'AND'.
"""
input tags_bool_exp {
  _and: [tags_bool_exp!]
  _not: tags_bool_exp
  _or: [tags_bool_exp!]
  count: Int_comparison_exp
  id: bigint_comparison_exp
  slug: String_comparison_exp
  tag: String_comparison_exp
  tag_category: tag_categories_bool_exp
  tag_category_id: Int_comparison_exp
  taggings: taggings_bool_exp
  taggings_aggregate: taggings_aggregate_bool_exp
}

"""
aggregate max on columns
"""
type tags_max_fields {
  count: Int
  id: bigint
  slug: String
  tag: String
  tag_category_id: Int
}

"""
order by max() on columns of table "tags"
"""
input tags_max_order_by {
  count: order_by
  id: order_by
  slug: order_by
  tag: order_by
  tag_category_id: order_by
}

"""
aggregate min on columns
"""
type tags_min_fields {
  count: Int
  id: bigint
  slug: String
  tag: String
  tag_category_id: Int
}

"""
order by min() on columns of table "tags"
"""
input tags_min_order_by {
  count: order_by
  id: order_by
  slug: order_by
  tag: order_by
  tag_category_id: order_by
}

"""
Ordering options when selecting data from "tags".
"""
input tags_order_by {
  count: order_by
  id: order_by
  slug: order_by
  tag: order_by
  tag_category: tag_categories_order_by
  tag_category_id: order_by
  taggings_aggregate: taggings_aggregate_order_by
}

"""
select columns of table "tags"
"""
enum tags_select_column {
  count
  id
  slug
  tag
  tag_category_id
}

"""
aggregate stddev on columns
"""
type tags_stddev_fields {
  count: Float
  id: Float
  tag_category_id: Float
}

"""
order by stddev() on columns of table "tags"
"""
input tags_stddev_order_by {
  count: order_by
  id: order_by
  tag_category_id: order_by
}

"""
aggregate stddev_pop on columns
"""
type tags_stddev_pop_fields {
  count: Float
  id: Float
  tag_category_id: Float
}

"""
order by stddev_pop() on columns of table "tags"
"""
input tags_stddev_pop_order_by {
  count: order_by
  id: order_by
  tag_category_id: order_by
}

"""
aggregate stddev_samp on columns
"""
type tags_stddev_samp_fields {
  count: Float
  id: Float
  tag_category_id: Float
}

"""
order by stddev_samp() on columns of table "tags"
"""
input tags_stddev_samp_order_by {
  count: order_by
  id: order_by
  tag_category_id: order_by
}

"""
Streaming cursor of the table "tags"
"""
input tags_stream_cursor_input {
  initial_value: tags_stream_cursor_value_input!
  ordering: cursor_ordering
}

"""
Initial value of the column from where the streaming should start
"""
input tags_stream_cursor_value_input {
  count: Int
  id: bigint
  slug: String
  tag: String
  tag_category_id: Int
}

"""
aggregate sum on columns
"""
type tags_sum_fields {
  count: Int
  id: bigint
  tag_category_id: Int
}

"""
order by sum() on columns of table "tags"
"""
input tags_sum_order_by {
  count: order_by
  id: order_by
  tag_category_id: order_by
}

"""
aggregate var_pop on columns
"""
type tags_var_pop_fields {
  count: Float
  id: Float
  tag_category_id: Float
}

"""
order by var_pop() on columns of table "tags"
"""
input tags_var_pop_order_by {
  count: order_by
  id: order_by
  tag_category_id: order_by
}

"""
aggregate var_samp on columns
"""
type tags_var_samp_fields {
  count: Float
  id: Float
  tag_category_id: Float
}

"""
order by var_samp() on columns of table "tags"
"""
input tags_var_samp_order_by {
  count: order_by
  id: order_by
  tag_category_id: order_by
}

"""
aggregate variance on columns
"""
type tags_variance_fields {
  count: Float
  id: Float
  tag_category_id: Float
}

"""
order by variance() on columns of table "tags"
"""
input tags_variance_order_by {
  count: order_by
  id: order_by
  tag_category_id: order_by
}

scalar timestamp

"""
Boolean expression to compare columns of type "timestamp". All fields are combined with logical 'AND'.
"""
input timestamp_comparison_exp {
  _eq: timestamp
  _gt: timestamp
  _gte: timestamp
  _in: [timestamp!]
  _is_null: Boolean
  _lt: timestamp
  _lte: timestamp
  _neq: timestamp
  _nin: [timestamp!]
}

scalar timestamptz

"""
Boolean expression to compare columns of type "timestamptz". All fields are combined with logical 'AND'.
"""
input timestamptz_comparison_exp {
  _eq: timestamptz
  _gt: timestamptz
  _gte: timestamptz
  _in: [timestamptz!]
  _is_null: Boolean
  _lt: timestamptz
  _lte: timestamptz
  _neq: timestamptz
  _nin: [timestamptz!]
}

input update_user_input {
  account_privacy_setting_id: Int
  activity_privacy_settings_id: Int
  bio: String
  birthdate: date
  cover: String
  current_password: String
  email: String
  image: String
  link: String
  location: String
  name: String
  onboarded: Boolean
  password: String
  password_confirmation: String
  pronoun_personal: String
  pronoun_possessive: String
  username: String
}

"""
columns and relationships of "user_blocks"
"""
type user_blocks {
  blocked_user: users
  blocked_user_id: Int
  created_at: timestamp!
  id: bigint!
  user: users
  user_id: Int
}

"""
order by aggregate values of table "user_blocks"
"""
input user_blocks_aggregate_order_by {
  avg: user_blocks_avg_order_by
  count: order_by
  max: user_blocks_max_order_by
  min: user_blocks_min_order_by
  stddev: user_blocks_stddev_order_by
  stddev_pop: user_blocks_stddev_pop_order_by
  stddev_samp: user_blocks_stddev_samp_order_by
  sum: user_blocks_sum_order_by
  var_pop: user_blocks_var_pop_order_by
  var_samp: user_blocks_var_samp_order_by
  variance: user_blocks_variance_order_by
}

"""
order by avg() on columns of table "user_blocks"
"""
input user_blocks_avg_order_by {
  blocked_user_id: order_by
  id: order_by
  user_id: order_by
}

"""
Boolean expression to filter rows from the table "user_blocks". All fields are combined with a logical 'AND'.
"""
input user_blocks_bool_exp {
  _and: [user_blocks_bool_exp!]
  _not: user_blocks_bool_exp
  _or: [user_blocks_bool_exp!]
  blocked_user: users_bool_exp
  blocked_user_id: Int_comparison_exp
  created_at: timestamp_comparison_exp
  id: bigint_comparison_exp
  user: users_bool_exp
  user_id: Int_comparison_exp
}

"""
unique or primary key constraints on table "user_blocks"
"""
enum user_blocks_constraint {
  index_user_blocks_on_user_id_and_blocked_user_id
  user_blocks_pkey
}

"""
input type for inserting data into table "user_blocks"
"""
input user_blocks_insert_input {
  blocked_user_id: Int
  user_id: Int
}

"""
order by max() on columns of table "user_blocks"
"""
input user_blocks_max_order_by {
  blocked_user_id: order_by
  created_at: order_by
  id: order_by
  user_id: order_by
}

"""
order by min() on columns of table "user_blocks"
"""
input user_blocks_min_order_by {
  blocked_user_id: order_by
  created_at: order_by
  id: order_by
  user_id: order_by
}

"""
response of any mutation on the table "user_blocks"
"""
type user_blocks_mutation_response {
  affected_rows: Int!
  returning: [user_blocks!]!
}

"""
on_conflict condition type for table "user_blocks"
"""
input user_blocks_on_conflict {
  constraint: user_blocks_constraint!
  update_columns: [user_blocks_update_column!]!
  where: user_blocks_bool_exp
}

"""
Ordering options when selecting data from "user_blocks".
"""
input user_blocks_order_by {
  blocked_user: users_order_by
  blocked_user_id: order_by
  created_at: order_by
  id: order_by
  user: users_order_by
  user_id: order_by
}

"""
select columns of table "user_blocks"
"""
enum user_blocks_select_column {
  blocked_user_id
  created_at
  id
  user_id
}

"""
order by stddev() on columns of table "user_blocks"
"""
input user_blocks_stddev_order_by {
  blocked_user_id: order_by
  id: order_by
  user_id: order_by
}

"""
order by stddev_pop() on columns of table "user_blocks"
"""
input user_blocks_stddev_pop_order_by {
  blocked_user_id: order_by
  id: order_by
  user_id: order_by
}

"""
order by stddev_samp() on columns of table "user_blocks"
"""
input user_blocks_stddev_samp_order_by {
  blocked_user_id: order_by
  id: order_by
  user_id: order_by
}

"""
Streaming cursor of the table "user_blocks"
"""
input user_blocks_stream_cursor_input {
  initial_value: user_blocks_stream_cursor_value_input!
  ordering: cursor_ordering
}

"""
Initial value of the column from where the streaming should start
"""
input user_blocks_stream_cursor_value_input {
  blocked_user_id: Int
  created_at: timestamp
  id: bigint
  user_id: Int
}

"""
order by sum() on columns of table "user_blocks"
"""
input user_blocks_sum_order_by {
  blocked_user_id: order_by
  id: order_by
  user_id: order_by
}

"""
placeholder for update columns of table "user_blocks" (current role has no relevant permissions)
"""
enum user_blocks_update_column {
  _PLACEHOLDER
}

"""
order by var_pop() on columns of table "user_blocks"
"""
input user_blocks_var_pop_order_by {
  blocked_user_id: order_by
  id: order_by
  user_id: order_by
}

"""
order by var_samp() on columns of table "user_blocks"
"""
input user_blocks_var_samp_order_by {
  blocked_user_id: order_by
  id: order_by
  user_id: order_by
}

"""
order by variance() on columns of table "user_blocks"
"""
input user_blocks_variance_order_by {
  blocked_user_id: order_by
  id: order_by
  user_id: order_by
}

"""
columns and relationships of "user_book_reads"
"""
type user_book_reads {
  edition: editions
  edition_id: Int
  finished_at: date
  id: Int!
  paused_at: date
  progress: float8
  progress_pages: Int
  progress_seconds: Int
  started_at: date
  user_book: user_books
  user_book_id: Int!
}

"""
aggregated selection of "user_book_reads"
"""
type user_book_reads_aggregate {
  aggregate: user_book_reads_aggregate_fields
  nodes: [user_book_reads!]!
}

input user_book_reads_aggregate_bool_exp {
  avg: user_book_reads_aggregate_bool_exp_avg
  corr: user_book_reads_aggregate_bool_exp_corr
  count: user_book_reads_aggregate_bool_exp_count
  covar_samp: user_book_reads_aggregate_bool_exp_covar_samp
  max: user_book_reads_aggregate_bool_exp_max
  min: user_book_reads_aggregate_bool_exp_min
  stddev_samp: user_book_reads_aggregate_bool_exp_stddev_samp
  sum: user_book_reads_aggregate_bool_exp_sum
  var_samp: user_book_reads_aggregate_bool_exp_var_samp
}

input user_book_reads_aggregate_bool_exp_avg {
  arguments: user_book_reads_select_column_user_book_reads_aggregate_bool_exp_avg_arguments_columns!
  distinct: Boolean
  filter: user_book_reads_bool_exp
  predicate: float8_comparison_exp!
}

input user_book_reads_aggregate_bool_exp_corr {
  arguments: user_book_reads_aggregate_bool_exp_corr_arguments!
  distinct: Boolean
  filter: user_book_reads_bool_exp
  predicate: float8_comparison_exp!
}

input user_book_reads_aggregate_bool_exp_corr_arguments {
  X: user_book_reads_select_column_user_book_reads_aggregate_bool_exp_corr_arguments_columns!
  Y: user_book_reads_select_column_user_book_reads_aggregate_bool_exp_corr_arguments_columns!
}

input user_book_reads_aggregate_bool_exp_count {
  arguments: [user_book_reads_select_column!]
  distinct: Boolean
  filter: user_book_reads_bool_exp
  predicate: Int_comparison_exp!
}

input user_book_reads_aggregate_bool_exp_covar_samp {
  arguments: user_book_reads_aggregate_bool_exp_covar_samp_arguments!
  distinct: Boolean
  filter: user_book_reads_bool_exp
  predicate: float8_comparison_exp!
}

input user_book_reads_aggregate_bool_exp_covar_samp_arguments {
  X: user_book_reads_select_column_user_book_reads_aggregate_bool_exp_covar_samp_arguments_columns!
  Y: user_book_reads_select_column_user_book_reads_aggregate_bool_exp_covar_samp_arguments_columns!
}

input user_book_reads_aggregate_bool_exp_max {
  arguments: user_book_reads_select_column_user_book_reads_aggregate_bool_exp_max_arguments_columns!
  distinct: Boolean
  filter: user_book_reads_bool_exp
  predicate: float8_comparison_exp!
}

input user_book_reads_aggregate_bool_exp_min {
  arguments: user_book_reads_select_column_user_book_reads_aggregate_bool_exp_min_arguments_columns!
  distinct: Boolean
  filter: user_book_reads_bool_exp
  predicate: float8_comparison_exp!
}

input user_book_reads_aggregate_bool_exp_stddev_samp {
  arguments: user_book_reads_select_column_user_book_reads_aggregate_bool_exp_stddev_samp_arguments_columns!
  distinct: Boolean
  filter: user_book_reads_bool_exp
  predicate: float8_comparison_exp!
}

input user_book_reads_aggregate_bool_exp_sum {
  arguments: user_book_reads_select_column_user_book_reads_aggregate_bool_exp_sum_arguments_columns!
  distinct: Boolean
  filter: user_book_reads_bool_exp
  predicate: float8_comparison_exp!
}

input user_book_reads_aggregate_bool_exp_var_samp {
  arguments: user_book_reads_select_column_user_book_reads_aggregate_bool_exp_var_samp_arguments_columns!
  distinct: Boolean
  filter: user_book_reads_bool_exp
  predicate: float8_comparison_exp!
}

"""
aggregate fields of "user_book_reads"
"""
type user_book_reads_aggregate_fields {
  avg: user_book_reads_avg_fields
  count: Int!
  max: user_book_reads_max_fields
  min: user_book_reads_min_fields
  stddev: user_book_reads_stddev_fields
  stddev_pop: user_book_reads_stddev_pop_fields
  stddev_samp: user_book_reads_stddev_samp_fields
  sum: user_book_reads_sum_fields
  var_pop: user_book_reads_var_pop_fields
  var_samp: user_book_reads_var_samp_fields
  variance: user_book_reads_variance_fields
}

"""
order by aggregate values of table "user_book_reads"
"""
input user_book_reads_aggregate_order_by {
  avg: user_book_reads_avg_order_by
  count: order_by
  max: user_book_reads_max_order_by
  min: user_book_reads_min_order_by
  stddev: user_book_reads_stddev_order_by
  stddev_pop: user_book_reads_stddev_pop_order_by
  stddev_samp: user_book_reads_stddev_samp_order_by
  sum: user_book_reads_sum_order_by
  var_pop: user_book_reads_var_pop_order_by
  var_samp: user_book_reads_var_samp_order_by
  variance: user_book_reads_variance_order_by
}

"""
aggregate avg on columns
"""
type user_book_reads_avg_fields {
  edition_id: Float
  id: Float
  progress: Float
  progress_pages: Float
  progress_seconds: Float
  user_book_id: Float
}

"""
order by avg() on columns of table "user_book_reads"
"""
input user_book_reads_avg_order_by {
  edition_id: order_by
  id: order_by
  progress: order_by
  progress_pages: order_by
  progress_seconds: order_by
  user_book_id: order_by
}

"""
Boolean expression to filter rows from the table "user_book_reads". All fields are combined with a logical 'AND'.
"""
input user_book_reads_bool_exp {
  _and: [user_book_reads_bool_exp!]
  _not: user_book_reads_bool_exp
  _or: [user_book_reads_bool_exp!]
  edition: editions_bool_exp
  edition_id: Int_comparison_exp
  finished_at: date_comparison_exp
  id: Int_comparison_exp
  paused_at: date_comparison_exp
  progress: float8_comparison_exp
  progress_pages: Int_comparison_exp
  progress_seconds: Int_comparison_exp
  started_at: date_comparison_exp
  user_book: user_books_bool_exp
  user_book_id: Int_comparison_exp
}

"""
aggregate max on columns
"""
type user_book_reads_max_fields {
  edition_id: Int
  finished_at: date
  id: Int
  paused_at: date
  progress: float8
  progress_pages: Int
  progress_seconds: Int
  started_at: date
  user_book_id: Int
}

"""
order by max() on columns of table "user_book_reads"
"""
input user_book_reads_max_order_by {
  edition_id: order_by
  finished_at: order_by
  id: order_by
  paused_at: order_by
  progress: order_by
  progress_pages: order_by
  progress_seconds: order_by
  started_at: order_by
  user_book_id: order_by
}

"""
aggregate min on columns
"""
type user_book_reads_min_fields {
  edition_id: Int
  finished_at: date
  id: Int
  paused_at: date
  progress: float8
  progress_pages: Int
  progress_seconds: Int
  started_at: date
  user_book_id: Int
}

"""
order by min() on columns of table "user_book_reads"
"""
input user_book_reads_min_order_by {
  edition_id: order_by
  finished_at: order_by
  id: order_by
  paused_at: order_by
  progress: order_by
  progress_pages: order_by
  progress_seconds: order_by
  started_at: order_by
  user_book_id: order_by
}

"""
Ordering options when selecting data from "user_book_reads".
"""
input user_book_reads_order_by {
  edition: editions_order_by
  edition_id: order_by
  finished_at: order_by
  id: order_by
  paused_at: order_by
  progress: order_by
  progress_pages: order_by
  progress_seconds: order_by
  started_at: order_by
  user_book: user_books_order_by
  user_book_id: order_by
}

"""
select columns of table "user_book_reads"
"""
enum user_book_reads_select_column {
  edition_id
  finished_at
  id
  paused_at
  progress
  progress_pages
  progress_seconds
  started_at
  user_book_id
}

"""
select "user_book_reads_aggregate_bool_exp_avg_arguments_columns" columns of table "user_book_reads"
"""
enum user_book_reads_select_column_user_book_reads_aggregate_bool_exp_avg_arguments_columns {
  progress
}

"""
select "user_book_reads_aggregate_bool_exp_corr_arguments_columns" columns of table "user_book_reads"
"""
enum user_book_reads_select_column_user_book_reads_aggregate_bool_exp_corr_arguments_columns {
  progress
}

"""
select "user_book_reads_aggregate_bool_exp_covar_samp_arguments_columns" columns of table "user_book_reads"
"""
enum user_book_reads_select_column_user_book_reads_aggregate_bool_exp_covar_samp_arguments_columns {
  progress
}

"""
select "user_book_reads_aggregate_bool_exp_max_arguments_columns" columns of table "user_book_reads"
"""
enum user_book_reads_select_column_user_book_reads_aggregate_bool_exp_max_arguments_columns {
  progress
}

"""
select "user_book_reads_aggregate_bool_exp_min_arguments_columns" columns of table "user_book_reads"
"""
enum user_book_reads_select_column_user_book_reads_aggregate_bool_exp_min_arguments_columns {
  progress
}

"""
select "user_book_reads_aggregate_bool_exp_stddev_samp_arguments_columns" columns of table "user_book_reads"
"""
enum user_book_reads_select_column_user_book_reads_aggregate_bool_exp_stddev_samp_arguments_columns {
  progress
}

"""
select "user_book_reads_aggregate_bool_exp_sum_arguments_columns" columns of table "user_book_reads"
"""
enum user_book_reads_select_column_user_book_reads_aggregate_bool_exp_sum_arguments_columns {
  progress
}

"""
select "user_book_reads_aggregate_bool_exp_var_samp_arguments_columns" columns of table "user_book_reads"
"""
enum user_book_reads_select_column_user_book_reads_aggregate_bool_exp_var_samp_arguments_columns {
  progress
}

"""
aggregate stddev on columns
"""
type user_book_reads_stddev_fields {
  edition_id: Float
  id: Float
  progress: Float
  progress_pages: Float
  progress_seconds: Float
  user_book_id: Float
}

"""
order by stddev() on columns of table "user_book_reads"
"""
input user_book_reads_stddev_order_by {
  edition_id: order_by
  id: order_by
  progress: order_by
  progress_pages: order_by
  progress_seconds: order_by
  user_book_id: order_by
}

"""
aggregate stddev_pop on columns
"""
type user_book_reads_stddev_pop_fields {
  edition_id: Float
  id: Float
  progress: Float
  progress_pages: Float
  progress_seconds: Float
  user_book_id: Float
}

"""
order by stddev_pop() on columns of table "user_book_reads"
"""
input user_book_reads_stddev_pop_order_by {
  edition_id: order_by
  id: order_by
  progress: order_by
  progress_pages: order_by
  progress_seconds: order_by
  user_book_id: order_by
}

"""
aggregate stddev_samp on columns
"""
type user_book_reads_stddev_samp_fields {
  edition_id: Float
  id: Float
  progress: Float
  progress_pages: Float
  progress_seconds: Float
  user_book_id: Float
}

"""
order by stddev_samp() on columns of table "user_book_reads"
"""
input user_book_reads_stddev_samp_order_by {
  edition_id: order_by
  id: order_by
  progress: order_by
  progress_pages: order_by
  progress_seconds: order_by
  user_book_id: order_by
}

"""
Streaming cursor of the table "user_book_reads"
"""
input user_book_reads_stream_cursor_input {
  initial_value: user_book_reads_stream_cursor_value_input!
  ordering: cursor_ordering
}

"""
Initial value of the column from where the streaming should start
"""
input user_book_reads_stream_cursor_value_input {
  edition_id: Int
  finished_at: date
  id: Int
  paused_at: date
  progress: float8
  progress_pages: Int
  progress_seconds: Int
  started_at: date
  user_book_id: Int
}

"""
aggregate sum on columns
"""
type user_book_reads_sum_fields {
  edition_id: Int
  id: Int
  progress: float8
  progress_pages: Int
  progress_seconds: Int
  user_book_id: Int
}

"""
order by sum() on columns of table "user_book_reads"
"""
input user_book_reads_sum_order_by {
  edition_id: order_by
  id: order_by
  progress: order_by
  progress_pages: order_by
  progress_seconds: order_by
  user_book_id: order_by
}

"""
aggregate var_pop on columns
"""
type user_book_reads_var_pop_fields {
  edition_id: Float
  id: Float
  progress: Float
  progress_pages: Float
  progress_seconds: Float
  user_book_id: Float
}

"""
order by var_pop() on columns of table "user_book_reads"
"""
input user_book_reads_var_pop_order_by {
  edition_id: order_by
  id: order_by
  progress: order_by
  progress_pages: order_by
  progress_seconds: order_by
  user_book_id: order_by
}

"""
aggregate var_samp on columns
"""
type user_book_reads_var_samp_fields {
  edition_id: Float
  id: Float
  progress: Float
  progress_pages: Float
  progress_seconds: Float
  user_book_id: Float
}

"""
order by var_samp() on columns of table "user_book_reads"
"""
input user_book_reads_var_samp_order_by {
  edition_id: order_by
  id: order_by
  progress: order_by
  progress_pages: order_by
  progress_seconds: order_by
  user_book_id: order_by
}

"""
aggregate variance on columns
"""
type user_book_reads_variance_fields {
  edition_id: Float
  id: Float
  progress: Float
  progress_pages: Float
  progress_seconds: Float
  user_book_id: Float
}

"""
order by variance() on columns of table "user_book_reads"
"""
input user_book_reads_variance_order_by {
  edition_id: order_by
  id: order_by
  progress: order_by
  progress_pages: order_by
  progress_seconds: order_by
  user_book_id: order_by
}

"""
columns and relationships of "user_book_statuses"
"""
type user_book_statuses {
  description: String
  id: Int!
  slug: String
  status: String!
  user_books: [user_books!]!
  user_books_aggregate: user_books_aggregate!
}

"""
aggregated selection of "user_book_statuses"
"""
type user_book_statuses_aggregate {
  aggregate: user_book_statuses_aggregate_fields
  nodes: [user_book_statuses!]!
}

"""
aggregate fields of "user_book_statuses"
"""
type user_book_statuses_aggregate_fields {
  avg: user_book_statuses_avg_fields
  count: Int!
  max: user_book_statuses_max_fields
  min: user_book_statuses_min_fields
  stddev: user_book_statuses_stddev_fields
  stddev_pop: user_book_statuses_stddev_pop_fields
  stddev_samp: user_book_statuses_stddev_samp_fields
  sum: user_book_statuses_sum_fields
  var_pop: user_book_statuses_var_pop_fields
  var_samp: user_book_statuses_var_samp_fields
  variance: user_book_statuses_variance_fields
}

"""
aggregate avg on columns
"""
type user_book_statuses_avg_fields {
  id: Float
}

"""
Boolean expression to filter rows from the table "user_book_statuses". All fields are combined with a logical 'AND'.
"""
input user_book_statuses_bool_exp {
  _and: [user_book_statuses_bool_exp!]
  _not: user_book_statuses_bool_exp
  _or: [user_book_statuses_bool_exp!]
  description: String_comparison_exp
  id: Int_comparison_exp
  slug: String_comparison_exp
  status: String_comparison_exp
  user_books: user_books_bool_exp
  user_books_aggregate: user_books_aggregate_bool_exp
}

"""
aggregate max on columns
"""
type user_book_statuses_max_fields {
  description: String
  id: Int
  slug: String
  status: String
}

"""
aggregate min on columns
"""
type user_book_statuses_min_fields {
  description: String
  id: Int
  slug: String
  status: String
}

"""
Ordering options when selecting data from "user_book_statuses".
"""
input user_book_statuses_order_by {
  description: order_by
  id: order_by
  slug: order_by
  status: order_by
  user_books_aggregate: user_books_aggregate_order_by
}

"""
select columns of table "user_book_statuses"
"""
enum user_book_statuses_select_column {
  description
  id
  slug
  status
}

"""
aggregate stddev on columns
"""
type user_book_statuses_stddev_fields {
  id: Float
}

"""
aggregate stddev_pop on columns
"""
type user_book_statuses_stddev_pop_fields {
  id: Float
}

"""
aggregate stddev_samp on columns
"""
type user_book_statuses_stddev_samp_fields {
  id: Float
}

"""
Streaming cursor of the table "user_book_statuses"
"""
input user_book_statuses_stream_cursor_input {
  initial_value: user_book_statuses_stream_cursor_value_input!
  ordering: cursor_ordering
}

"""
Initial value of the column from where the streaming should start
"""
input user_book_statuses_stream_cursor_value_input {
  description: String
  id: Int
  slug: String
  status: String
}

"""
aggregate sum on columns
"""
type user_book_statuses_sum_fields {
  id: Int
}

"""
aggregate var_pop on columns
"""
type user_book_statuses_var_pop_fields {
  id: Float
}

"""
aggregate var_samp on columns
"""
type user_book_statuses_var_samp_fields {
  id: Float
}

"""
aggregate variance on columns
"""
type user_book_statuses_variance_fields {
  id: Float
}

"""
columns and relationships of "user_books"
"""
type user_books {
  book: books!
  book_id: Int!
  cached_match_score: float8
  created_at: timestamptz!
  date_added: date!
  edition: editions
  edition_id: Int
  first_read_date: date
  first_started_reading_date: date
  followers: [followed_users!]!
  has_review: Boolean!
  id: Int!
  imported: Boolean
  last_read_date: date
  likes: [likes!]!
  likes_count: Int!
  media_url: String
  merged_at: timestamp
  object_type: String!
  original_book_id: Int
  original_edition_id: Int
  owned: Boolean!
  owned_copies: Int
  privacy_setting: privacy_settings!
  privacy_setting_id: Int!
  private_notes: String
  rating: numeric
  read_count: Int!
  reading_format: reading_formats
  reading_format_id: Int!
  reading_journal_summary: reading_journals_summary
  reading_journals: [reading_journals!]!
  recommended_by: String
  recommended_for: String
  referrer: users
  referrer_user_id: Int
  review: String
  review_has_spoilers: Boolean!
  review_html: String
  review_length: Int!
  review_migrated: Boolean
  review_object: jsonb!
  review_raw: String
  review_slate: jsonb!
  reviewed_at: timestamp
  sponsored_review: Boolean!
  starred: Boolean!
  status_id: Int!
  updated_at: timestamptz
  url: String
  user: users!
  user_book_reads: [user_book_reads!]!
  user_book_reads_aggregate: user_book_reads_aggregate!
  user_book_status: user_book_statuses!
  user_books: [user_books!]!
  user_books_aggregate: user_books_aggregate!
  user_id: Int!
}

"""
aggregated selection of "user_books"
"""
type user_books_aggregate {
  aggregate: user_books_aggregate_fields
  nodes: [user_books!]!
}

input user_books_aggregate_bool_exp {
  avg: user_books_aggregate_bool_exp_avg
  bool_and: user_books_aggregate_bool_exp_bool_and
  bool_or: user_books_aggregate_bool_exp_bool_or
  corr: user_books_aggregate_bool_exp_corr
  count: user_books_aggregate_bool_exp_count
  covar_samp: user_books_aggregate_bool_exp_covar_samp
  max: user_books_aggregate_bool_exp_max
  min: user_books_aggregate_bool_exp_min
  stddev_samp: user_books_aggregate_bool_exp_stddev_samp
  sum: user_books_aggregate_bool_exp_sum
  var_samp: user_books_aggregate_bool_exp_var_samp
}

input user_books_aggregate_bool_exp_avg {
  arguments: user_books_select_column_user_books_aggregate_bool_exp_avg_arguments_columns!
  distinct: Boolean
  filter: user_books_bool_exp
  predicate: float8_comparison_exp!
}

input user_books_aggregate_bool_exp_bool_and {
  arguments: user_books_select_column_user_books_aggregate_bool_exp_bool_and_arguments_columns!
  distinct: Boolean
  filter: user_books_bool_exp
  predicate: Boolean_comparison_exp!
}

input user_books_aggregate_bool_exp_bool_or {
  arguments: user_books_select_column_user_books_aggregate_bool_exp_bool_or_arguments_columns!
  distinct: Boolean
  filter: user_books_bool_exp
  predicate: Boolean_comparison_exp!
}

input user_books_aggregate_bool_exp_corr {
  arguments: user_books_aggregate_bool_exp_corr_arguments!
  distinct: Boolean
  filter: user_books_bool_exp
  predicate: float8_comparison_exp!
}

input user_books_aggregate_bool_exp_corr_arguments {
  X: user_books_select_column_user_books_aggregate_bool_exp_corr_arguments_columns!
  Y: user_books_select_column_user_books_aggregate_bool_exp_corr_arguments_columns!
}

input user_books_aggregate_bool_exp_count {
  arguments: [user_books_select_column!]
  distinct: Boolean
  filter: user_books_bool_exp
  predicate: Int_comparison_exp!
}

input user_books_aggregate_bool_exp_covar_samp {
  arguments: user_books_aggregate_bool_exp_covar_samp_arguments!
  distinct: Boolean
  filter: user_books_bool_exp
  predicate: float8_comparison_exp!
}

input user_books_aggregate_bool_exp_covar_samp_arguments {
  X: user_books_select_column_user_books_aggregate_bool_exp_covar_samp_arguments_columns!
  Y: user_books_select_column_user_books_aggregate_bool_exp_covar_samp_arguments_columns!
}

input user_books_aggregate_bool_exp_max {
  arguments: user_books_select_column_user_books_aggregate_bool_exp_max_arguments_columns!
  distinct: Boolean
  filter: user_books_bool_exp
  predicate: float8_comparison_exp!
}

input user_books_aggregate_bool_exp_min {
  arguments: user_books_select_column_user_books_aggregate_bool_exp_min_arguments_columns!
  distinct: Boolean
  filter: user_books_bool_exp
  predicate: float8_comparison_exp!
}

input user_books_aggregate_bool_exp_stddev_samp {
  arguments: user_books_select_column_user_books_aggregate_bool_exp_stddev_samp_arguments_columns!
  distinct: Boolean
  filter: user_books_bool_exp
  predicate: float8_comparison_exp!
}

input user_books_aggregate_bool_exp_sum {
  arguments: user_books_select_column_user_books_aggregate_bool_exp_sum_arguments_columns!
  distinct: Boolean
  filter: user_books_bool_exp
  predicate: float8_comparison_exp!
}

input user_books_aggregate_bool_exp_var_samp {
  arguments: user_books_select_column_user_books_aggregate_bool_exp_var_samp_arguments_columns!
  distinct: Boolean
  filter: user_books_bool_exp
  predicate: float8_comparison_exp!
}

"""
aggregate fields of "user_books"
"""
type user_books_aggregate_fields {
  avg: user_books_avg_fields
  count: Int!
  max: user_books_max_fields
  min: user_books_min_fields
  stddev: user_books_stddev_fields
  stddev_pop: user_books_stddev_pop_fields
  stddev_samp: user_books_stddev_samp_fields
  sum: user_books_sum_fields
  var_pop: user_books_var_pop_fields
  var_samp: user_books_var_samp_fields
  variance: user_books_variance_fields
}

"""
order by aggregate values of table "user_books"
"""
input user_books_aggregate_order_by {
  avg: user_books_avg_order_by
  count: order_by
  max: user_books_max_order_by
  min: user_books_min_order_by
  stddev: user_books_stddev_order_by
  stddev_pop: user_books_stddev_pop_order_by
  stddev_samp: user_books_stddev_samp_order_by
  sum: user_books_sum_order_by
  var_pop: user_books_var_pop_order_by
  var_samp: user_books_var_samp_order_by
  variance: user_books_variance_order_by
}

"""
aggregate avg on columns
"""
type user_books_avg_fields {
  book_id: Float
  cached_match_score: Float
  edition_id: Float
  id: Float
  likes_count: Float
  original_book_id: Float
  original_edition_id: Float
  owned_copies: Float
  privacy_setting_id: Float
  rating: Float
  read_count: Float
  reading_format_id: Float
  referrer_user_id: Float
  review_length: Float
  status_id: Float
  user_id: Float
}

"""
order by avg() on columns of table "user_books"
"""
input user_books_avg_order_by {
  book_id: order_by
  cached_match_score: order_by
  edition_id: order_by
  id: order_by
  likes_count: order_by
  original_book_id: order_by
  original_edition_id: order_by
  owned_copies: order_by
  privacy_setting_id: order_by
  rating: order_by
  read_count: order_by
  reading_format_id: order_by
  referrer_user_id: order_by
  review_length: order_by
  status_id: order_by
  user_id: order_by
}

"""
Boolean expression to filter rows from the table "user_books". All fields are combined with a logical 'AND'.
"""
input user_books_bool_exp {
  _and: [user_books_bool_exp!]
  _not: user_books_bool_exp
  _or: [user_books_bool_exp!]
  book: books_bool_exp
  book_id: Int_comparison_exp
  cached_match_score: float8_comparison_exp
  created_at: timestamptz_comparison_exp
  date_added: date_comparison_exp
  edition: editions_bool_exp
  edition_id: Int_comparison_exp
  first_read_date: date_comparison_exp
  first_started_reading_date: date_comparison_exp
  followers: followed_users_bool_exp
  has_review: Boolean_comparison_exp
  id: Int_comparison_exp
  imported: Boolean_comparison_exp
  last_read_date: date_comparison_exp
  likes: likes_bool_exp
  likes_count: Int_comparison_exp
  media_url: String_comparison_exp
  merged_at: timestamp_comparison_exp
  object_type: String_comparison_exp
  original_book_id: Int_comparison_exp
  original_edition_id: Int_comparison_exp
  owned: Boolean_comparison_exp
  owned_copies: Int_comparison_exp
  privacy_setting: privacy_settings_bool_exp
  privacy_setting_id: Int_comparison_exp
  private_notes: String_comparison_exp
  rating: numeric_comparison_exp
  read_count: Int_comparison_exp
  reading_format: reading_formats_bool_exp
  reading_format_id: Int_comparison_exp
  reading_journal_summary: reading_journals_summary_bool_exp
  reading_journals: reading_journals_bool_exp
  recommended_by: String_comparison_exp
  recommended_for: String_comparison_exp
  referrer: users_bool_exp
  referrer_user_id: Int_comparison_exp
  review: String_comparison_exp
  review_has_spoilers: Boolean_comparison_exp
  review_html: String_comparison_exp
  review_length: Int_comparison_exp
  review_migrated: Boolean_comparison_exp
  review_object: jsonb_comparison_exp
  review_raw: String_comparison_exp
  review_slate: jsonb_comparison_exp
  reviewed_at: timestamp_comparison_exp
  sponsored_review: Boolean_comparison_exp
  starred: Boolean_comparison_exp
  status_id: Int_comparison_exp
  updated_at: timestamptz_comparison_exp
  url: String_comparison_exp
  user: users_bool_exp
  user_book_reads: user_book_reads_bool_exp
  user_book_reads_aggregate: user_book_reads_aggregate_bool_exp
  user_book_status: user_book_statuses_bool_exp
  user_books: user_books_bool_exp
  user_books_aggregate: user_books_aggregate_bool_exp
  user_id: Int_comparison_exp
}

"""
aggregate max on columns
"""
type user_books_max_fields {
  book_id: Int
  cached_match_score: float8
  created_at: timestamptz
  date_added: date
  edition_id: Int
  first_read_date: date
  first_started_reading_date: date
  id: Int
  last_read_date: date
  likes_count: Int
  media_url: String
  merged_at: timestamp
  object_type: String
  original_book_id: Int
  original_edition_id: Int
  owned_copies: Int
  privacy_setting_id: Int
  private_notes: String
  rating: numeric
  read_count: Int
  reading_format_id: Int
  recommended_by: String
  recommended_for: String
  referrer_user_id: Int
  review: String
  review_html: String
  review_length: Int
  review_raw: String
  reviewed_at: timestamp
  status_id: Int
  updated_at: timestamptz
  url: String
  user_id: Int
}

"""
order by max() on columns of table "user_books"
"""
input user_books_max_order_by {
  book_id: order_by
  cached_match_score: order_by
  created_at: order_by
  date_added: order_by
  edition_id: order_by
  first_read_date: order_by
  first_started_reading_date: order_by
  id: order_by
  last_read_date: order_by
  likes_count: order_by
  media_url: order_by
  merged_at: order_by
  object_type: order_by
  original_book_id: order_by
  original_edition_id: order_by
  owned_copies: order_by
  privacy_setting_id: order_by
  private_notes: order_by
  rating: order_by
  read_count: order_by
  reading_format_id: order_by
  recommended_by: order_by
  recommended_for: order_by
  referrer_user_id: order_by
  review: order_by
  review_html: order_by
  review_length: order_by
  review_raw: order_by
  reviewed_at: order_by
  status_id: order_by
  updated_at: order_by
  url: order_by
  user_id: order_by
}

"""
aggregate min on columns
"""
type user_books_min_fields {
  book_id: Int
  cached_match_score: float8
  created_at: timestamptz
  date_added: date
  edition_id: Int
  first_read_date: date
  first_started_reading_date: date
  id: Int
  last_read_date: date
  likes_count: Int
  media_url: String
  merged_at: timestamp
  object_type: String
  original_book_id: Int
  original_edition_id: Int
  owned_copies: Int
  privacy_setting_id: Int
  private_notes: String
  rating: numeric
  read_count: Int
  reading_format_id: Int
  recommended_by: String
  recommended_for: String
  referrer_user_id: Int
  review: String
  review_html: String
  review_length: Int
  review_raw: String
  reviewed_at: timestamp
  status_id: Int
  updated_at: timestamptz
  url: String
  user_id: Int
}

"""
order by min() on columns of table "user_books"
"""
input user_books_min_order_by {
  book_id: order_by
  cached_match_score: order_by
  created_at: order_by
  date_added: order_by
  edition_id: order_by
  first_read_date: order_by
  first_started_reading_date: order_by
  id: order_by
  last_read_date: order_by
  likes_count: order_by
  media_url: order_by
  merged_at: order_by
  object_type: order_by
  original_book_id: order_by
  original_edition_id: order_by
  owned_copies: order_by
  privacy_setting_id: order_by
  private_notes: order_by
  rating: order_by
  read_count: order_by
  reading_format_id: order_by
  recommended_by: order_by
  recommended_for: order_by
  referrer_user_id: order_by
  review: order_by
  review_html: order_by
  review_length: order_by
  review_raw: order_by
  reviewed_at: order_by
  status_id: order_by
  updated_at: order_by
  url: order_by
  user_id: order_by
}

"""
Ordering options when selecting data from "user_books".
"""
input user_books_order_by {
  book: books_order_by
  book_id: order_by
  cached_match_score: order_by
  created_at: order_by
  date_added: order_by
  edition: editions_order_by
  edition_id: order_by
  first_read_date: order_by
  first_started_reading_date: order_by
  followers_aggregate: followed_users_aggregate_order_by
  has_review: order_by
  id: order_by
  imported: order_by
  last_read_date: order_by
  likes_aggregate: likes_aggregate_order_by
  likes_count: order_by
  media_url: order_by
  merged_at: order_by
  object_type: order_by
  original_book_id: order_by
  original_edition_id: order_by
  owned: order_by
  owned_copies: order_by
  privacy_setting: privacy_settings_order_by
  privacy_setting_id: order_by
  private_notes: order_by
  rating: order_by
  read_count: order_by
  reading_format: reading_formats_order_by
  reading_format_id: order_by
  reading_journal_summary: reading_journals_summary_order_by
  reading_journals_aggregate: reading_journals_aggregate_order_by
  recommended_by: order_by
  recommended_for: order_by
  referrer: users_order_by
  referrer_user_id: order_by
  review: order_by
  review_has_spoilers: order_by
  review_html: order_by
  review_length: order_by
  review_migrated: order_by
  review_object: order_by
  review_raw: order_by
  review_slate: order_by
  reviewed_at: order_by
  sponsored_review: order_by
  starred: order_by
  status_id: order_by
  updated_at: order_by
  url: order_by
  user: users_order_by
  user_book_reads_aggregate: user_book_reads_aggregate_order_by
  user_book_status: user_book_statuses_order_by
  user_books_aggregate: user_books_aggregate_order_by
  user_id: order_by
}

"""
select columns of table "user_books"
"""
enum user_books_select_column {
  book_id
  cached_match_score
  created_at
  date_added
  edition_id
  first_read_date
  first_started_reading_date
  has_review
  id
  imported
  last_read_date
  likes_count
  media_url
  merged_at
  object_type
  original_book_id
  original_edition_id
  owned
  owned_copies
  privacy_setting_id
  private_notes
  rating
  read_count
  reading_format_id
  recommended_by
  recommended_for
  referrer_user_id
  review
  review_has_spoilers
  review_html
  review_length
  review_migrated
  review_object
  review_raw
  review_slate
  reviewed_at
  sponsored_review
  starred
  status_id
  updated_at
  url
  user_id
}

"""
select "user_books_aggregate_bool_exp_avg_arguments_columns" columns of table "user_books"
"""
enum user_books_select_column_user_books_aggregate_bool_exp_avg_arguments_columns {
  cached_match_score
}

"""
select "user_books_aggregate_bool_exp_bool_and_arguments_columns" columns of table "user_books"
"""
enum user_books_select_column_user_books_aggregate_bool_exp_bool_and_arguments_columns {
  has_review
  imported
  owned
  review_has_spoilers
  review_migrated
  sponsored_review
  starred
}

"""
select "user_books_aggregate_bool_exp_bool_or_arguments_columns" columns of table "user_books"
"""
enum user_books_select_column_user_books_aggregate_bool_exp_bool_or_arguments_columns {
  has_review
  imported
  owned
  review_has_spoilers
  review_migrated
  sponsored_review
  starred
}

"""
select "user_books_aggregate_bool_exp_corr_arguments_columns" columns of table "user_books"
"""
enum user_books_select_column_user_books_aggregate_bool_exp_corr_arguments_columns {
  cached_match_score
}

"""
select "user_books_aggregate_bool_exp_covar_samp_arguments_columns" columns of table "user_books"
"""
enum user_books_select_column_user_books_aggregate_bool_exp_covar_samp_arguments_columns {
  cached_match_score
}

"""
select "user_books_aggregate_bool_exp_max_arguments_columns" columns of table "user_books"
"""
enum user_books_select_column_user_books_aggregate_bool_exp_max_arguments_columns {
  cached_match_score
}

"""
select "user_books_aggregate_bool_exp_min_arguments_columns" columns of table "user_books"
"""
enum user_books_select_column_user_books_aggregate_bool_exp_min_arguments_columns {
  cached_match_score
}

"""
select "user_books_aggregate_bool_exp_stddev_samp_arguments_columns" columns of table "user_books"
"""
enum user_books_select_column_user_books_aggregate_bool_exp_stddev_samp_arguments_columns {
  cached_match_score
}

"""
select "user_books_aggregate_bool_exp_sum_arguments_columns" columns of table "user_books"
"""
enum user_books_select_column_user_books_aggregate_bool_exp_sum_arguments_columns {
  cached_match_score
}

"""
select "user_books_aggregate_bool_exp_var_samp_arguments_columns" columns of table "user_books"
"""
enum user_books_select_column_user_books_aggregate_bool_exp_var_samp_arguments_columns {
  cached_match_score
}

"""
aggregate stddev on columns
"""
type user_books_stddev_fields {
  book_id: Float
  cached_match_score: Float
  edition_id: Float
  id: Float
  likes_count: Float
  original_book_id: Float
  original_edition_id: Float
  owned_copies: Float
  privacy_setting_id: Float
  rating: Float
  read_count: Float
  reading_format_id: Float
  referrer_user_id: Float
  review_length: Float
  status_id: Float
  user_id: Float
}

"""
order by stddev() on columns of table "user_books"
"""
input user_books_stddev_order_by {
  book_id: order_by
  cached_match_score: order_by
  edition_id: order_by
  id: order_by
  likes_count: order_by
  original_book_id: order_by
  original_edition_id: order_by
  owned_copies: order_by
  privacy_setting_id: order_by
  rating: order_by
  read_count: order_by
  reading_format_id: order_by
  referrer_user_id: order_by
  review_length: order_by
  status_id: order_by
  user_id: order_by
}

"""
aggregate stddev_pop on columns
"""
type user_books_stddev_pop_fields {
  book_id: Float
  cached_match_score: Float
  edition_id: Float
  id: Float
  likes_count: Float
  original_book_id: Float
  original_edition_id: Float
  owned_copies: Float
  privacy_setting_id: Float
  rating: Float
  read_count: Float
  reading_format_id: Float
  referrer_user_id: Float
  review_length: Float
  status_id: Float
  user_id: Float
}

"""
order by stddev_pop() on columns of table "user_books"
"""
input user_books_stddev_pop_order_by {
  book_id: order_by
  cached_match_score: order_by
  edition_id: order_by
  id: order_by
  likes_count: order_by
  original_book_id: order_by
  original_edition_id: order_by
  owned_copies: order_by
  privacy_setting_id: order_by
  rating: order_by
  read_count: order_by
  reading_format_id: order_by
  referrer_user_id: order_by
  review_length: order_by
  status_id: order_by
  user_id: order_by
}

"""
aggregate stddev_samp on columns
"""
type user_books_stddev_samp_fields {
  book_id: Float
  cached_match_score: Float
  edition_id: Float
  id: Float
  likes_count: Float
  original_book_id: Float
  original_edition_id: Float
  owned_copies: Float
  privacy_setting_id: Float
  rating: Float
  read_count: Float
  reading_format_id: Float
  referrer_user_id: Float
  review_length: Float
  status_id: Float
  user_id: Float
}

"""
order by stddev_samp() on columns of table "user_books"
"""
input user_books_stddev_samp_order_by {
  book_id: order_by
  cached_match_score: order_by
  edition_id: order_by
  id: order_by
  likes_count: order_by
  original_book_id: order_by
  original_edition_id: order_by
  owned_copies: order_by
  privacy_setting_id: order_by
  rating: order_by
  read_count: order_by
  reading_format_id: order_by
  referrer_user_id: order_by
  review_length: order_by
  status_id: order_by
  user_id: order_by
}

"""
Streaming cursor of the table "user_books"
"""
input user_books_stream_cursor_input {
  initial_value: user_books_stream_cursor_value_input!
  ordering: cursor_ordering
}

"""
Initial value of the column from where the streaming should start
"""
input user_books_stream_cursor_value_input {
  book_id: Int
  cached_match_score: float8
  created_at: timestamptz
  date_added: date
  edition_id: Int
  first_read_date: date
  first_started_reading_date: date
  has_review: Boolean
  id: Int
  imported: Boolean
  last_read_date: date
  likes_count: Int
  media_url: String
  merged_at: timestamp
  object_type: String
  original_book_id: Int
  original_edition_id: Int
  owned: Boolean
  owned_copies: Int
  privacy_setting_id: Int
  private_notes: String
  rating: numeric
  read_count: Int
  reading_format_id: Int
  recommended_by: String
  recommended_for: String
  referrer_user_id: Int
  review: String
  review_has_spoilers: Boolean
  review_html: String
  review_length: Int
  review_migrated: Boolean
  review_object: jsonb
  review_raw: String
  review_slate: jsonb
  reviewed_at: timestamp
  sponsored_review: Boolean
  starred: Boolean
  status_id: Int
  updated_at: timestamptz
  url: String
  user_id: Int
}

"""
aggregate sum on columns
"""
type user_books_sum_fields {
  book_id: Int
  cached_match_score: float8
  edition_id: Int
  id: Int
  likes_count: Int
  original_book_id: Int
  original_edition_id: Int
  owned_copies: Int
  privacy_setting_id: Int
  rating: numeric
  read_count: Int
  reading_format_id: Int
  referrer_user_id: Int
  review_length: Int
  status_id: Int
  user_id: Int
}

"""
order by sum() on columns of table "user_books"
"""
input user_books_sum_order_by {
  book_id: order_by
  cached_match_score: order_by
  edition_id: order_by
  id: order_by
  likes_count: order_by
  original_book_id: order_by
  original_edition_id: order_by
  owned_copies: order_by
  privacy_setting_id: order_by
  rating: order_by
  read_count: order_by
  reading_format_id: order_by
  referrer_user_id: order_by
  review_length: order_by
  status_id: order_by
  user_id: order_by
}

"""
aggregate var_pop on columns
"""
type user_books_var_pop_fields {
  book_id: Float
  cached_match_score: Float
  edition_id: Float
  id: Float
  likes_count: Float
  original_book_id: Float
  original_edition_id: Float
  owned_copies: Float
  privacy_setting_id: Float
  rating: Float
  read_count: Float
  reading_format_id: Float
  referrer_user_id: Float
  review_length: Float
  status_id: Float
  user_id: Float
}

"""
order by var_pop() on columns of table "user_books"
"""
input user_books_var_pop_order_by {
  book_id: order_by
  cached_match_score: order_by
  edition_id: order_by
  id: order_by
  likes_count: order_by
  original_book_id: order_by
  original_edition_id: order_by
  owned_copies: order_by
  privacy_setting_id: order_by
  rating: order_by
  read_count: order_by
  reading_format_id: order_by
  referrer_user_id: order_by
  review_length: order_by
  status_id: order_by
  user_id: order_by
}

"""
aggregate var_samp on columns
"""
type user_books_var_samp_fields {
  book_id: Float
  cached_match_score: Float
  edition_id: Float
  id: Float
  likes_count: Float
  original_book_id: Float
  original_edition_id: Float
  owned_copies: Float
  privacy_setting_id: Float
  rating: Float
  read_count: Float
  reading_format_id: Float
  referrer_user_id: Float
  review_length: Float
  status_id: Float
  user_id: Float
}

"""
order by var_samp() on columns of table "user_books"
"""
input user_books_var_samp_order_by {
  book_id: order_by
  cached_match_score: order_by
  edition_id: order_by
  id: order_by
  likes_count: order_by
  original_book_id: order_by
  original_edition_id: order_by
  owned_copies: order_by
  privacy_setting_id: order_by
  rating: order_by
  read_count: order_by
  reading_format_id: order_by
  referrer_user_id: order_by
  review_length: order_by
  status_id: order_by
  user_id: order_by
}

"""
aggregate variance on columns
"""
type user_books_variance_fields {
  book_id: Float
  cached_match_score: Float
  edition_id: Float
  id: Float
  likes_count: Float
  original_book_id: Float
  original_edition_id: Float
  owned_copies: Float
  privacy_setting_id: Float
  rating: Float
  read_count: Float
  reading_format_id: Float
  referrer_user_id: Float
  review_length: Float
  status_id: Float
  user_id: Float
}

"""
order by variance() on columns of table "user_books"
"""
input user_books_variance_order_by {
  book_id: order_by
  cached_match_score: order_by
  edition_id: order_by
  id: order_by
  likes_count: order_by
  original_book_id: order_by
  original_edition_id: order_by
  owned_copies: order_by
  privacy_setting_id: order_by
  rating: order_by
  read_count: order_by
  reading_format_id: order_by
  referrer_user_id: order_by
  review_length: order_by
  status_id: order_by
  user_id: order_by
}

"""
columns and relationships of "user_flags"
"""
type user_flags {
  action_id: Int
  action_type: String
  category: String!
  created_at: timestamptz
  details: String!
  flag_status: flag_statuses!
  flag_status_id: Int!
  id: Int!
  reported_user_id: Int!
  user_id: Int!
  user_reported: users!
  user_submitted: users!
}

"""
order by aggregate values of table "user_flags"
"""
input user_flags_aggregate_order_by {
  avg: user_flags_avg_order_by
  count: order_by
  max: user_flags_max_order_by
  min: user_flags_min_order_by
  stddev: user_flags_stddev_order_by
  stddev_pop: user_flags_stddev_pop_order_by
  stddev_samp: user_flags_stddev_samp_order_by
  sum: user_flags_sum_order_by
  var_pop: user_flags_var_pop_order_by
  var_samp: user_flags_var_samp_order_by
  variance: user_flags_variance_order_by
}

"""
order by avg() on columns of table "user_flags"
"""
input user_flags_avg_order_by {
  action_id: order_by
  flag_status_id: order_by
  id: order_by
  reported_user_id: order_by
  user_id: order_by
}

"""
Boolean expression to filter rows from the table "user_flags". All fields are combined with a logical 'AND'.
"""
input user_flags_bool_exp {
  _and: [user_flags_bool_exp!]
  _not: user_flags_bool_exp
  _or: [user_flags_bool_exp!]
  action_id: Int_comparison_exp
  action_type: String_comparison_exp
  category: String_comparison_exp
  created_at: timestamptz_comparison_exp
  details: String_comparison_exp
  flag_status: flag_statuses_bool_exp
  flag_status_id: Int_comparison_exp
  id: Int_comparison_exp
  reported_user_id: Int_comparison_exp
  user_id: Int_comparison_exp
  user_reported: users_bool_exp
  user_submitted: users_bool_exp
}

"""
unique or primary key constraints on table "user_flags"
"""
enum user_flags_constraint {
  user_flags_id_key
  user_flags_pkey
}

"""
input type for inserting data into table "user_flags"
"""
input user_flags_insert_input {
  action_id: Int
  action_type: String
  category: String
  details: String
  reported_user_id: Int
  user_id: Int
}

"""
order by max() on columns of table "user_flags"
"""
input user_flags_max_order_by {
  action_id: order_by
  action_type: order_by
  category: order_by
  created_at: order_by
  details: order_by
  flag_status_id: order_by
  id: order_by
  reported_user_id: order_by
  user_id: order_by
}

"""
order by min() on columns of table "user_flags"
"""
input user_flags_min_order_by {
  action_id: order_by
  action_type: order_by
  category: order_by
  created_at: order_by
  details: order_by
  flag_status_id: order_by
  id: order_by
  reported_user_id: order_by
  user_id: order_by
}

"""
response of any mutation on the table "user_flags"
"""
type user_flags_mutation_response {
  affected_rows: Int!
  returning: [user_flags!]!
}

"""
on_conflict condition type for table "user_flags"
"""
input user_flags_on_conflict {
  constraint: user_flags_constraint!
  update_columns: [user_flags_update_column!]!
  where: user_flags_bool_exp
}

"""
Ordering options when selecting data from "user_flags".
"""
input user_flags_order_by {
  action_id: order_by
  action_type: order_by
  category: order_by
  created_at: order_by
  details: order_by
  flag_status: flag_statuses_order_by
  flag_status_id: order_by
  id: order_by
  reported_user_id: order_by
  user_id: order_by
  user_reported: users_order_by
  user_submitted: users_order_by
}

"""
select columns of table "user_flags"
"""
enum user_flags_select_column {
  action_id
  action_type
  category
  created_at
  details
  flag_status_id
  id
  reported_user_id
  user_id
}

"""
order by stddev() on columns of table "user_flags"
"""
input user_flags_stddev_order_by {
  action_id: order_by
  flag_status_id: order_by
  id: order_by
  reported_user_id: order_by
  user_id: order_by
}

"""
order by stddev_pop() on columns of table "user_flags"
"""
input user_flags_stddev_pop_order_by {
  action_id: order_by
  flag_status_id: order_by
  id: order_by
  reported_user_id: order_by
  user_id: order_by
}

"""
order by stddev_samp() on columns of table "user_flags"
"""
input user_flags_stddev_samp_order_by {
  action_id: order_by
  flag_status_id: order_by
  id: order_by
  reported_user_id: order_by
  user_id: order_by
}

"""
Streaming cursor of the table "user_flags"
"""
input user_flags_stream_cursor_input {
  initial_value: user_flags_stream_cursor_value_input!
  ordering: cursor_ordering
}

"""
Initial value of the column from where the streaming should start
"""
input user_flags_stream_cursor_value_input {
  action_id: Int
  action_type: String
  category: String
  created_at: timestamptz
  details: String
  flag_status_id: Int
  id: Int
  reported_user_id: Int
  user_id: Int
}

"""
order by sum() on columns of table "user_flags"
"""
input user_flags_sum_order_by {
  action_id: order_by
  flag_status_id: order_by
  id: order_by
  reported_user_id: order_by
  user_id: order_by
}

"""
placeholder for update columns of table "user_flags" (current role has no relevant permissions)
"""
enum user_flags_update_column {
  _PLACEHOLDER
}

"""
order by var_pop() on columns of table "user_flags"
"""
input user_flags_var_pop_order_by {
  action_id: order_by
  flag_status_id: order_by
  id: order_by
  reported_user_id: order_by
  user_id: order_by
}

"""
order by var_samp() on columns of table "user_flags"
"""
input user_flags_var_samp_order_by {
  action_id: order_by
  flag_status_id: order_by
  id: order_by
  reported_user_id: order_by
  user_id: order_by
}

"""
order by variance() on columns of table "user_flags"
"""
input user_flags_variance_order_by {
  action_id: order_by
  flag_status_id: order_by
  id: order_by
  reported_user_id: order_by
  user_id: order_by
}

"""
columns and relationships of "user_referrals"
"""
type user_referrals {
  created_at: timestamp!
  id: bigint!
  referrer: users
  referrer_id: Int
  state: String
  updated_at: timestamp!
  user: users
  user_id: Int
}

"""
Boolean expression to filter rows from the table "user_referrals". All fields are combined with a logical 'AND'.
"""
input user_referrals_bool_exp {
  _and: [user_referrals_bool_exp!]
  _not: user_referrals_bool_exp
  _or: [user_referrals_bool_exp!]
  created_at: timestamp_comparison_exp
  id: bigint_comparison_exp
  referrer: users_bool_exp
  referrer_id: Int_comparison_exp
  state: String_comparison_exp
  updated_at: timestamp_comparison_exp
  user: users_bool_exp
  user_id: Int_comparison_exp
}

"""
Ordering options when selecting data from "user_referrals".
"""
input user_referrals_order_by {
  created_at: order_by
  id: order_by
  referrer: users_order_by
  referrer_id: order_by
  state: order_by
  updated_at: order_by
  user: users_order_by
  user_id: order_by
}

"""
select columns of table "user_referrals"
"""
enum user_referrals_select_column {
  created_at
  id
  referrer_id
  state
  updated_at
  user_id
}

"""
Streaming cursor of the table "user_referrals"
"""
input user_referrals_stream_cursor_input {
  initial_value: user_referrals_stream_cursor_value_input!
  ordering: cursor_ordering
}

"""
Initial value of the column from where the streaming should start
"""
input user_referrals_stream_cursor_value_input {
  created_at: timestamp
  id: bigint
  referrer_id: Int
  state: String
  updated_at: timestamp
  user_id: Int
}

"""
columns and relationships of "user_statuses"
"""
type user_statuses {
  id: Int!
  status: String!
  users: [users!]!
}

"""
Boolean expression to filter rows from the table "user_statuses". All fields are combined with a logical 'AND'.
"""
input user_statuses_bool_exp {
  _and: [user_statuses_bool_exp!]
  _not: user_statuses_bool_exp
  _or: [user_statuses_bool_exp!]
  id: Int_comparison_exp
  status: String_comparison_exp
  users: users_bool_exp
}

"""
Ordering options when selecting data from "user_statuses".
"""
input user_statuses_order_by {
  id: order_by
  status: order_by
  users_aggregate: users_aggregate_order_by
}

"""
select columns of table "user_statuses"
"""
enum user_statuses_select_column {
  id
  status
}

"""
Streaming cursor of the table "user_statuses"
"""
input user_statuses_stream_cursor_input {
  initial_value: user_statuses_stream_cursor_value_input!
  ordering: cursor_ordering
}

"""
Initial value of the column from where the streaming should start
"""
input user_statuses_stream_cursor_value_input {
  id: Int
  status: String
}

"""
columns and relationships of "users"
"""
type users {
  access_level: Int
  account_privacy_setting_id: Int!
  activities: [activities!]!
  activity_privacy_settings_id: Int!
  admin: Boolean!
  bio: String
  birthdate: date
  blocked_users: [user_blocks!]!
  books_count: Int!
  cached_cover: jsonb!
  cached_genres: jsonb!
  cached_image: jsonb!
  collection_imports: [collection_imports!]!
  confirmation_sent_at: timestamp
  confirmed_at: timestamp
  created_at: timestamptz!
  current_sign_in_at: timestamp
  email: String
  email_verified: timestamptz
  flair: String
  followed_by_users: [followed_users!]!
  followed_lists: [followed_lists!]!
  followed_prompts: [followed_prompts!]!
  followed_users: [followed_users!]!
  followed_users_count: Int!
  followers_count: Int!
  goals: [goals!]!
  id: Int!
  image: images
  image_id: Int
  last_activity_at: timestamp
  last_sign_in_at: timestamp
  librarian_roles: jsonb!
  link: String
  lists: [lists!]!
  lists_aggregate: lists_aggregate!
  location: String
  locked_at: timestamp
  match_updated_at: timestamp
  membership: String
  membership_ends_at: timestamp
  name: String
  notification_deliveries: [notification_deliveries!]!
  notification_deliveries_aggregate: notification_deliveries_aggregate!
  object_type: String
  onboarded: Boolean!
  payment_system_id: Int
  pro: Boolean!
  prompt_answers: [prompt_answers!]!
  prompt_answers_aggregate: prompt_answers_aggregate!
  prompts: [prompts!]!
  pronoun_personal: String!
  pronoun_possessive: String!
  recommendations: [recommendations!]!
  recommended: [recommendations!]!
  referrer_id: Int
  referrer_url: String
  referrered_users: [user_books!]!
  referrered_users_aggregate: user_books_aggregate!
  remember_created_at: timestamp
  reported_user_flags: [user_flags!]!
  reset_password_sent_at: timestamp
  sign_in_count: Int
  status_id: Int!
  taggings: [taggings!]!
  taggings_aggregate: taggings_aggregate!
  unconfirmed_email: String
  updated_at: timestamptz!
  user_books: [user_books!]!
  user_books_aggregate: user_books_aggregate!
  user_flags: [user_flags!]!
  username: citext
}

"""
columns and relationships of "users_aggregate_by_created_at_date"
"""
type users_aggregate_by_created_at_date {
  count: bigint
  created_at: date
}

"""
Boolean expression to filter rows from the table "users_aggregate_by_created_at_date". All fields are combined with a logical 'AND'.
"""
input users_aggregate_by_created_at_date_bool_exp {
  _and: [users_aggregate_by_created_at_date_bool_exp!]
  _not: users_aggregate_by_created_at_date_bool_exp
  _or: [users_aggregate_by_created_at_date_bool_exp!]
  count: bigint_comparison_exp
  created_at: date_comparison_exp
}

"""
Ordering options when selecting data from "users_aggregate_by_created_at_date".
"""
input users_aggregate_by_created_at_date_order_by {
  count: order_by
  created_at: order_by
}

"""
select columns of table "users_aggregate_by_created_at_date"
"""
enum users_aggregate_by_created_at_date_select_column {
  count
  created_at
}

"""
Streaming cursor of the table "users_aggregate_by_created_at_date"
"""
input users_aggregate_by_created_at_date_stream_cursor_input {
  initial_value: users_aggregate_by_created_at_date_stream_cursor_value_input!
  ordering: cursor_ordering
}

"""
Initial value of the column from where the streaming should start
"""
input users_aggregate_by_created_at_date_stream_cursor_value_input {
  count: bigint
  created_at: date
}

"""
order by aggregate values of table "users"
"""
input users_aggregate_order_by {
  avg: users_avg_order_by
  count: order_by
  max: users_max_order_by
  min: users_min_order_by
  stddev: users_stddev_order_by
  stddev_pop: users_stddev_pop_order_by
  stddev_samp: users_stddev_samp_order_by
  sum: users_sum_order_by
  var_pop: users_var_pop_order_by
  var_samp: users_var_samp_order_by
  variance: users_variance_order_by
}

"""
order by avg() on columns of table "users"
"""
input users_avg_order_by {
  access_level: order_by
  account_privacy_setting_id: order_by
  activity_privacy_settings_id: order_by
  books_count: order_by
  followed_users_count: order_by
  followers_count: order_by
  id: order_by
  image_id: order_by
  payment_system_id: order_by
  referrer_id: order_by
  sign_in_count: order_by
  status_id: order_by
}

"""
Boolean expression to filter rows from the table "users". All fields are combined with a logical 'AND'.
"""
input users_bool_exp {
  _and: [users_bool_exp!]
  _not: users_bool_exp
  _or: [users_bool_exp!]
  access_level: Int_comparison_exp
  account_privacy_setting_id: Int_comparison_exp
  activities: activities_bool_exp
  activity_privacy_settings_id: Int_comparison_exp
  admin: Boolean_comparison_exp
  bio: String_comparison_exp
  birthdate: date_comparison_exp
  blocked_users: user_blocks_bool_exp
  books_count: Int_comparison_exp
  cached_cover: jsonb_comparison_exp
  cached_genres: jsonb_comparison_exp
  cached_image: jsonb_comparison_exp
  collection_imports: collection_imports_bool_exp
  confirmation_sent_at: timestamp_comparison_exp
  confirmed_at: timestamp_comparison_exp
  created_at: timestamptz_comparison_exp
  current_sign_in_at: timestamp_comparison_exp
  email: String_comparison_exp
  email_verified: timestamptz_comparison_exp
  flair: String_comparison_exp
  followed_by_users: followed_users_bool_exp
  followed_lists: followed_lists_bool_exp
  followed_prompts: followed_prompts_bool_exp
  followed_users: followed_users_bool_exp
  followed_users_count: Int_comparison_exp
  followers_count: Int_comparison_exp
  goals: goals_bool_exp
  id: Int_comparison_exp
  image: images_bool_exp
  image_id: Int_comparison_exp
  last_activity_at: timestamp_comparison_exp
  last_sign_in_at: timestamp_comparison_exp
  librarian_roles: jsonb_comparison_exp
  link: String_comparison_exp
  lists: lists_bool_exp
  lists_aggregate: lists_aggregate_bool_exp
  location: String_comparison_exp
  locked_at: timestamp_comparison_exp
  match_updated_at: timestamp_comparison_exp
  membership: String_comparison_exp
  membership_ends_at: timestamp_comparison_exp
  name: String_comparison_exp
  notification_deliveries: notification_deliveries_bool_exp
  notification_deliveries_aggregate: notification_deliveries_aggregate_bool_exp
  object_type: String_comparison_exp
  onboarded: Boolean_comparison_exp
  payment_system_id: Int_comparison_exp
  pro: Boolean_comparison_exp
  prompt_answers: prompt_answers_bool_exp
  prompt_answers_aggregate: prompt_answers_aggregate_bool_exp
  prompts: prompts_bool_exp
  pronoun_personal: String_comparison_exp
  pronoun_possessive: String_comparison_exp
  recommendations: recommendations_bool_exp
  recommended: recommendations_bool_exp
  referrer_id: Int_comparison_exp
  referrer_url: String_comparison_exp
  referrered_users: user_books_bool_exp
  referrered_users_aggregate: user_books_aggregate_bool_exp
  remember_created_at: timestamp_comparison_exp
  reported_user_flags: user_flags_bool_exp
  reset_password_sent_at: timestamp_comparison_exp
  sign_in_count: Int_comparison_exp
  status_id: Int_comparison_exp
  taggings: taggings_bool_exp
  taggings_aggregate: taggings_aggregate_bool_exp
  unconfirmed_email: String_comparison_exp
  updated_at: timestamptz_comparison_exp
  user_books: user_books_bool_exp
  user_books_aggregate: user_books_aggregate_bool_exp
  user_flags: user_flags_bool_exp
  username: citext_comparison_exp
}

"""
order by max() on columns of table "users"
"""
input users_max_order_by {
  access_level: order_by
  account_privacy_setting_id: order_by
  activity_privacy_settings_id: order_by
  bio: order_by
  birthdate: order_by
  books_count: order_by
  confirmation_sent_at: order_by
  confirmed_at: order_by
  created_at: order_by
  current_sign_in_at: order_by
  email: order_by
  email_verified: order_by
  flair: order_by
  followed_users_count: order_by
  followers_count: order_by
  id: order_by
  image_id: order_by
  last_activity_at: order_by
  last_sign_in_at: order_by
  link: order_by
  location: order_by
  locked_at: order_by
  match_updated_at: order_by
  membership: order_by
  membership_ends_at: order_by
  name: order_by
  object_type: order_by
  payment_system_id: order_by
  pronoun_personal: order_by
  pronoun_possessive: order_by
  referrer_id: order_by
  referrer_url: order_by
  remember_created_at: order_by
  reset_password_sent_at: order_by
  sign_in_count: order_by
  status_id: order_by
  unconfirmed_email: order_by
  updated_at: order_by
  username: order_by
}

"""
order by min() on columns of table "users"
"""
input users_min_order_by {
  access_level: order_by
  account_privacy_setting_id: order_by
  activity_privacy_settings_id: order_by
  bio: order_by
  birthdate: order_by
  books_count: order_by
  confirmation_sent_at: order_by
  confirmed_at: order_by
  created_at: order_by
  current_sign_in_at: order_by
  email: order_by
  email_verified: order_by
  flair: order_by
  followed_users_count: order_by
  followers_count: order_by
  id: order_by
  image_id: order_by
  last_activity_at: order_by
  last_sign_in_at: order_by
  link: order_by
  location: order_by
  locked_at: order_by
  match_updated_at: order_by
  membership: order_by
  membership_ends_at: order_by
  name: order_by
  object_type: order_by
  payment_system_id: order_by
  pronoun_personal: order_by
  pronoun_possessive: order_by
  referrer_id: order_by
  referrer_url: order_by
  remember_created_at: order_by
  reset_password_sent_at: order_by
  sign_in_count: order_by
  status_id: order_by
  unconfirmed_email: order_by
  updated_at: order_by
  username: order_by
}

"""
Ordering options when selecting data from "users".
"""
input users_order_by {
  access_level: order_by
  account_privacy_setting_id: order_by
  activities_aggregate: activities_aggregate_order_by
  activity_privacy_settings_id: order_by
  admin: order_by
  bio: order_by
  birthdate: order_by
  blocked_users_aggregate: user_blocks_aggregate_order_by
  books_count: order_by
  cached_cover: order_by
  cached_genres: order_by
  cached_image: order_by
  collection_imports_aggregate: collection_imports_aggregate_order_by
  confirmation_sent_at: order_by
  confirmed_at: order_by
  created_at: order_by
  current_sign_in_at: order_by
  email: order_by
  email_verified: order_by
  flair: order_by
  followed_by_users_aggregate: followed_users_aggregate_order_by
  followed_lists_aggregate: followed_lists_aggregate_order_by
  followed_prompts_aggregate: followed_prompts_aggregate_order_by
  followed_users_aggregate: followed_users_aggregate_order_by
  followed_users_count: order_by
  followers_count: order_by
  goals_aggregate: goals_aggregate_order_by
  id: order_by
  image: images_order_by
  image_id: order_by
  last_activity_at: order_by
  last_sign_in_at: order_by
  librarian_roles: order_by
  link: order_by
  lists_aggregate: lists_aggregate_order_by
  location: order_by
  locked_at: order_by
  match_updated_at: order_by
  membership: order_by
  membership_ends_at: order_by
  name: order_by
  notification_deliveries_aggregate: notification_deliveries_aggregate_order_by
  object_type: order_by
  onboarded: order_by
  payment_system_id: order_by
  pro: order_by
  prompt_answers_aggregate: prompt_answers_aggregate_order_by
  prompts_aggregate: prompts_aggregate_order_by
  pronoun_personal: order_by
  pronoun_possessive: order_by
  recommendations_aggregate: recommendations_aggregate_order_by
  recommended_aggregate: recommendations_aggregate_order_by
  referrer_id: order_by
  referrer_url: order_by
  referrered_users_aggregate: user_books_aggregate_order_by
  remember_created_at: order_by
  reported_user_flags_aggregate: user_flags_aggregate_order_by
  reset_password_sent_at: order_by
  sign_in_count: order_by
  status_id: order_by
  taggings_aggregate: taggings_aggregate_order_by
  unconfirmed_email: order_by
  updated_at: order_by
  user_books_aggregate: user_books_aggregate_order_by
  user_flags_aggregate: user_flags_aggregate_order_by
  username: order_by
}

"""
select columns of table "users"
"""
enum users_select_column {
  access_level
  account_privacy_setting_id
  activity_privacy_settings_id
  admin
  bio
  birthdate
  books_count
  cached_cover
  cached_genres
  cached_image
  confirmation_sent_at
  confirmed_at
  created_at
  current_sign_in_at
  email
  email_verified
  flair
  followed_users_count
  followers_count
  id
  image_id
  last_activity_at
  last_sign_in_at
  librarian_roles
  link
  location
  locked_at
  match_updated_at
  membership
  membership_ends_at
  name
  object_type
  onboarded
  payment_system_id
  pro
  pronoun_personal
  pronoun_possessive
  referrer_id
  referrer_url
  remember_created_at
  reset_password_sent_at
  sign_in_count
  status_id
  unconfirmed_email
  updated_at
  username
}

"""
order by stddev() on columns of table "users"
"""
input users_stddev_order_by {
  access_level: order_by
  account_privacy_setting_id: order_by
  activity_privacy_settings_id: order_by
  books_count: order_by
  followed_users_count: order_by
  followers_count: order_by
  id: order_by
  image_id: order_by
  payment_system_id: order_by
  referrer_id: order_by
  sign_in_count: order_by
  status_id: order_by
}

"""
order by stddev_pop() on columns of table "users"
"""
input users_stddev_pop_order_by {
  access_level: order_by
  account_privacy_setting_id: order_by
  activity_privacy_settings_id: order_by
  books_count: order_by
  followed_users_count: order_by
  followers_count: order_by
  id: order_by
  image_id: order_by
  payment_system_id: order_by
  referrer_id: order_by
  sign_in_count: order_by
  status_id: order_by
}

"""
order by stddev_samp() on columns of table "users"
"""
input users_stddev_samp_order_by {
  access_level: order_by
  account_privacy_setting_id: order_by
  activity_privacy_settings_id: order_by
  books_count: order_by
  followed_users_count: order_by
  followers_count: order_by
  id: order_by
  image_id: order_by
  payment_system_id: order_by
  referrer_id: order_by
  sign_in_count: order_by
  status_id: order_by
}

"""
Streaming cursor of the table "users"
"""
input users_stream_cursor_input {
  initial_value: users_stream_cursor_value_input!
  ordering: cursor_ordering
}

"""
Initial value of the column from where the streaming should start
"""
input users_stream_cursor_value_input {
  access_level: Int
  account_privacy_setting_id: Int
  activity_privacy_settings_id: Int
  admin: Boolean
  bio: String
  birthdate: date
  books_count: Int
  cached_cover: jsonb
  cached_genres: jsonb
  cached_image: jsonb
  confirmation_sent_at: timestamp
  confirmed_at: timestamp
  created_at: timestamptz
  current_sign_in_at: timestamp
  email: String
  email_verified: timestamptz
  flair: String
  followed_users_count: Int
  followers_count: Int
  id: Int
  image_id: Int
  last_activity_at: timestamp
  last_sign_in_at: timestamp
  librarian_roles: jsonb
  link: String
  location: String
  locked_at: timestamp
  match_updated_at: timestamp
  membership: String
  membership_ends_at: timestamp
  name: String
  object_type: String
  onboarded: Boolean
  payment_system_id: Int
  pro: Boolean
  pronoun_personal: String
  pronoun_possessive: String
  referrer_id: Int
  referrer_url: String
  remember_created_at: timestamp
  reset_password_sent_at: timestamp
  sign_in_count: Int
  status_id: Int
  unconfirmed_email: String
  updated_at: timestamptz
  username: citext
}

"""
order by sum() on columns of table "users"
"""
input users_sum_order_by {
  access_level: order_by
  account_privacy_setting_id: order_by
  activity_privacy_settings_id: order_by
  books_count: order_by
  followed_users_count: order_by
  followers_count: order_by
  id: order_by
  image_id: order_by
  payment_system_id: order_by
  referrer_id: order_by
  sign_in_count: order_by
  status_id: order_by
}

"""
order by var_pop() on columns of table "users"
"""
input users_var_pop_order_by {
  access_level: order_by
  account_privacy_setting_id: order_by
  activity_privacy_settings_id: order_by
  books_count: order_by
  followed_users_count: order_by
  followers_count: order_by
  id: order_by
  image_id: order_by
  payment_system_id: order_by
  referrer_id: order_by
  sign_in_count: order_by
  status_id: order_by
}

"""
order by var_samp() on columns of table "users"
"""
input users_var_samp_order_by {
  access_level: order_by
  account_privacy_setting_id: order_by
  activity_privacy_settings_id: order_by
  books_count: order_by
  followed_users_count: order_by
  followers_count: order_by
  id: order_by
  image_id: order_by
  payment_system_id: order_by
  referrer_id: order_by
  sign_in_count: order_by
  status_id: order_by
}

"""
order by variance() on columns of table "users"
"""
input users_variance_order_by {
  access_level: order_by
  account_privacy_setting_id: order_by
  activity_privacy_settings_id: order_by
  books_count: order_by
  followed_users_count: order_by
  followers_count: order_by
  id: order_by
  image_id: order_by
  payment_system_id: order_by
  referrer_id: order_by
  sign_in_count: order_by
  status_id: order_by
}
</file>

<file path="Makefile">
# Makefile for hardcover-cli

APP := hardcover-cli
VERSION ?= $(shell git describe --tags --always --dirty)
GO := go
LINT := golangci-lint
GENQLIENT := go run github.com/Khan/genqlient

BUILD_FLAGS := -ldflags "-X main.Version=${VERSION}"

# GraphQL configuration
GRAPHQL_DIR := internal/client
SCHEMA_FILE := $(GRAPHQL_DIR)/schema.graphql
GENQLIENT_CONFIG := $(GRAPHQL_DIR)/genqlient.yaml
GENERATED_FILE := $(GRAPHQL_DIR)/generated.go

# Default GraphQL endpoint (update this with the actual Hardcover API endpoint)
GRAPHQL_ENDPOINT ?= https://api.hardcover.app/v1/graphql

# Use latest version of genqlient
GENQLIENT_LATEST := go run github.com/Khan/genqlient@latest

.PHONY: all build test lint install clean help release fmt graphql-fetch graphql-generate graphql-update

all: build

## Build the binary
build:
	@echo "Building $(APP) version $(VERSION)"
	$(GO) build -o bin/$(APP) $(BUILD_FLAGS) .

## Run tests
test:
	$(GO) test ./... -timeout 2m

## Run linter
lint:
	$(LINT) run

## Format code
fmt:
	$(GO) fmt ./...

## Install binary into $GOBIN or default $GOPATH/bin
install: build
	@echo "Installing $(APP)..."
	install -m 0755 bin/$(APP) $(GOBIN) || install -m 0755 bin/$(APP) $(GOPATH)/bin

## Remove binaries and caches
clean:
	@echo "Cleaning..."
	rm -rf bin/
	$(GO) clean -cache ./...

## Fetch latest GraphQL schema from remote endpoint using the CLI
graphql-fetch:
	@echo "Fetching latest GraphQL schema using hardcover-cli..."
	@if [ ! -f bin/$(APP) ]; then \
		echo "Building hardcover-cli first..."; \
		$(MAKE) build; \
	fi
	@bin/$(APP) schema --output $(SCHEMA_FILE)
	@echo "Schema updated successfully: $(SCHEMA_FILE)"

## Generate Go code from GraphQL schema and queries using latest version
graphql-generate:
	@echo "Generating Go code from GraphQL schema using latest version of genqlient..."
	@if [ ! -f $(GENQLIENT_CONFIG) ]; then \
		echo "Error: genqlient config not found at $(GENQLIENT_CONFIG)"; \
		exit 1; \
	fi
	@if [ ! -f $(SCHEMA_FILE) ]; then \
		echo "Error: Schema file not found at $(SCHEMA_FILE)"; \
		echo "Run 'make graphql-fetch' first to download the schema"; \
		exit 1; \
	fi
	$(GENQLIENT_LATEST) $(GENQLIENT_CONFIG)
	@echo "Generated Go code: $(GENERATED_FILE)"

## Fetch latest schema and regenerate code (complete update)
graphql-update: graphql-fetch graphql-generate
	@echo "GraphQL schema and code generation completed successfully!"

## Show GraphQL schema information
graphql-info:
	@echo "GraphQL Configuration:"
	@echo "  Schema file: $(SCHEMA_FILE)"
	@echo "  Config file: $(GENQLIENT_CONFIG)"
	@echo "  Generated file: $(GENERATED_FILE)"
	@echo "  Endpoint: $(GRAPHQL_ENDPOINT)"
	@echo ""
	@if [ -f $(SCHEMA_FILE) ]; then \
		echo "Current schema types:"; \
		grep "^type " $(SCHEMA_FILE) | sed 's/^type /  - /' | sed 's/ {.*//'; \
	else \
		echo "No schema file found at $(SCHEMA_FILE)"; \
	fi

## Help
help:
	@grep -E '^[a-zA-Z_-]+:.*?## .*$$' $(MAKEFILE_LIST) | \
	awk 'BEGIN {FS = ":.*?## "}; {printf "\033[36m%-15s\033[0m %s\n", $$1, $$2}'
</file>

<file path="README.md">
# Hardcover CLI

A comprehensive command-line interface for interacting with the Hardcover.app GraphQL API.

## Features

- **User Profile Management**: Get your authenticated user profile information
- **Book Search**: Search for books by title, author, or other criteria
- **Book Details**: Retrieve detailed information about specific books
- **Configuration Management**: Easy setup and management of API keys
- **High Test Coverage**: Comprehensive unit tests for all functionality
- **Well-Documented**: Clear help text and documentation for all commands

## Installation

### Prerequisites

- Go 1.19 or later
- A Hardcover.app account and API key

### Build from Source

```bash
git clone <repository-url>
cd hardcover-cli
go build -o hardcover main.go
```

## Configuration

Before using the CLI, you need to set your Hardcover.app API key. You can do this in two ways:

### Option 1: Environment Variable

```bash
export HARDCOVER_API_KEY="your-api-key-here"
```

### Option 2: Configuration File

```bash
hardcover config set-api-key "your-api-key-here"
```

The configuration file is stored at `~/.hardcover/config.yaml`.

## Usage

### Basic Commands

#### Get Your Profile

```bash
hardcover me
```

Displays your user profile information including:
- User ID
- Username
- Email address
- Account creation date
- Last updated date

#### Search for Books

```bash
hardcover search books "golang programming"
hardcover search books "tolkien"
hardcover search books "machine learning"
```

Returns matching books with:
- Title and author information
- Publication details
- Ratings and genres
- Hardcover.app URL

#### Get Book Details

```bash
hardcover book get 12345
hardcover book get "book-slug-or-id"
```

Displays comprehensive book information including:
- Title and description
- Author(s) and contributors
- Publication details (year, page count, ISBN)
- Genres and categories
- Ratings and reviews summary
- Cover image URL
- Hardcover.app URL

### Configuration Commands

#### Set API Key

```bash
hardcover config set-api-key "your-api-key-here"
```

#### Get Current API Key

```bash
hardcover config get-api-key
```

#### Show Configuration File Path

```bash
hardcover config show-path
```

### Global Options

- `--config`: Specify a custom config file path
- `--api-key`: Override the API key for a single command
- `--help`: Show help for any command

## Examples

### Search and Get Book Details

```bash
# Search for Go programming books
hardcover search books "golang"

# Get details for a specific book (use the ID from search results)
hardcover book get 67890
```

### Profile Management

```bash
# Get your profile
hardcover me

# Set up your API key
hardcover config set-api-key "your-api-key"

# Check your current API key
hardcover config get-api-key
```

## Development

### Project Structure

```
hardcover-cli/
├── cmd/                    # CLI command implementations
│   ├── root.go            # Root command and CLI setup
│   ├── me.go              # User profile command
│   ├── search.go          # Search commands
│   ├── book.go            # Book-related commands
│   ├── config.go          # Configuration commands
│   └── *_test.go          # Unit tests
├── internal/
│   ├── client/            # GraphQL client implementation
│   │   ├── client.go      # HTTP client wrapper
│   │   ├── schema.graphql # GraphQL schema
│   │   └── queries.graphql # GraphQL queries
│   └── config/            # Configuration management
│       ├── config.go      # Configuration logic
│       └── config_test.go # Configuration tests
├── main.go                # Application entry point
├── go.mod                 # Go module definition
└── README.md             # This file
```

### Running Tests

```bash
# Run all tests
go test ./...

# Run tests with coverage
go test ./... -cover

# Run tests for specific package
go test ./internal/config -v
```

### GraphQL Schema

The application uses a GraphQL schema based on the Hardcover.app API. The schema is defined in `internal/client/schema.graphql` and includes types for:

- User profile information
- Book details and metadata
- Search results
- Contributors and genres

### Key Dependencies

- **Cobra**: CLI framework for Go
- **Testify**: Testing toolkit with assertions and mocks
- **YAML**: Configuration file parsing

## API Reference

### GraphQL Queries

The application uses the following GraphQL queries:

#### Get Current User

```graphql
query GetCurrentUser {
  me {
    id
    username
    email
    createdAt
    updatedAt
  }
}
```

#### Search Books

```graphql
query SearchBooks($query: String!) {
  search(query: $query, type: BOOKS) {
    ... on BookSearchResults {
      totalCount
      results {
        ... on Book {
          id
          title
          slug
          cached_contributors {
            name
            role
          }
          cached_genres {
            name
          }
          averageRating
          ratingsCount
        }
      }
    }
  }
}
```

#### Get Book Details

```graphql
query GetBook($id: ID!) {
  book(id: $id) {
    id
    title
    description
    slug
    isbn
    publicationYear
    pageCount
    cached_contributors {
      name
      role
    }
    cached_genres {
      name
    }
    image
    averageRating
    ratingsCount
    createdAt
    updatedAt
  }
}
```

## Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests for new functionality
5. Ensure all tests pass
6. Submit a pull request

## License

This project is licensed under the MIT License - see the LICENSE file for details.

## Support

For issues and questions:
- Check the help text: `hardcover --help`
- Review the documentation above
- File an issue in the repository

## Changelog

### v1.0.0
- Initial release
- User profile management
- Book search functionality
- Book details retrieval
- Configuration management
- Comprehensive test coverage
</file>

<file path="cmd/config_test.go">
package cmd

import (
	"bytes"
	"context"
	"os"
	"path/filepath"
	"testing"

	"github.com/spf13/cobra"
	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/require"

	"hardcover-cli/internal/config"
)

func TestConfigSetAPIKeyCmd_Success(t *testing.T) {
	// Create temporary directory for config
	tempDir := t.TempDir()

	// Mock the home directory for testing
	oldHome := os.Getenv("HOME")
	os.Setenv("HOME", tempDir)
	defer os.Setenv("HOME", oldHome)

	cmd := &cobra.Command{}
	cmd.SetContext(context.Background())

	// Capture output
	var output bytes.Buffer
	cmd.SetOut(&output)

	// Execute command
	err := configSetAPIKeyCmd.RunE(cmd, []string{"test-api-key-123"})
	require.NoError(t, err)

	// Verify output
	outputStr := output.String()
	assert.Contains(t, outputStr, "API key has been set and saved to configuration file")
	assert.Contains(t, outputStr, "Configuration file:")

	// Verify config file was created and contains correct data
	configPath := filepath.Join(tempDir, ".hardcover", "config.yaml")
	_, err = os.Stat(configPath)
	require.NoError(t, err)

	// Load config and verify
	cfg, err := config.LoadConfig()
	require.NoError(t, err)
	assert.Equal(t, "test-api-key-123", cfg.APIKey)
}

func TestConfigSetAPIKeyCmd_RequiresArgument(t *testing.T) {
	cmd := &cobra.Command{}
	cmd.SetContext(context.Background())

	// Test with no arguments - this should fail validation before reaching RunE
	err := configSetAPIKeyCmd.Args(cmd, []string{})
	require.Error(t, err)

	// Test with too many arguments - this should fail validation before reaching RunE
	err = configSetAPIKeyCmd.Args(cmd, []string{"arg1", "arg2"})
	require.Error(t, err)
}

func TestConfigGetAPIKeyCmd_WithAPIKey(t *testing.T) {
	// Create temporary directory for config
	tempDir := t.TempDir()

	// Mock the home directory for testing
	oldHome := os.Getenv("HOME")
	os.Setenv("HOME", tempDir)
	defer os.Setenv("HOME", oldHome)

	// Create config with API key
	cfg := &config.Config{
		APIKey:  "test-api-key-123456789",
		BaseURL: "https://api.hardcover.app/v1/graphql",
	}
	err := config.SaveConfig(cfg)
	require.NoError(t, err)

	cmd := &cobra.Command{}
	cmd.SetContext(context.Background())

	// Capture output
	var output bytes.Buffer
	cmd.SetOut(&output)

	// Execute command
	err = configGetAPIKeyCmd.RunE(cmd, []string{})
	require.NoError(t, err)

	// Verify output shows masked API key
	outputStr := output.String()
	assert.Contains(t, outputStr, "API key: test...6789")
	assert.Contains(t, outputStr, "Source: Configuration file")
}

func TestConfigGetAPIKeyCmd_WithEnvironmentVariable(t *testing.T) {
	// Set environment variable
	expectedAPIKey := "env-api-key-123456789"
	os.Setenv("HARDCOVER_API_KEY", expectedAPIKey)
	defer os.Unsetenv("HARDCOVER_API_KEY")

	// Create temporary directory for config
	tempDir := t.TempDir()

	// Mock the home directory for testing
	oldHome := os.Getenv("HOME")
	os.Setenv("HOME", tempDir)
	defer os.Setenv("HOME", oldHome)

	cmd := &cobra.Command{}
	cmd.SetContext(context.Background())

	// Capture output
	var output bytes.Buffer
	cmd.SetOut(&output)

	// Execute command
	err := configGetAPIKeyCmd.RunE(cmd, []string{})
	require.NoError(t, err)

	// Verify output shows masked API key from environment
	outputStr := output.String()
	assert.Contains(t, outputStr, "API key: env-...6789")
	assert.Contains(t, outputStr, "Source: Environment variable")
}

func TestConfigGetAPIKeyCmd_NoAPIKey(t *testing.T) {
	// Make sure no environment variable is set
	os.Unsetenv("HARDCOVER_API_KEY")

	// Create temporary directory for config
	tempDir := t.TempDir()

	// Mock the home directory for testing
	oldHome := os.Getenv("HOME")
	os.Setenv("HOME", tempDir)
	defer os.Setenv("HOME", oldHome)

	cmd := &cobra.Command{}
	cmd.SetContext(context.Background())

	// Capture output
	var output bytes.Buffer
	cmd.SetOut(&output)

	// Execute command
	err := configGetAPIKeyCmd.RunE(cmd, []string{})
	require.NoError(t, err)

	// Verify output shows no API key message
	outputStr := output.String()
	assert.Contains(t, outputStr, "No API key is currently set")
	assert.Contains(t, outputStr, "hardcover config set-api-key")
	assert.Contains(t, outputStr, "export HARDCOVER_API_KEY")
}

func TestConfigGetAPIKeyCmd_ShortAPIKey(t *testing.T) {
	// Create temporary directory for config
	tempDir := t.TempDir()

	// Mock the home directory for testing
	oldHome := os.Getenv("HOME")
	os.Setenv("HOME", tempDir)
	defer os.Setenv("HOME", oldHome)

	// Create config with short API key
	cfg := &config.Config{
		APIKey:  "short",
		BaseURL: "https://api.hardcover.app/v1/graphql",
	}
	err := config.SaveConfig(cfg)
	require.NoError(t, err)

	cmd := &cobra.Command{}
	cmd.SetContext(context.Background())

	// Capture output
	var output bytes.Buffer
	cmd.SetOut(&output)

	// Execute command
	err = configGetAPIKeyCmd.RunE(cmd, []string{})
	require.NoError(t, err)

	// Verify output shows full API key for short keys
	outputStr := output.String()
	assert.Contains(t, outputStr, "API key: short")
}

func TestConfigShowPathCmd_Success(t *testing.T) {
	// Create temporary directory for config
	tempDir := t.TempDir()

	// Mock the home directory for testing
	oldHome := os.Getenv("HOME")
	os.Setenv("HOME", tempDir)
	defer os.Setenv("HOME", oldHome)

	cmd := &cobra.Command{}
	cmd.SetContext(context.Background())

	// Capture output
	var output bytes.Buffer
	cmd.SetOut(&output)

	// Execute command
	err := configShowPathCmd.RunE(cmd, []string{})
	require.NoError(t, err)

	// Verify output
	outputStr := output.String()
	expectedPath := filepath.Join(tempDir, ".hardcover", "config.yaml")
	assert.Contains(t, outputStr, "Configuration file path: "+expectedPath)
	assert.Contains(t, outputStr, "Configuration file does not exist yet")
}

func TestConfigShowPathCmd_FileExists(t *testing.T) {
	// Create temporary directory for config
	tempDir := t.TempDir()

	// Mock the home directory for testing
	oldHome := os.Getenv("HOME")
	os.Setenv("HOME", tempDir)
	defer os.Setenv("HOME", oldHome)

	// Create config file
	cfg := &config.Config{
		APIKey:  "test-api-key",
		BaseURL: "https://api.hardcover.app/v1/graphql",
	}
	err := config.SaveConfig(cfg)
	require.NoError(t, err)

	cmd := &cobra.Command{}
	cmd.SetContext(context.Background())

	// Capture output
	var output bytes.Buffer
	cmd.SetOut(&output)

	// Execute command
	err = configShowPathCmd.RunE(cmd, []string{})
	require.NoError(t, err)

	// Verify output
	outputStr := output.String()
	expectedPath := filepath.Join(tempDir, ".hardcover", "config.yaml")
	assert.Contains(t, outputStr, "Configuration file path: "+expectedPath)
	assert.Contains(t, outputStr, "Configuration file exists")
	assert.NotContains(t, outputStr, "does not exist yet")
}

func TestConfigCmd_CommandProperties(t *testing.T) {
	// Test config command properties
	assert.Equal(t, "config", configCmd.Use)
	assert.Equal(t, "Manage configuration settings", configCmd.Short)
	assert.NotEmpty(t, configCmd.Long)
	assert.Contains(t, configCmd.Long, "set-api-key")
	assert.Contains(t, configCmd.Long, "get-api-key")
	assert.Contains(t, configCmd.Long, "show-path")
}

func TestConfigSetAPIKeyCmd_CommandProperties(t *testing.T) {
	// Test command properties
	assert.Equal(t, "set-api-key <api_key>", configSetAPIKeyCmd.Use)
	assert.Equal(t, "Set your Hardcover.app API key", configSetAPIKeyCmd.Short)
	assert.NotEmpty(t, configSetAPIKeyCmd.Long)
	assert.Contains(t, configSetAPIKeyCmd.Long, "~/.hardcover/config.yaml")
	assert.Contains(t, configSetAPIKeyCmd.Long, "hardcover config set-api-key")
}

func TestConfigGetAPIKeyCmd_CommandProperties(t *testing.T) {
	// Test command properties
	assert.Equal(t, "get-api-key", configGetAPIKeyCmd.Use)
	assert.Equal(t, "Display your current API key", configGetAPIKeyCmd.Short)
	assert.NotEmpty(t, configGetAPIKeyCmd.Long)
	assert.Contains(t, configGetAPIKeyCmd.Long, "HARDCOVER_API_KEY")
	assert.Contains(t, configGetAPIKeyCmd.Long, "hardcover config get-api-key")
}

func TestConfigShowPathCmd_CommandProperties(t *testing.T) {
	// Test command properties
	assert.Equal(t, "show-path", configShowPathCmd.Use)
	assert.Equal(t, "Show the path to the configuration file", configShowPathCmd.Short)
	assert.NotEmpty(t, configShowPathCmd.Long)
	assert.Contains(t, configShowPathCmd.Long, "hardcover config show-path")
}

func TestConfigCmd_Integration(t *testing.T) {
	// Setup commands for testing
	setupConfigCommands()

	// Test the command is properly registered
	found := false
	for _, cmd := range rootCmd.Commands() {
		if cmd.Use == "config" {
			found = true

			// Check that subcommands are registered
			subCommands := []string{"set-api-key <api_key>", "get-api-key", "show-path"}
			for _, expectedSub := range subCommands {
				subFound := false
				for _, subCmd := range cmd.Commands() {
					if subCmd.Use == expectedSub {
						subFound = true
						break
					}
				}
				assert.True(t, subFound, "subcommand %s should be registered", expectedSub)
			}
			break
		}
	}
	assert.True(t, found, "config command should be registered with root command")
}

func TestConfigSetAPIKeyCmd_UpdatesExistingConfig(t *testing.T) {
	// Create temporary directory for config
	tempDir := t.TempDir()

	// Mock the home directory for testing
	oldHome := os.Getenv("HOME")
	os.Setenv("HOME", tempDir)
	defer os.Setenv("HOME", oldHome)

	// Create initial config
	cfg := &config.Config{
		APIKey:  "old-api-key",
		BaseURL: "https://api.hardcover.app/v1/graphql",
	}
	err := config.SaveConfig(cfg)
	require.NoError(t, err)

	cmd := &cobra.Command{}
	cmd.SetContext(context.Background())

	// Execute command to update API key
	err = configSetAPIKeyCmd.RunE(cmd, []string{"new-api-key"})
	require.NoError(t, err)

	// Verify config was updated
	updatedCfg, err := config.LoadConfig()
	require.NoError(t, err)
	assert.Equal(t, "new-api-key", updatedCfg.APIKey)
	assert.Equal(t, "https://api.hardcover.app/v1/graphql", updatedCfg.BaseURL)
}
</file>

<file path="cmd/config.go">
package cmd

import (
	"fmt"
	"os"

	"github.com/spf13/cobra"

	"hardcover-cli/internal/config"
)

// configCmd represents the config command
var configCmd = &cobra.Command{
	Use:   "config",
	Short: "Manage configuration settings",
	Long: `Manage configuration settings for the Hardcover CLI application.

Available subcommands:
  set-api-key    Set your Hardcover.app API key
  get-api-key    Display your current API key
  show-path      Show the path to the configuration file`,
}

// configSetAPIKeyCmd represents the config set-api-key command
var configSetAPIKeyCmd = &cobra.Command{
	Use:   "set-api-key <api_key>",
	Short: "Set your Hardcover.app API key",
	Long: `Set your Hardcover.app API key for authenticating with the API.

The API key will be stored in a configuration file at:
  ~/.hardcover/config.yaml

Example:
  hardcover config set-api-key "your-api-key-here"`,
	Args: cobra.ExactArgs(1),
	RunE: func(cmd *cobra.Command, args []string) error {
		apiKey := args[0]

		// Load existing config or create new one
		cfg, err := config.LoadConfig()
		if err != nil {
			cfg = config.DefaultConfig()
		}

		// Update the API key
		cfg.APIKey = apiKey

		// Save the configuration
		if saveErr := config.SaveConfig(cfg); saveErr != nil {
			return fmt.Errorf("failed to save configuration: %w", saveErr)
		}

		printToStdoutf(cmd.OutOrStdout(), "API key has been set and saved to configuration file.\n")

		configPath, err := config.GetConfigPath()
		if err == nil {
			printToStdoutf(cmd.OutOrStdout(), "Configuration file: %s\n", configPath)
		}

		return nil
	},
}

// configGetAPIKeyCmd represents the config get-api-key command
var configGetAPIKeyCmd = &cobra.Command{
	Use:   "get-api-key",
	Short: "Display your current API key",
	Long: `Display your current API key from the configuration file or environment variable.

The API key is loaded from:
1. HARDCOVER_API_KEY environment variable (if set)
2. Configuration file at ~/.hardcover/config.yaml

Example:
  hardcover config get-api-key`,
	RunE: func(cmd *cobra.Command, args []string) error {
		cfg, err := config.LoadConfig()
		if err != nil {
			return fmt.Errorf("failed to load configuration: %w", err)
		}

		if cfg.APIKey == "" {
			printToStdoutf(cmd.OutOrStdout(), "No API key is currently set.\n")
			printToStdoutf(cmd.OutOrStdout(), "Set it using:\n")
			printToStdoutf(cmd.OutOrStdout(), "  hardcover config set-api-key \"your-api-key\"\n")
			printToStdoutf(cmd.OutOrStdout(), "  or\n")
			printToStdoutf(cmd.OutOrStdout(), "  export HARDCOVER_API_KEY=\"your-api-key\"\n")
			return nil
		}

		// Show only the first and last few characters for security
		const minLengthForMasking = 10
		if len(cfg.APIKey) > minLengthForMasking {
			masked := cfg.APIKey[:4] + "..." + cfg.APIKey[len(cfg.APIKey)-4:]
			printToStdoutf(cmd.OutOrStdout(), "API key: %s\n", masked)
		} else {
			printToStdoutf(cmd.OutOrStdout(), "API key: %s\n", cfg.APIKey)
		}

		// Show the source of the API key
		if os.Getenv("HARDCOVER_API_KEY") != "" {
			printToStdoutf(cmd.OutOrStdout(), "Source: Environment variable (HARDCOVER_API_KEY)\n")
		} else {
			configPath, err := config.GetConfigPath()
			if err == nil {
				printToStdoutf(cmd.OutOrStdout(), "Source: Configuration file (%s)\n", configPath)
			}
		}

		return nil
	},
}

// configShowPathCmd represents the config show-path command
var configShowPathCmd = &cobra.Command{
	Use:   "show-path",
	Short: "Show the path to the configuration file",
	Long: `Show the path to the configuration file where settings are stored.

Example:
  hardcover config show-path`,
	RunE: func(cmd *cobra.Command, args []string) error {
		configPath, err := config.GetConfigPath()
		if err != nil {
			return fmt.Errorf("failed to get configuration path: %w", err)
		}

		printToStdoutf(cmd.OutOrStdout(), "Configuration file path: %s\n", configPath)

		// Check if file exists
		if _, err := os.Stat(configPath); os.IsNotExist(err) {
			printToStdoutf(cmd.OutOrStdout(), "Configuration file does not exist yet.\n")
			printToStdoutf(cmd.OutOrStdout(), "It will be created when you set your API key.\n")
		} else {
			printToStdoutf(cmd.OutOrStdout(), "Configuration file exists.\n")
		}

		return nil
	},
}

// setupConfigCommands registers the config commands with the root command
func setupConfigCommands() {
	configCmd.AddCommand(configSetAPIKeyCmd)
	configCmd.AddCommand(configGetAPIKeyCmd)
	configCmd.AddCommand(configShowPathCmd)
	rootCmd.AddCommand(configCmd)
}
</file>

<file path="internal/client/client_test.go">
package client

import (
	"context"
	"encoding/json"
	"net/http"
	"net/http/httptest"
	"testing"
	"time"

	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/require"
)

func TestNewClient(t *testing.T) {
	endpoint := "https://api.example.com/graphql"
	apiKey := "test-api-key"

	client := NewClient(endpoint, apiKey)

	assert.NotNil(t, client)
	// Note: We can't access internal fields anymore since we're using an interface
	// The client should be functional though
}

func TestClient_GetCurrentUser_Success(t *testing.T) {
	// Create test server
	server := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
		// Verify request method and headers
		assert.Equal(t, "POST", r.Method)
		assert.Equal(t, "application/json", r.Header.Get("Content-Type"))
		assert.Equal(t, "Bearer test-api-key", r.Header.Get("Authorization"))

		// Verify request body
		var req map[string]interface{}
		err := json.NewDecoder(r.Body).Decode(&req)
		require.NoError(t, err)
		assert.Contains(t, req["query"], "query GetCurrentUser")
		assert.Contains(t, req["query"], "me")

		// Send response
		response := map[string]interface{}{
			"data": map[string]interface{}{
				"me": []map[string]interface{}{
					{
						"id":         123,
						"username":   "testuser",
						"email":      "test@example.com",
						"created_at": "2023-01-01T00:00:00Z",
						"updated_at": "2023-01-02T00:00:00Z",
					},
				},
			},
		}
		w.Header().Set("Content-Type", "application/json")
		json.NewEncoder(w).Encode(response)
	}))
	defer server.Close()

	client := NewClient(server.URL, "test-api-key")

	response, err := client.GetCurrentUser(context.Background())

	require.NoError(t, err)
	assert.NotNil(t, response)
	users := response.GetMe()
	require.Len(t, users, 1)
	user := users[0]
	assert.Equal(t, 123, user.GetId())
	assert.Equal(t, "testuser", user.GetUsername())
	assert.Equal(t, "test@example.com", user.GetEmail())
}

func TestClient_GetCurrentUser_GraphQLError(t *testing.T) {
	// Create test server that returns GraphQL errors
	server := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
		response := map[string]interface{}{
			"data": nil,
			"errors": []map[string]interface{}{
				{
					"message": "User not found",
					"locations": []map[string]interface{}{
						{"line": 1, "column": 9},
					},
				},
			},
		}
		w.Header().Set("Content-Type", "application/json")
		json.NewEncoder(w).Encode(response)
	}))
	defer server.Close()

	client := NewClient(server.URL, "test-api-key")

	_, err := client.GetCurrentUser(context.Background())

	require.Error(t, err)
	assert.Contains(t, err.Error(), "User not found")
}

func TestClient_GetCurrentUser_HTTPError(t *testing.T) {
	// Create test server that returns HTTP error
	server := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
		w.WriteHeader(http.StatusUnauthorized)
		w.Write([]byte("Unauthorized"))
	}))
	defer server.Close()

	client := NewClient(server.URL, "test-api-key")

	_, err := client.GetCurrentUser(context.Background())

	require.Error(t, err)
	assert.Contains(t, err.Error(), "returned error 401")
}

func TestClient_GetCurrentUser_NetworkError(t *testing.T) {
	// Use invalid endpoint to trigger network error
	client := NewClient("http://invalid-endpoint:99999", "test-api-key")

	_, err := client.GetCurrentUser(context.Background())

	require.Error(t, err)
	assert.Contains(t, err.Error(), "dial tcp: address 99999: invalid port")
}

func TestClient_GetCurrentUser_WithoutAPIKey(t *testing.T) {
	// Create test server
	server := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
		// Verify no Authorization header is set
		assert.Empty(t, r.Header.Get("Authorization"))

		// Send response
		response := map[string]interface{}{
			"data": map[string]interface{}{
				"me": []map[string]interface{}{
					{
						"id":       123,
						"username": "testuser",
					},
				},
			},
		}
		w.Header().Set("Content-Type", "application/json")
		json.NewEncoder(w).Encode(response)
	}))
	defer server.Close()

	client := NewClient(server.URL, "")

	response, err := client.GetCurrentUser(context.Background())

	require.NoError(t, err)
	assert.NotNil(t, response)
	users := response.GetMe()
	require.Len(t, users, 1)
	user := users[0]
	assert.Equal(t, 123, user.GetId())
}

func TestClient_GetCurrentUser_WithContext(t *testing.T) {
	// Create test server with delay
	server := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
		time.Sleep(100 * time.Millisecond)

		response := map[string]interface{}{
			"data": map[string]interface{}{
				"me": []map[string]interface{}{
					{
						"id":       123,
						"username": "testuser",
					},
				},
			},
		}
		w.Header().Set("Content-Type", "application/json")
		json.NewEncoder(w).Encode(response)
	}))
	defer server.Close()

	client := NewClient(server.URL, "test-api-key")

	// Create context with timeout
	ctx, cancel := context.WithTimeout(context.Background(), 50*time.Millisecond)
	defer cancel()

	_, err := client.GetCurrentUser(ctx)

	require.Error(t, err)
	assert.Contains(t, err.Error(), "context deadline exceeded")
}

func TestClient_GetBook_Success(t *testing.T) {
	// Create test server
	server := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
		// Verify request
		assert.Equal(t, "POST", r.Method)
		assert.Equal(t, "Bearer test-api-key", r.Header.Get("Authorization"))

		// Send response
		response := map[string]interface{}{
			"data": map[string]interface{}{
				"books_by_pk": map[string]interface{}{
					"id":    123,
					"title": "Test Book",
					"slug":  "test-book",
				},
			},
		}
		w.Header().Set("Content-Type", "application/json")
		json.NewEncoder(w).Encode(response)
	}))
	defer server.Close()

	client := NewClient(server.URL, "test-api-key")

	response, err := client.GetBook(context.Background(), 123)

	require.NoError(t, err)
	assert.NotNil(t, response)
	book := response.GetBooks_by_pk()
	assert.Equal(t, 123, book.GetId())
	assert.Equal(t, "Test Book", book.GetTitle())
}

func TestClient_SearchBooks_Success(t *testing.T) {
	// Create test server
	server := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
		// Verify request
		assert.Equal(t, "POST", r.Method)
		assert.Equal(t, "Bearer test-api-key", r.Header.Get("Authorization"))

		// Send response
		response := map[string]interface{}{
			"data": map[string]interface{}{
				"search": map[string]interface{}{
					"error":      "",
					"ids":        []int{123},
					"page":       1,
					"per_page":   10,
					"query":      "test",
					"query_type": "Book",
					"results":    "[]",
				},
			},
		}
		w.Header().Set("Content-Type", "application/json")
		json.NewEncoder(w).Encode(response)
	}))
	defer server.Close()

	client := NewClient(server.URL, "test-api-key")

	response, err := client.SearchBooks(context.Background(), "test", "Book", 10, 1)

	require.NoError(t, err)
	assert.NotNil(t, response)
	searchResults := response.GetSearch()
	assert.Equal(t, "test", searchResults.GetQuery())
	assert.Equal(t, "Book", searchResults.GetQuery_type())
}
</file>

<file path=".golangci.yml">
version: "2"
run:
  issues-exit-code: 1
  tests: true
linters:
  enable:
    - bodyclose
    - depguard
    - dogsled
    - dupl
    - exhaustive
    - funlen
    - gochecknoinits
    - goconst
    - gocritic
    - gocyclo
    - goprintffuncname
    - gosec
    - lll
    - misspell
    - mnd
    - nakedret
    - noctx
    - nolintlint
    - revive
    - rowserrcheck
    - staticcheck
    - unconvert
    - unparam
    - whitespace
  disable:
    - gochecknoglobals
  settings:
    depguard:
      rules:
        main:
          files:
            - "cmd/**/*.go"
            - "main.go"
          allow:
            - "fmt"
            - "os"
            - "context"
            - "strings"
            - "github.com/spf13/cobra"
            - "hardcover-cli/internal/client"
            - "hardcover-cli/internal/config"
        test:
          files:
            - "**/*_test.go"
          allow:
            - "fmt"
            - "os"
            - "context"
            - "strings"
            - "bytes"
            - "net/http"
            - "net/http/httptest"
            - "path/filepath"
            - "encoding/json"
            - "testing"
            - "time"
            - "github.com/spf13/cobra"
            - "github.com/stretchr/testify/assert"
            - "github.com/stretchr/testify/require"
            - "hardcover-cli/internal/client"
            - "hardcover-cli/internal/config"
            - "hardcover-cli/cmd"
        internal:
          files:
            - "internal/**/*.go"
          allow:
            - "fmt"
            - "os"
            - "path/filepath"
            - "gopkg.in/yaml.v3"
            - "bytes"
            - "context"
            - "encoding/json"
            - "io"
            - "net/http"
            - "time"
            - "github.com/stretchr/testify/assert"
            - "github.com/stretchr/testify/require"
    dupl:
      threshold: 100
    errcheck:
      check-type-assertions: true
      check-blank: true
    goconst:
      min-len: 3
      min-occurrences: 3
    gocritic:
      disabled-checks:
        - wrapperFunc
        - dupImport
        - ifElseChain
      enabled-tags:
        - performance
        - style
        - experimental
        - diagnostic
    gocyclo:
      min-complexity: 15
    govet:
      enable-all: true
    lll:
      line-length: 120
    misspell:
      locale: US
    nakedret:
      max-func-lines: 30
    prealloc:
      simple: true
      range-loops: true
      for-loops: false
    revive:
      confidence: 0.8
    unparam:
      check-exported: false
  exclusions:
    generated: lax
    rules:
      - linters:
          - dupl
          - errcheck
          - funlen
          - gocyclo
          - gosec
        path: _test\.go
      - linters:
          - lll
        source: '^//go:generate '
      - linters:
          - staticcheck
        text: 'SA9003:'
      - linters:
          - staticcheck
        text: 'SA1019:'
    paths:
      - third_party$
      - builtin$
      - examples$
issues:
  max-issues-per-linter: 0
  max-same-issues: 0
  new: false
formatters:
  enable:
    - gofmt
    - goimports
  settings:
    gofmt:
      simplify: true
    goimports:
      local-prefixes:
        - hardcover-cli
  exclusions:
    generated: lax
    paths:
      - third_party$
      - builtin$
      - examples$
</file>

<file path="main.go">
package main

import (
	"fmt"
	"os"

	"hardcover-cli/cmd"
)

// version is set by the build process
var version = "dev"

// main is the entry point for the hardcover CLI application
func main() {
	// Set version in cmd package if needed
	if len(os.Args) > 1 && (os.Args[1] == "--version" || os.Args[1] == "-v") {
		fmt.Printf("hardcover version %s\n", version)
		os.Exit(0)
	}

	// Setup all commands
	cmd.SetupCommands()

	cmd.Execute()
}
</file>

<file path=".github/dependabot.yml">
version: 2
updates:
  # Enable version updates for Go modules
  - package-ecosystem: "gomod"
    directory: "/"
    schedule:
      interval: "weekly"
      day: "monday"
      time: "09:00"
      timezone: "Etc/UTC"
    open-pull-requests-limit: 5
    assignees:
      - "petems"
    reviewers:
      - "petems"
    labels:
      - "dependencies"
      - "go"
    commit-message:
      prefix: "chore"
      include: "scope"
    rebase-strategy: "auto"
    
  # Enable version updates for GitHub Actions
  - package-ecosystem: "github-actions"
    directory: "/"
    schedule:
      interval: "weekly"
      day: "monday"
      time: "09:00"
      timezone: "Etc/UTC"
    open-pull-requests-limit: 3
    assignees:
      - "petems"
    reviewers:
      - "petems"
    labels:
      - "dependencies"
      - "github-actions"
    commit-message:
      prefix: "chore"
      include: "scope"
</file>

<file path=".github/WORKFLOWS.md">
# GitHub Actions Workflows

This document describes the GitHub Actions workflows configured for the Hardcover CLI project.

## Overview

The project uses several GitHub Actions workflows to ensure code quality, security, and automated deployment:

1. **CI (Continuous Integration)** - Main testing and quality checks
2. **Release** - Automated releases and binary builds
3. **Dependency Update** - Automated dependency management
4. **Nightly Tests** - Scheduled testing with latest dependencies

## Workflows

### 1. CI Workflow (`.github/workflows/ci.yml`)

**Triggers:**
- Push to `main` or `develop` branches
- Pull requests to `main` or `develop` branches

**Jobs:**

#### Test Job
- **Matrix Strategy**: Tests across multiple OS (Ubuntu, Windows, macOS) and Go versions (1.19, 1.20, 1.21)
- **Features**:
  - Go module caching for faster builds
  - Race condition detection
  - Code coverage reporting
  - Codecov integration

#### Lint Job
- **golangci-lint**: Comprehensive code linting
- **Configuration**: Uses `.golangci.yml` for custom rules
- **Features**: Performance, style, and security checks

#### Format Check Job
- **gofmt**: Ensures consistent code formatting
- **Fails if**: Any files are not properly formatted

#### Security Job
- **Gosec**: Security vulnerability scanning
- **SARIF Upload**: Results uploaded to GitHub Security tab

#### Build Job
- **Binary Build**: Ensures application builds successfully
- **CLI Testing**: Basic CLI functionality verification
- **Artifact Upload**: Stores built binary

#### Go Vet Job
- **Static Analysis**: Go's built-in static analysis tool
- **Detects**: Common Go programming errors

#### Mod Tidy Job
- **Dependency Check**: Ensures `go.mod` and `go.sum` are clean
- **Fails if**: `go mod tidy` would make changes

### 2. Release Workflow (`.github/workflows/release.yml`)

**Triggers:**
- Git tags matching `v*` pattern (e.g., `v1.0.0`)

**Jobs:**

#### Test Before Release
- **Full Test Suite**: Ensures all tests pass before release
- **Linting**: Code quality verification

#### Build Matrix
- **Cross-Platform**: Builds for multiple OS/architecture combinations
  - Linux (amd64, arm64)
  - macOS (amd64, arm64)
  - Windows (amd64)
- **Versioning**: Embeds version information in binaries
- **Archive Creation**: Creates `.tar.gz` (Unix) and `.zip` (Windows) archives

#### Release Creation
- **GitHub Release**: Automatically creates GitHub release
- **Asset Upload**: Attaches all platform binaries
- **Release Notes**: Includes installation and usage instructions

#### Homebrew (Optional)
- **Formula Update**: Automatically updates Homebrew formula
- **Requires**: `COMMITTER_TOKEN` secret and Homebrew tap repository

### 3. Dependency Update Workflow (`.github/workflows/dependency-update.yml`)

**Triggers:**
- Weekly schedule (Mondays at 9 AM UTC)
- Manual trigger (`workflow_dispatch`)

**Jobs:**

#### Dependency Updates
- **Automated Updates**: Updates all Go dependencies to latest versions
- **Testing**: Ensures tests still pass with new dependencies
- **Pull Request**: Creates PR with changes if updates are available

#### Security Audit
- **Nancy**: Sonatype dependency vulnerability scanner
- **govulncheck**: Go vulnerability checker
- **Gosec**: Security scanning with SARIF output

#### License Check
- **go-licenses**: Validates dependency licenses
- **Report Generation**: Creates license summary

### 4. Nightly Tests Workflow (`.github/workflows/nightly.yml`)

**Triggers:**
- Daily schedule (2 AM UTC)
- Manual trigger (`workflow_dispatch`)

**Jobs:**

#### Latest Dependencies Test
- **Bleeding Edge**: Tests with latest available dependencies
- **Coverage**: Generates coverage reports

#### Go Version Matrix
- **Compatibility**: Tests across multiple Go versions (1.19-1.22)
- **Future Proofing**: Ensures compatibility with newer Go releases

#### Performance Benchmarks
- **Benchmark Tests**: Runs performance benchmarks
- **Trend Tracking**: Monitors performance over time
- **Alerts**: Notifies on significant performance regressions

#### Integration Tests
- **CLI Testing**: End-to-end CLI command testing
- **Smoke Tests**: Basic functionality verification

#### Failure Notification
- **Issue Creation**: Automatically creates GitHub issues on failure
- **Comment Updates**: Updates existing issues with new failures

## Dependabot Configuration (`.github/dependabot.yml`)

**Features:**
- **Go Modules**: Weekly dependency updates
- **GitHub Actions**: Weekly action version updates
- **Pull Request Limits**: Prevents overwhelming number of PRs
- **Auto-Assignment**: Assigns PRs to maintainers
- **Labeling**: Automatic categorization

## Required Secrets

### For Basic Workflows
- `GITHUB_TOKEN` - Automatically provided by GitHub

### For Enhanced Features (Optional)
- `CODECOV_TOKEN` - For code coverage reporting
- `COMMITTER_TOKEN` - For Homebrew formula updates

## Configuration Files

### `.golangci.yml`
Comprehensive linting configuration with:
- **Enabled Linters**: 30+ linters for code quality
- **Custom Rules**: Project-specific configurations
- **Test Exclusions**: Relaxed rules for test files
- **Performance Focus**: Optimized for Go best practices

### `.github/dependabot.yml`
Automated dependency management:
- **Schedule**: Weekly updates on Mondays
- **Limits**: Reasonable PR limits to avoid spam
- **Categorization**: Proper labeling and assignment

## Usage

### Running Tests Locally

```bash
# Run all tests
go test ./...

# Run tests with race detection
go test -race ./...

# Run tests with coverage
go test -coverprofile=coverage.out ./...

# Run linter
golangci-lint run

# Check formatting
gofmt -s -l .
```

### Creating a Release

1. **Tag the Release**:
   ```bash
   git tag -a v1.0.0 -m "Release version 1.0.0"
   git push origin v1.0.0
   ```

2. **Automatic Process**:
   - Tests run automatically
   - Binaries built for all platforms
   - GitHub release created
   - Assets uploaded

### Manual Workflow Triggers

All workflows support manual triggering via GitHub UI:
1. Go to **Actions** tab
2. Select desired workflow
3. Click **Run workflow**
4. Choose branch and click **Run workflow**

## Best Practices

### For Contributors
1. **Test Locally**: Run tests before pushing
2. **Format Code**: Use `gofmt` or IDE formatting
3. **Check Linting**: Run `golangci-lint` locally
4. **Update Dependencies**: Keep dependencies current

### For Maintainers
1. **Review PRs**: Check automated PR reviews
2. **Monitor Nightly**: Check nightly test results
3. **Security**: Review security scan results
4. **Releases**: Use semantic versioning for tags

## Troubleshooting

### Common Issues

1. **Test Failures**: Check for dependency conflicts or API changes
2. **Lint Errors**: Review `.golangci.yml` configuration
3. **Build Failures**: Verify Go version compatibility
4. **Security Alerts**: Review and update vulnerable dependencies

### Workflow Debugging

1. **Enable Debug Logging**: Add `ACTIONS_STEP_DEBUG=true` secret
2. **Check Logs**: Review workflow run logs in Actions tab
3. **Local Reproduction**: Run commands locally to reproduce issues

## Monitoring

### Key Metrics
- **Test Coverage**: Monitor via Codecov dashboard
- **Security**: Review GitHub Security tab
- **Performance**: Track benchmark trends
- **Dependencies**: Monitor Dependabot PRs

### Alerts
- **Nightly Failures**: Automatic issue creation
- **Security Vulnerabilities**: GitHub Security alerts
- **Performance Regressions**: Benchmark alerts
- **Dependency Updates**: Dependabot notifications

This comprehensive CI/CD setup ensures high code quality, security, and automated maintenance for the Hardcover CLI project.
</file>

<file path="cmd/book_test.go">
package cmd

import (
	"bytes"
	"context"
	"encoding/json"
	"net/http"
	"net/http/httptest"
	"testing"

	"github.com/spf13/cobra"
	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/require"

	"hardcover-cli/internal/config"
)

func TestBookGetCmd_Success(t *testing.T) {
	// Create test server
	server := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
		// Verify request
		assert.Equal(t, "POST", r.Method)
		assert.Equal(t, "Bearer test-api-key", r.Header.Get("Authorization"))

		// Verify GraphQL query
		var req map[string]interface{}
		err := json.NewDecoder(r.Body).Decode(&req)
		require.NoError(t, err)
		assert.Contains(t, req["query"], "query GetBook")
		assert.Contains(t, req["query"], "book")
		assert.Equal(t, float64(123), req["variables"].(map[string]interface{})["id"])

		// Send response
		response := map[string]interface{}{
			"data": map[string]interface{}{
				"books_by_pk": map[string]interface{}{
					"id":                  123,
					"title":               "The Go Programming Language",
					"description":         "A comprehensive guide to Go programming",
					"slug":                "go-programming-language",
					"isbn":                "978-0134190440",
					"publicationYear":     2015,
					"pageCount":           380,
					"cached_contributors": "Alan Donovan (author), Brian Kernighan (author), John Doe (editor)",
					"cached_genres": []map[string]interface{}{
						{
							"name": "Programming",
						},
						{
							"name": "Technology",
						},
						{
							"name": "Computer Science",
						},
					},
					"image":         "https://example.com/book-cover.jpg",
					"averageRating": 4.5,
					"ratingsCount":  123,
					"createdAt":     "2023-01-01T00:00:00Z",
					"updatedAt":     "2023-01-02T00:00:00Z",
				},
			},
		}
		w.Header().Set("Content-Type", "application/json")
		json.NewEncoder(w).Encode(response)
	}))
	defer server.Close()

	// Create command with test context
	cfg := &config.Config{
		APIKey:  "test-api-key",
		BaseURL: server.URL,
	}
	ctx := withConfig(context.Background(), cfg)

	cmd := &cobra.Command{}
	cmd.SetContext(ctx)

	// Capture output
	var output bytes.Buffer
	cmd.SetOut(&output)

	// Execute command
	err := bookGetCmd.RunE(cmd, []string{"123"})
	require.NoError(t, err)

	// Verify output
	outputStr := output.String()
	assert.Contains(t, outputStr, "Book Details:")
	assert.Contains(t, outputStr, "Title: The Go Programming Language")
	assert.Contains(t, outputStr, "ID: 123")
	assert.Contains(t, outputStr, "Description: A comprehensive guide to Go programming")
	assert.Contains(t, outputStr, "Contributors: Alan Donovan (author), Brian Kernighan (author), John Doe (editor)")
}

func TestBookGetCmd_MissingAPIKey(t *testing.T) {
	// Create command with empty API key
	cfg := &config.Config{
		APIKey:  "",
		BaseURL: "https://api.hardcover.app/v1/graphql",
	}
	ctx := withConfig(context.Background(), cfg)

	cmd := &cobra.Command{}
	cmd.SetContext(ctx)

	// Execute command
	err := bookGetCmd.RunE(cmd, []string{"123"})
	require.Error(t, err)
	assert.Contains(t, err.Error(), "API key is required")
}

func TestBookGetCmd_BookNotFound(t *testing.T) {
	// Create test server that returns null for book
	server := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
		response := map[string]interface{}{
			"data": map[string]interface{}{
				"books_by_pk": nil,
			},
		}
		w.Header().Set("Content-Type", "application/json")
		json.NewEncoder(w).Encode(response)
	}))
	defer server.Close()

	// Create command with test context
	cfg := &config.Config{
		APIKey:  "test-api-key",
		BaseURL: server.URL,
	}
	ctx := withConfig(context.Background(), cfg)

	cmd := &cobra.Command{}
	cmd.SetContext(ctx)

	// Capture output
	var output bytes.Buffer
	cmd.SetOut(&output)

	// Execute command
	err := bookGetCmd.RunE(cmd, []string{"999"})
	require.NoError(t, err)

	// Verify output handles null book gracefully
	outputStr := output.String()
	assert.Contains(t, outputStr, "Book Details:")
	assert.Contains(t, outputStr, "ID: 0")
}

func TestBookGetCmd_APIError(t *testing.T) {
	// Create test server that returns error
	server := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
		response := map[string]interface{}{
			"data": nil,
			"errors": []map[string]interface{}{
				{
					"message": "Book not found",
				},
			},
		}
		w.Header().Set("Content-Type", "application/json")
		json.NewEncoder(w).Encode(response)
	}))
	defer server.Close()

	// Create command with test context
	cfg := &config.Config{
		APIKey:  "test-api-key",
		BaseURL: server.URL,
	}
	ctx := withConfig(context.Background(), cfg)

	cmd := &cobra.Command{}
	cmd.SetContext(ctx)

	// Execute command
	err := bookGetCmd.RunE(cmd, []string{"123"})
	require.Error(t, err)
	assert.Contains(t, err.Error(), "failed to get book")
}

func TestBookGetCmd_MinimalData(t *testing.T) {
	// Create test server with minimal book data
	server := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
		response := map[string]interface{}{
			"data": map[string]interface{}{
				"books_by_pk": map[string]interface{}{
					"id":                  123,
					"title":               "Simple Book",
					"slug":                "simple-book",
					"cached_contributors": "",
					"cached_genres":       []map[string]interface{}{},
					"averageRating":       0,
					"ratingsCount":        0,
				},
			},
		}
		w.Header().Set("Content-Type", "application/json")
		json.NewEncoder(w).Encode(response)
	}))
	defer server.Close()

	// Create command with test context
	cfg := &config.Config{
		APIKey:  "test-api-key",
		BaseURL: server.URL,
	}
	ctx := withConfig(context.Background(), cfg)

	cmd := &cobra.Command{}
	cmd.SetContext(ctx)

	// Capture output
	var output bytes.Buffer
	cmd.SetOut(&output)

	// Execute command
	err := bookGetCmd.RunE(cmd, []string{"123"})
	require.NoError(t, err)

	// Verify output contains minimal information
	outputStr := output.String()
	assert.Contains(t, outputStr, "Title: Simple Book")
	assert.Contains(t, outputStr, "ID: 123")
	assert.NotContains(t, outputStr, "Description:")
	assert.NotContains(t, outputStr, "Contributors:")
	assert.NotContains(t, outputStr, "Publication Year:")
	assert.NotContains(t, outputStr, "Page Count:")
	assert.NotContains(t, outputStr, "ISBN:")
	assert.NotContains(t, outputStr, "Genres:")
	assert.NotContains(t, outputStr, "Average Rating:")
	assert.NotContains(t, outputStr, "Image:")
	assert.NotContains(t, outputStr, "Created:")
	assert.NotContains(t, outputStr, "Updated:")
}

func TestBookGetCmd_OnlyAuthors(t *testing.T) {
	// Create test server with book that has only authors, no other contributors
	server := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
		response := map[string]interface{}{
			"data": map[string]interface{}{
				"books_by_pk": map[string]interface{}{
					"id":                  123,
					"title":               "Authors Only Book",
					"slug":                "authors-only-book",
					"cached_contributors": "Author One (author), Author Two (Author), Author Three",
					"cached_genres":       []map[string]interface{}{},
				},
			},
		}
		w.Header().Set("Content-Type", "application/json")
		json.NewEncoder(w).Encode(response)
	}))
	defer server.Close()

	// Create command with test context
	cfg := &config.Config{
		APIKey:  "test-api-key",
		BaseURL: server.URL,
	}
	ctx := withConfig(context.Background(), cfg)

	cmd := &cobra.Command{}
	cmd.SetContext(ctx)

	// Capture output
	var output bytes.Buffer
	cmd.SetOut(&output)

	// Execute command
	err := bookGetCmd.RunE(cmd, []string{"123"})
	require.NoError(t, err)

	// Verify output shows authors but no contributors
	outputStr := output.String()
	assert.Contains(t, outputStr, "Contributors:")
	assert.Contains(t, outputStr, "Author One (author)")
	assert.Contains(t, outputStr, "Author Two (Author)")
	assert.Contains(t, outputStr, "Author Three")
}

func TestBookGetCmd_CommandProperties(t *testing.T) {
	// Test command properties
	assert.Equal(t, "get [book-id]", bookGetCmd.Use)
	assert.Equal(t, "Get detailed information about a specific book", bookGetCmd.Short)
	assert.NotEmpty(t, bookGetCmd.Long)
	assert.Contains(t, bookGetCmd.Long, "Retrieves and displays detailed information")
	assert.Contains(t, bookGetCmd.Long, "hardcover book get")
}

func TestBookGetCmd_RequiresArgument(t *testing.T) {
	// Test that the command requires exactly one argument
	cfg := &config.Config{
		APIKey:  "test-api-key",
		BaseURL: "https://api.hardcover.app/v1/graphql",
	}
	ctx := withConfig(context.Background(), cfg)

	cmd := &cobra.Command{}
	cmd.SetContext(ctx)

	// Test with no arguments - this should fail validation before reaching RunE
	err := bookGetCmd.Args(cmd, []string{})
	require.Error(t, err)

	// Test with too many arguments - this should fail validation before reaching RunE
	err = bookGetCmd.Args(cmd, []string{"arg1", "arg2"})
	require.Error(t, err)
}

func TestBookCmd_CommandProperties(t *testing.T) {
	// Test book command properties
	assert.Equal(t, "book", bookCmd.Use)
	assert.Equal(t, "Manage and retrieve book information", bookCmd.Short)
	assert.NotEmpty(t, bookCmd.Long)
	assert.Contains(t, bookCmd.Long, "get")
}

func TestBookCmd_Integration(t *testing.T) {
	// Setup commands for testing
	SetupCommands()

	// Test the command is properly registered
	found := false
	for _, cmd := range rootCmd.Commands() {
		if cmd.Use != "book" {
			continue
		}
		found = true
		// Check that get subcommand is registered
		getFound := false
		for _, subCmd := range cmd.Commands() {
			if subCmd.Use == "get [book-id]" {
				getFound = true
				break
			}
		}
		assert.True(t, getFound, "get subcommand should be registered")
		break
	}
	assert.True(t, found, "book command should be registered with root command")
}
</file>

<file path="cmd/context.go">
package cmd

import (
	"context"
	"fmt"

	"hardcover-cli/internal/config"
)

type contextKey string

const (
	configKey contextKey = "config"
)

// withConfig adds the configuration to the context
func withConfig(ctx context.Context, cfg *config.Config) context.Context {
	return context.WithValue(ctx, configKey, cfg)
}

// getConfig retrieves the configuration from the context
func getConfig(ctx context.Context) (*config.Config, bool) {
	cfg, ok := ctx.Value(configKey).(*config.Config)
	return cfg, ok
}

// printToStdoutf safely prints to stdout without checking errors (for CLI output)
func printToStdoutf(w interface{ Write([]byte) (int, error) }, format string, args ...interface{}) {
	_, _ = fmt.Fprintf(w, format, args...) //nolint:errcheck // CLI output errors are not critical
}
</file>

<file path="cmd/me.go">
package cmd

import (
	"context"
	"fmt"

	"github.com/spf13/cobra"

	"hardcover-cli/internal/client"
)

// meCmd represents the me command
var meCmd = &cobra.Command{
	Use:   "me",
	Short: "Get your user profile information",
	Long: `Fetches and displays the authenticated user's profile information including:
- User ID
- Username
- Email address
- Account creation date
- Last updated date

Example:
  hardcover me`,
	RunE: func(cmd *cobra.Command, args []string) error {
		cfg, ok := getConfig(cmd.Context())
		if !ok {
			return fmt.Errorf("failed to get configuration")
		}

		if cfg.APIKey == "" {
			return fmt.Errorf("API key is required. Set it using:\n" +
				"  export HARDCOVER_API_KEY=\"your-api-key\"\n" +
				"  or\n" +
				"  hardcover config set-api-key \"your-api-key\"")
		}

		client := client.NewClient(cfg.BaseURL, cfg.APIKey)

		response, err := client.GetCurrentUser(context.Background())
		if err != nil {
			return fmt.Errorf("failed to get user profile: %w", err)
		}

		// Display the user information using the generated types
		users := response.GetMe()
		if len(users) == 0 {
			return fmt.Errorf("no user profile found")
		}

		user := users[0] // Take the first user
		printToStdoutf(cmd.OutOrStdout(), "User Profile:\n")
		printToStdoutf(cmd.OutOrStdout(), "  ID: %d\n", user.GetId())
		printToStdoutf(cmd.OutOrStdout(), "  Username: %s\n", user.GetUsername())
		if user.GetEmail() != "" {
			printToStdoutf(cmd.OutOrStdout(), "  Email: %s\n", user.GetEmail())
		}
		if user.GetCreated_at() != "" {
			printToStdoutf(cmd.OutOrStdout(), "  Created: %s\n", user.GetCreated_at())
		}
		if user.GetUpdated_at() != "" {
			printToStdoutf(cmd.OutOrStdout(), "  Updated: %s\n", user.GetUpdated_at())
		}

		return nil
	},
}

// setupMeCommands registers the me command with the root command
func setupMeCommands() {
	rootCmd.AddCommand(meCmd)
}
</file>

<file path="cmd/root.go">
package cmd

import (
	"context"
	"fmt"
	"os"

	"github.com/spf13/cobra"

	"hardcover-cli/internal/config"
)

var cfgFile string

// rootCmd represents the base command when called without any subcommands
var rootCmd = &cobra.Command{
	Use:   "hardcover",
	Short: "A CLI tool for interacting with the Hardcover.app GraphQL API",
	Long: `Hardcover CLI is a command-line interface for interacting with the Hardcover.app GraphQL API.
It allows you to search for books, get book details, and manage your profile.

Before using the CLI, you need to set your Hardcover.app API key:

  # Set via environment variable
  export HARDCOVER_API_KEY="your-api-key-here"
  
  # Or set via config file
  hardcover config set-api-key "your-api-key-here"

Examples:
  hardcover me                           # Get your user profile
  hardcover search books "golang"        # Search for books about golang
  hardcover book get 12345               # Get details for book with ID 12345`,
}

// SetupCommands initializes all commands and their relationships
func SetupCommands() {
	setupRootCommand()
	setupMeCommands()
	setupSearchCommands()
	setupBookCommands()
	setupConfigCommands()
	setupSchemaCommands()
}

// Execute adds all child commands to the root command and sets flags appropriately.
// This is called by main.main(). It only needs to happen once to the rootCmd.
func Execute() {
	// Load configuration and set context before executing
	cfg, err := config.LoadConfig()
	if err != nil {
		fmt.Fprintf(os.Stderr, "Warning: failed to load config: %v\n", err)
		// Continue with default config
		cfg = config.DefaultConfig()
	}

	// Override with command-line flag if provided
	if apiKey, flagErr := rootCmd.PersistentFlags().GetString("api-key"); flagErr == nil && apiKey != "" {
		cfg.APIKey = apiKey
	}

	// Set context on root command with a proper context
	ctx := withConfig(context.Background(), cfg)
	rootCmd.SetContext(ctx)

	err = rootCmd.Execute()
	if err != nil {
		os.Exit(1)
	}
}

// setupRootCommand configures the root command with flags and initialization
func setupRootCommand() {
	cobra.OnInitialize(initConfig)

	// Check if flags are already added to prevent re-registration
	if rootCmd.PersistentFlags().Lookup("config") == nil {
		rootCmd.PersistentFlags().StringVar(&cfgFile, "config", "", "config file (default is $HOME/.hardcover/config.yaml)")
	}

	if rootCmd.PersistentFlags().Lookup("api-key") == nil {
		rootCmd.PersistentFlags().StringP("api-key", "k", "",
			"Hardcover.app API key (can also be set via HARDCOVER_API_KEY environment variable)")
	}

	// Cobra also supports local flags, which will only run
	// when this action is called directly.
	if rootCmd.Flags().Lookup("toggle") == nil {
		rootCmd.Flags().BoolP("toggle", "t", false, "Help message for toggle")
	}
}

// initConfig reads in config file and ENV variables if set.
func initConfig() {
	cfg, err := config.LoadConfig()
	if err != nil {
		fmt.Fprintf(os.Stderr, "Warning: failed to load config: %v\n", err)
		return
	}

	// Override with command-line flag if provided
	if apiKey, err := rootCmd.PersistentFlags().GetString("api-key"); err == nil && apiKey != "" {
		cfg.APIKey = apiKey
	}

	// Store config in a way that subcommands can access it
	rootCmd.SetContext(withConfig(rootCmd.Context(), cfg))
}
</file>

<file path="cmd/search_test.go">
package cmd

import (
	"bytes"
	"context"
	"encoding/json"
	"net/http"
	"net/http/httptest"
	"testing"

	"github.com/spf13/cobra"
	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/require"

	"hardcover-cli/internal/config"
)

func TestSearchBooksCmd_Success(t *testing.T) {
	// Create test server
	server := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
		// Verify request
		assert.Equal(t, "POST", r.Method)
		assert.Equal(t, "Bearer test-api-key", r.Header.Get("Authorization"))

		// Verify GraphQL query
		var req map[string]interface{}
		err := json.NewDecoder(r.Body).Decode(&req)
		require.NoError(t, err)
		assert.Contains(t, req["query"], "query SearchBooks")
		assert.Contains(t, req["query"], "search")
		variables := req["variables"].(map[string]interface{})
		assert.Equal(t, "golang", variables["query"])

		// Send response
		response := map[string]interface{}{
			"data": map[string]interface{}{
				"search": map[string]interface{}{
					"error":      "",
					"ids":        []int{1, 2},
					"page":       1,
					"per_page":   10,
					"query":      "golang",
					"query_type": "Book",
					"results":    "[]",
				},
			},
		}
		w.Header().Set("Content-Type", "application/json")
		json.NewEncoder(w).Encode(response)
	}))
	defer server.Close()

	// Create command with test context
	cfg := &config.Config{
		APIKey:  "test-api-key",
		BaseURL: server.URL,
	}
	ctx := withConfig(context.Background(), cfg)

	cmd := &cobra.Command{}
	cmd.SetContext(ctx)

	// Capture output
	var output bytes.Buffer
	cmd.SetOut(&output)

	// Execute command
	err := searchBooksCmd.RunE(cmd, []string{"golang"})
	require.NoError(t, err)

	// Verify output
	outputStr := output.String()
	assert.Contains(t, outputStr, "Search Results:")
	assert.Contains(t, outputStr, "Query: golang")
	assert.Contains(t, outputStr, "Query Type: Book")
}

func TestSearchBooksCmd_MissingAPIKey(t *testing.T) {
	// Create command with empty API key
	cfg := &config.Config{
		APIKey:  "",
		BaseURL: "https://api.hardcover.app/v1/graphql",
	}
	ctx := withConfig(context.Background(), cfg)

	cmd := &cobra.Command{}
	cmd.SetContext(ctx)

	// Execute command
	err := searchBooksCmd.RunE(cmd, []string{"golang"})
	require.Error(t, err)
	assert.Contains(t, err.Error(), "API key is required")
}

func TestSearchBooksCmd_NoResults(t *testing.T) {
	// Create test server that returns no results
	server := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
		response := map[string]interface{}{
			"data": map[string]interface{}{
				"search": map[string]interface{}{
					"error":      "",
					"ids":        []int{},
					"page":       1,
					"per_page":   10,
					"query":      "nonexistent",
					"query_type": "Book",
					"results":    "[]",
				},
			},
		}
		w.Header().Set("Content-Type", "application/json")
		json.NewEncoder(w).Encode(response)
	}))
	defer server.Close()

	// Create command with test context
	cfg := &config.Config{
		APIKey:  "test-api-key",
		BaseURL: server.URL,
	}
	ctx := withConfig(context.Background(), cfg)

	cmd := &cobra.Command{}
	cmd.SetContext(ctx)

	// Capture output
	var output bytes.Buffer
	cmd.SetOut(&output)

	// Execute command
	err := searchBooksCmd.RunE(cmd, []string{"nonexistent"})
	require.NoError(t, err)

	// Verify output
	outputStr := output.String()
	assert.Contains(t, outputStr, "Search Results:")
	assert.Contains(t, outputStr, "Query: nonexistent")
}

func TestSearchBooksCmd_APIError(t *testing.T) {
	// Create test server that returns error
	server := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
		response := map[string]interface{}{
			"data": nil,
			"errors": []map[string]interface{}{
				{
					"message": "Search failed",
				},
			},
		}
		w.Header().Set("Content-Type", "application/json")
		json.NewEncoder(w).Encode(response)
	}))
	defer server.Close()

	// Create command with test context
	cfg := &config.Config{
		APIKey:  "test-api-key",
		BaseURL: server.URL,
	}
	ctx := withConfig(context.Background(), cfg)

	cmd := &cobra.Command{}
	cmd.SetContext(ctx)

	// Execute command
	err := searchBooksCmd.RunE(cmd, []string{"golang"})
	require.Error(t, err)
	assert.Contains(t, err.Error(), "failed to search books")
}

func TestSearchBooksCmd_MinimalData(t *testing.T) {
	// Create test server with minimal book data
	server := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
		response := map[string]interface{}{
			"data": map[string]interface{}{
				"search": map[string]interface{}{
					"error":      "",
					"ids":        []int{1},
					"page":       1,
					"per_page":   10,
					"query":      "simple",
					"query_type": "Book",
					"results":    "[]",
				},
			},
		}
		w.Header().Set("Content-Type", "application/json")
		json.NewEncoder(w).Encode(response)
	}))
	defer server.Close()

	// Create command with test context
	cfg := &config.Config{
		APIKey:  "test-api-key",
		BaseURL: server.URL,
	}
	ctx := withConfig(context.Background(), cfg)

	cmd := &cobra.Command{}
	cmd.SetContext(ctx)

	// Capture output
	var output bytes.Buffer
	cmd.SetOut(&output)

	// Execute command
	err := searchBooksCmd.RunE(cmd, []string{"simple"})
	require.NoError(t, err)

	// Verify output contains minimal information
	outputStr := output.String()
	assert.Contains(t, outputStr, "Search Results:")
	assert.Contains(t, outputStr, "Query: simple")
}

func TestSearchBooksCmd_CommandProperties(t *testing.T) {
	// Test command properties
	assert.Equal(t, "books [query]", searchBooksCmd.Use)
	assert.Equal(t, "Search for books", searchBooksCmd.Short)
	assert.NotEmpty(t, searchBooksCmd.Long)
	assert.Contains(t, searchBooksCmd.Long, "hardcover search books")
}

func TestSearchBooksCmd_RequiresArgument(t *testing.T) {
	// Test that the command requires exactly one argument
	cmd := &cobra.Command{}

	// Test with no arguments - this should fail validation before reaching RunE
	err := searchBooksCmd.Args(cmd, []string{})
	require.Error(t, err)

	// Test with too many arguments - this should fail validation before reaching RunE
	err = searchBooksCmd.Args(cmd, []string{"arg1", "arg2"})
	require.Error(t, err)
}

func TestSearchCmd_CommandProperties(t *testing.T) {
	// Test search command properties
	assert.Equal(t, "search", searchCmd.Use)
	assert.Equal(t, "Search for content on Hardcover.app", searchCmd.Short)
	assert.NotEmpty(t, searchCmd.Long)
	assert.Contains(t, searchCmd.Long, "books")
}

func TestSearchCmd_Integration(t *testing.T) {
	// Setup commands for testing
	SetupCommands()

	// Test the command is properly registered
	found := false
	for _, cmd := range rootCmd.Commands() {
		if cmd.Use != "search" {
			continue
		}
		found = true
		// Check that books subcommand is registered
		booksFound := false
		for _, subCmd := range cmd.Commands() {
			if subCmd.Use == "books [query]" {
				booksFound = true
				break
			}
		}
		assert.True(t, booksFound, "books subcommand should be registered")
		break
	}
	assert.True(t, found, "search command should be registered with root command")
}
</file>

<file path="cmd/search.go">
package cmd

import (
	"context"
	"fmt"

	"github.com/spf13/cobra"

	"hardcover-cli/internal/client"
)

const (
	defaultPerPage = 10
)

// searchCmd represents the search command
var searchCmd = &cobra.Command{
	Use:   "search",
	Short: "Search for content on Hardcover.app",
	Long: `Search for various types of content on Hardcover.app including books, authors, and users.
	
Available subcommands:
  books    Search for books by title, author, or other criteria`,
}

// searchBooksCmd represents the search books command
var searchBooksCmd = &cobra.Command{
	Use:   "books [query]",
	Short: "Search for books",
	Long: `Search for books on Hardcover.app.
	
The search will return search results with:
- Error information if any
- Book IDs found
- Pagination information
- Query details

Example:
  hardcover search books "lord of the rings"
  hardcover search books "harry potter" --query-type "Book" --per-page 5`,
	Args: cobra.ExactArgs(1),
	RunE: func(cmd *cobra.Command, args []string) error {
		cfg, ok := getConfig(cmd.Context())
		if !ok {
			return fmt.Errorf("failed to get configuration")
		}

		if cfg.APIKey == "" {
			return fmt.Errorf("API key is required. Set it using:\n" +
				"  export HARDCOVER_API_KEY=\"your-api-key\"\n" +
				"  or\n" +
				"  hardcover config set-api-key \"your-api-key\"")
		}

		// Get search parameters
		query := args[0]
		queryType, err := cmd.Flags().GetString("query-type")
		if err != nil {
			return fmt.Errorf("failed to get query-type flag: %w", err)
		}
		perPage, err := cmd.Flags().GetInt("per-page")
		if err != nil {
			return fmt.Errorf("failed to get per-page flag: %w", err)
		}
		page, err := cmd.Flags().GetInt("page")
		if err != nil {
			return fmt.Errorf("failed to get page flag: %w", err)
		}

		// Set defaults
		if queryType == "" {
			queryType = "Book"
		}
		if perPage == 0 {
			perPage = 10
		}
		if page == 0 {
			page = 1
		}

		client := client.NewClient(cfg.BaseURL, cfg.APIKey)

		response, err := client.SearchBooks(context.Background(), query, queryType, perPage, page)
		if err != nil {
			return fmt.Errorf("failed to search books: %w", err)
		}

		// Display search results
		searchResults := response.GetSearch()

		printToStdoutf(cmd.OutOrStdout(), "Search Results:\n")

		if searchResults.GetError() != "" {
			printToStdoutf(cmd.OutOrStdout(), "  Error: %s\n", searchResults.GetError())
		}

		if searchResults.GetQuery() != "" {
			printToStdoutf(cmd.OutOrStdout(), "  Query: %s\n", searchResults.GetQuery())
		}

		if searchResults.GetQuery_type() != "" {
			printToStdoutf(cmd.OutOrStdout(), "  Query Type: %s\n", searchResults.GetQuery_type())
		}

		if searchResults.GetPage() > 0 {
			printToStdoutf(cmd.OutOrStdout(), "  Page: %d\n", searchResults.GetPage())
		}

		if searchResults.GetPer_page() > 0 {
			printToStdoutf(cmd.OutOrStdout(), "  Per Page: %d\n", searchResults.GetPer_page())
		}

		ids := searchResults.GetIds()
		if len(ids) > 0 {
			printToStdoutf(cmd.OutOrStdout(), "  Book IDs found: %v\n", ids)
		} else {
			printToStdoutf(cmd.OutOrStdout(), "  No book IDs found\n")
		}

		if searchResults.GetResults() != "" {
			printToStdoutf(cmd.OutOrStdout(), "  Results: %s\n", searchResults.GetResults())
		}

		return nil
	},
}

// setupSearchCommands registers the search commands with the root command
func setupSearchCommands() {
	// Check if flags are already added to prevent re-registration
	if searchBooksCmd.Flags().Lookup("query-type") == nil {
		// Add flags to searchBooksCmd
		searchBooksCmd.Flags().String("query-type", "Book",
			"Type of content to search for (Book, Author, Character, List, Prompt, Publisher, Series, User)")
		searchBooksCmd.Flags().Int("per-page", defaultPerPage, "Number of results per page")
		searchBooksCmd.Flags().Int("page", 1, "Page number to return")
	}

	// Check if command is already added to prevent re-registration
	searchAdded := false
	for _, cmd := range searchCmd.Commands() {
		if cmd.Use == searchBooksCmd.Use {
			searchAdded = true
			break
		}
	}
	if !searchAdded {
		searchCmd.AddCommand(searchBooksCmd)
	}

	rootAdded := false
	for _, cmd := range rootCmd.Commands() {
		if cmd.Use == searchCmd.Use {
			rootAdded = true
			break
		}
	}
	if !rootAdded {
		rootCmd.AddCommand(searchCmd)
	}
}
</file>

<file path="internal/client/client.go">
package client

import (
	"context"
	"net/http"
	"time"

	"github.com/Khan/genqlient/graphql"
)

const (
	// DefaultTimeout is the default HTTP client timeout
	DefaultTimeout = 30 * time.Second
)

// HardcoverClient defines the interface for interacting with Hardcover API
type HardcoverClient interface {
	GetCurrentUser(ctx context.Context) (*GetCurrentUserResponse, error)
	GetBooks(ctx context.Context) (*GetBooksResponse, error)
	GetBook(ctx context.Context, id int) (*GetBookResponse, error)
	SearchBooks(ctx context.Context, query string, queryType string, perPage int, page int) (*SearchBooksResponse, error)
}

// Client represents a GraphQL client that uses genqlient
type Client struct {
	graphqlClient graphql.Client
}

// NewClient creates a new GraphQL client using genqlient
func NewClient(endpoint, apiKey string) HardcoverClient {
	httpClient := &http.Client{
		Timeout: DefaultTimeout,
	}

	// Create a graphql client with auth headers
	graphqlClient := graphql.NewClient(endpoint, &authedTransport{
		wrapped: httpClient,
		apiKey:  apiKey,
	})

	return &Client{
		graphqlClient: graphqlClient,
	}
}

// authedTransport wraps an HTTP client to add authorization headers
type authedTransport struct {
	wrapped *http.Client
	apiKey  string
}

// Do implements the graphql.Doer interface
func (t *authedTransport) Do(req *http.Request) (*http.Response, error) {
	req.Header.Set("Content-Type", "application/json")
	req.Header.Set("User-Agent", "hardcover-cli/1.0.0")
	if t.apiKey != "" {
		req.Header.Set("Authorization", "Bearer "+t.apiKey)
	}
	return t.wrapped.Do(req)
}

// GetCurrentUser gets the current user profile using genqlient
func (c *Client) GetCurrentUser(ctx context.Context) (*GetCurrentUserResponse, error) {
	return GetCurrentUser(ctx, c.graphqlClient)
}

// GetBooks gets all books using genqlient
func (c *Client) GetBooks(ctx context.Context) (*GetBooksResponse, error) {
	return GetBooks(ctx, c.graphqlClient)
}

// GetBook gets a specific book by ID using genqlient
func (c *Client) GetBook(ctx context.Context, id int) (*GetBookResponse, error) {
	return GetBook(ctx, c.graphqlClient, id)
}

// SearchBooks searches for books using genqlient
func (c *Client) SearchBooks(ctx context.Context, query, queryType string, perPage, page int) (
	*SearchBooksResponse, error) {
	return SearchBooks(ctx, c.graphqlClient, query, queryType, perPage, page)
}
</file>

<file path="internal/config/config_test.go">
package config

import (
	"os"
	"path/filepath"
	"testing"

	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/require"
)

const (
	testAPIKeyFromEnv    = "test-api-key-from-env"
	testAPIKeyFromFile   = "test-api-key-from-file"
	defaultConfigContent = `api_key: test-api-key-from-file
base_url: https://api.hardcover.app/v1/graphql`
)

func TestDefaultConfig(t *testing.T) {
	cfg := DefaultConfig()
	assert.NotNil(t, cfg)
	assert.Equal(t, "https://api.hardcover.app/v1/graphql", cfg.BaseURL)
	assert.Empty(t, cfg.APIKey)
}

func TestLoadConfig_FromEnvironment(t *testing.T) {
	// Set environment variable
	os.Setenv("HARDCOVER_API_KEY", testAPIKeyFromEnv)
	defer os.Unsetenv("HARDCOVER_API_KEY")

	cfg, err := LoadConfig()
	require.NoError(t, err)
	assert.Equal(t, testAPIKeyFromEnv, cfg.APIKey)
	assert.Equal(t, "https://api.hardcover.app/v1/graphql", cfg.BaseURL)
}

func TestLoadConfig_FromFile(t *testing.T) {
	// Create temporary directory for config
	tempDir := t.TempDir()
	configDir := filepath.Join(tempDir, ".hardcover")
	configPath := filepath.Join(configDir, "config.yaml")

	// Create config directory
	err := os.MkdirAll(configDir, 0o755)
	require.NoError(t, err)

	// Create config file
	err = os.WriteFile(configPath, []byte(defaultConfigContent), 0o600)
	require.NoError(t, err)

	// Mock the home directory for testing
	oldHome := os.Getenv("HOME")
	os.Setenv("HOME", tempDir)
	defer os.Setenv("HOME", oldHome)

	cfg, err := LoadConfig()
	require.NoError(t, err)
	assert.Equal(t, testAPIKeyFromFile, cfg.APIKey)
	assert.Equal(t, "https://api.hardcover.app/v1/graphql", cfg.BaseURL)
}

func TestLoadConfig_NoFileExists(t *testing.T) {
	// Make sure no environment variable is set
	os.Unsetenv("HARDCOVER_API_KEY")

	// Create temporary directory for config
	tempDir := t.TempDir()

	// Mock the home directory for testing
	oldHome := os.Getenv("HOME")
	os.Setenv("HOME", tempDir)
	defer os.Setenv("HOME", oldHome)

	cfg, err := LoadConfig()
	require.NoError(t, err)
	assert.Empty(t, cfg.APIKey)
	assert.Equal(t, "https://api.hardcover.app/v1/graphql", cfg.BaseURL)
}

func TestSaveConfig(t *testing.T) {
	// Create temporary directory for config
	tempDir := t.TempDir()

	// Mock the home directory for testing
	oldHome := os.Getenv("HOME")
	os.Setenv("HOME", tempDir)
	defer os.Setenv("HOME", oldHome)

	cfg := &Config{
		APIKey:  "test-api-key",
		BaseURL: "https://api.hardcover.app/v1/graphql",
	}

	err := SaveConfig(cfg)
	require.NoError(t, err)

	// Verify file was created
	configPath := filepath.Join(tempDir, ".hardcover", "config.yaml")
	_, err = os.Stat(configPath)
	require.NoError(t, err)

	// Load the config back and verify
	loadedCfg, err := LoadConfig()
	require.NoError(t, err)
	assert.Equal(t, cfg.APIKey, loadedCfg.APIKey)
	assert.Equal(t, cfg.BaseURL, loadedCfg.BaseURL)
}

func TestGetConfigPath(t *testing.T) {
	// Create temporary directory for config
	tempDir := t.TempDir()

	// Mock the home directory for testing
	oldHome := os.Getenv("HOME")
	os.Setenv("HOME", tempDir)
	defer os.Setenv("HOME", oldHome)

	configPath, err := GetConfigPath()
	require.NoError(t, err)

	expectedPath := filepath.Join(tempDir, ".hardcover", "config.yaml")
	assert.Equal(t, expectedPath, configPath)
}

func TestLoadConfig_EnvironmentOverridesFile(t *testing.T) {
	// Create temporary directory for config
	tempDir := t.TempDir()
	configDir := filepath.Join(tempDir, ".hardcover")
	configPath := filepath.Join(configDir, "config.yaml")

	// Create config directory
	err := os.MkdirAll(configDir, 0o755)
	require.NoError(t, err)

	// Create config file with one API key
	configContent := `api_key: file-api-key
base_url: https://api.hardcover.app/v1/graphql`
	err = os.WriteFile(configPath, []byte(configContent), 0o600)
	require.NoError(t, err)

	// Set environment variable with different API key
	envAPIKey := "env-api-key"
	os.Setenv("HARDCOVER_API_KEY", envAPIKey)
	defer os.Unsetenv("HARDCOVER_API_KEY")

	// Mock the home directory for testing
	oldHome := os.Getenv("HOME")
	os.Setenv("HOME", tempDir)
	defer os.Setenv("HOME", oldHome)

	cfg, err := LoadConfig()
	require.NoError(t, err)

	// Environment variable should override file
	assert.Equal(t, envAPIKey, cfg.APIKey)
}

func TestLoadConfig_InvalidYAML(t *testing.T) {
	// Create temporary directory for config
	tempDir := t.TempDir()
	configDir := filepath.Join(tempDir, ".hardcover")
	configPath := filepath.Join(configDir, "config.yaml")

	// Create config directory
	err := os.MkdirAll(configDir, 0o755)
	require.NoError(t, err)

	// Create config file with invalid YAML
	configContent := `api_key: test-api-key
base_url: https://api.hardcover.app/v1/graphql
invalid_yaml: [unclosed bracket`
	err = os.WriteFile(configPath, []byte(configContent), 0o600)
	require.NoError(t, err)

	// Mock the home directory for testing
	oldHome := os.Getenv("HOME")
	os.Setenv("HOME", tempDir)
	defer os.Setenv("HOME", oldHome)

	_, err = LoadConfig()
	assert.Error(t, err)
	assert.Contains(t, err.Error(), "failed to parse config file")
}

// TestLoadConfig_EmptyEnvironmentVariable tests the specific fix for the issue
// where an empty environment variable was preventing config file loading
func TestLoadConfig_EmptyEnvironmentVariable(t *testing.T) {
	// Create temporary directory for config
	tempDir := t.TempDir()
	configDir := filepath.Join(tempDir, ".hardcover")
	configPath := filepath.Join(configDir, "config.yaml")

	// Create config directory
	err := os.MkdirAll(configDir, 0o755)
	require.NoError(t, err)

	// Create config file with API key
	err = os.WriteFile(configPath, []byte(defaultConfigContent), 0o600)
	require.NoError(t, err)

	// Set empty environment variable (this was the bug)
	os.Setenv("HARDCOVER_API_KEY", "")
	defer os.Unsetenv("HARDCOVER_API_KEY")

	// Mock the home directory for testing
	oldHome := os.Getenv("HOME")
	os.Setenv("HOME", tempDir)
	defer os.Setenv("HOME", oldHome)

	cfg, err := LoadConfig()
	require.NoError(t, err)

	// Should load from config file even with empty environment variable
	assert.Equal(t, testAPIKeyFromFile, cfg.APIKey)
	assert.Equal(t, "https://api.hardcover.app/v1/graphql", cfg.BaseURL)
}

// TestLoadConfig_WhitespaceEnvironmentVariable tests that whitespace-only environment variables are treated as empty
func TestLoadConfig_WhitespaceEnvironmentVariable(t *testing.T) {
	// Create temporary directory for config
	tempDir := t.TempDir()
	configDir := filepath.Join(tempDir, ".hardcover")
	configPath := filepath.Join(configDir, "config.yaml")

	// Create config directory
	err := os.MkdirAll(configDir, 0o755)
	require.NoError(t, err)

	// Create config file with API key
	err = os.WriteFile(configPath, []byte(defaultConfigContent), 0o600)
	require.NoError(t, err)

	// Set whitespace-only environment variable
	os.Setenv("HARDCOVER_API_KEY", "   ")
	defer os.Unsetenv("HARDCOVER_API_KEY")

	// Mock the home directory for testing
	oldHome := os.Getenv("HOME")
	os.Setenv("HOME", tempDir)
	defer os.Setenv("HOME", oldHome)

	cfg, err := LoadConfig()
	require.NoError(t, err)

	// Should load from config file even with whitespace-only environment variable
	assert.Equal(t, testAPIKeyFromFile, cfg.APIKey)
	assert.Equal(t, "https://api.hardcover.app/v1/graphql", cfg.BaseURL)
}

// TestLoadConfig_EnvironmentVariableOverridesFile tests that non-empty environment variables
// properly override config file
func TestLoadConfig_EnvironmentVariableOverridesFile(t *testing.T) {
	// Create temporary directory for config
	tempDir := t.TempDir()
	configDir := filepath.Join(tempDir, ".hardcover")
	configPath := filepath.Join(configDir, "config.yaml")

	// Create config directory
	err := os.MkdirAll(configDir, 0o755)
	require.NoError(t, err)

	// Create config file with API key
	err = os.WriteFile(configPath, []byte(defaultConfigContent), 0o600)
	require.NoError(t, err)

	// Set non-empty environment variable
	envAPIKey := testAPIKeyFromEnv
	os.Setenv("HARDCOVER_API_KEY", envAPIKey)
	defer os.Unsetenv("HARDCOVER_API_KEY")

	// Mock the home directory for testing
	oldHome := os.Getenv("HOME")
	os.Setenv("HOME", tempDir)
	defer os.Setenv("HOME", oldHome)

	cfg, err := LoadConfig()
	require.NoError(t, err)

	// Environment variable should override config file
	assert.Equal(t, envAPIKey, cfg.APIKey)
	assert.Equal(t, "https://api.hardcover.app/v1/graphql", cfg.BaseURL)
}

// TestLoadConfig_NoEnvironmentVariableNoFile tests the default behavior when neither env var nor file exists
func TestLoadConfig_NoEnvironmentVariableNoFile(t *testing.T) {
	// Make sure no environment variable is set
	os.Unsetenv("HARDCOVER_API_KEY")

	// Create temporary directory for config
	tempDir := t.TempDir()

	// Mock the home directory for testing
	oldHome := os.Getenv("HOME")
	os.Setenv("HOME", tempDir)
	defer os.Setenv("HOME", oldHome)

	cfg, err := LoadConfig()
	require.NoError(t, err)

	// Should return default config with empty API key
	assert.Empty(t, cfg.APIKey)
	assert.Equal(t, "https://api.hardcover.app/v1/graphql", cfg.BaseURL)
}

// TestLoadConfig_ConfigFileOnly tests loading from config file when no environment variable is set
func TestLoadConfig_ConfigFileOnly(t *testing.T) {
	// Make sure no environment variable is set
	os.Unsetenv("HARDCOVER_API_KEY")

	// Create temporary directory for config
	tempDir := t.TempDir()
	configDir := filepath.Join(tempDir, ".hardcover")
	configPath := filepath.Join(configDir, "config.yaml")

	// Create config directory
	err := os.MkdirAll(configDir, 0o755)
	require.NoError(t, err)

	// Create config file with API key
	err = os.WriteFile(configPath, []byte(defaultConfigContent), 0o600)
	require.NoError(t, err)

	// Mock the home directory for testing
	oldHome := os.Getenv("HOME")
	os.Setenv("HOME", tempDir)
	defer os.Setenv("HOME", oldHome)

	cfg, err := LoadConfig()
	require.NoError(t, err)

	// Should load from config file
	assert.Equal(t, testAPIKeyFromFile, cfg.APIKey)
	assert.Equal(t, "https://api.hardcover.app/v1/graphql", cfg.BaseURL)
}

// TestLoadConfig_EnvironmentVariableOnly tests loading from environment variable when no config file exists
func TestLoadConfig_EnvironmentVariableOnly(t *testing.T) {
	// Set environment variable
	expectedAPIKey := testAPIKeyFromEnv
	os.Setenv("HARDCOVER_API_KEY", expectedAPIKey)
	defer os.Unsetenv("HARDCOVER_API_KEY")

	// Create temporary directory for config (but don't create config file)
	tempDir := t.TempDir()

	// Mock the home directory for testing
	oldHome := os.Getenv("HOME")
	os.Setenv("HOME", tempDir)
	defer os.Setenv("HOME", oldHome)

	cfg, err := LoadConfig()
	require.NoError(t, err)

	// Should load from environment variable
	assert.Equal(t, expectedAPIKey, cfg.APIKey)
	assert.Equal(t, "https://api.hardcover.app/v1/graphql", cfg.BaseURL)
}

// TestLoadConfig_ConfigFileWithCustomBaseURL tests that custom base URL from config file is preserved
func TestLoadConfig_ConfigFileWithCustomBaseURL(t *testing.T) {
	// Make sure no environment variable is set
	os.Unsetenv("HARDCOVER_API_KEY")

	// Create temporary directory for config
	tempDir := t.TempDir()
	configDir := filepath.Join(tempDir, ".hardcover")
	configPath := filepath.Join(configDir, "config.yaml")

	// Create config directory
	err := os.MkdirAll(configDir, 0o755)
	require.NoError(t, err)

	// Create config file with custom base URL
	configContent := `api_key: test-api-key
base_url: https://custom-api.example.com/graphql`
	err = os.WriteFile(configPath, []byte(configContent), 0o600)
	require.NoError(t, err)

	// Mock the home directory for testing
	oldHome := os.Getenv("HOME")
	os.Setenv("HOME", tempDir)
	defer os.Setenv("HOME", oldHome)

	cfg, err := LoadConfig()
	require.NoError(t, err)

	// Should preserve custom base URL from config file
	assert.Equal(t, "test-api-key", cfg.APIKey)
	assert.Equal(t, "https://custom-api.example.com/graphql", cfg.BaseURL)
}

// TestLoadConfig_EnvironmentVariablePreservesBaseURL tests that environment variable doesn't affect base URL
func TestLoadConfig_EnvironmentVariablePreservesBaseURL(t *testing.T) {
	// Create temporary directory for config
	tempDir := t.TempDir()
	configDir := filepath.Join(tempDir, ".hardcover")
	configPath := filepath.Join(configDir, "config.yaml")

	// Create config directory
	err := os.MkdirAll(configDir, 0o755)
	require.NoError(t, err)

	// Create config file with custom base URL
	configContent := `api_key: file-api-key
base_url: https://custom-api.example.com/graphql`
	err = os.WriteFile(configPath, []byte(configContent), 0o600)
	require.NoError(t, err)

	// Set environment variable
	envAPIKey := "env-api-key"
	os.Setenv("HARDCOVER_API_KEY", envAPIKey)
	defer os.Unsetenv("HARDCOVER_API_KEY")

	// Mock the home directory for testing
	oldHome := os.Getenv("HOME")
	os.Setenv("HOME", tempDir)
	defer os.Setenv("HOME", oldHome)

	cfg, err := LoadConfig()
	require.NoError(t, err)

	// Environment variable should override API key but preserve base URL
	assert.Equal(t, envAPIKey, cfg.APIKey)
	assert.Equal(t, "https://custom-api.example.com/graphql", cfg.BaseURL)
}
</file>

<file path=".gitignore">
# If you prefer the allow list template instead of the deny list, see community template:
# https://github.com/github/gitignore/blob/main/community/Golang/Go.AllowList.gitignore
#
# Binaries for programs and plugins
*.exe
*.exe~
*.dll
*.so
*.dylib

# Build output directory
bin/

# Test binary, built with `go test -c`
*.test

# Code coverage profiles and other test artifacts
*.out
coverage.*
*.coverprofile
profile.cov

# Dependency directories (remove the comment below to include it)
# vendor/

# Go workspace file
go.work
go.work.sum

# env file
.env

# Editor/IDE
# .idea/
# .vscode/

# Build artifacts
bin/
hardcover
hardcover-cli
repomix-output.xml
</file>

<file path="go.mod">
module hardcover-cli

go 1.23

require (
	github.com/Khan/genqlient v0.8.1
	github.com/spf13/cobra v1.9.1
	github.com/stretchr/testify v1.10.0
	gopkg.in/yaml.v3 v3.0.1
)

require (
	github.com/agnivade/levenshtein v1.1.1 // indirect
	github.com/alexflint/go-arg v1.5.1 // indirect
	github.com/alexflint/go-scalar v1.2.0 // indirect
	github.com/bmatcuk/doublestar/v4 v4.6.1 // indirect
	github.com/davecgh/go-spew v1.1.1 // indirect
	github.com/google/uuid v1.6.0 // indirect
	github.com/inconshreveable/mousetrap v1.1.0 // indirect
	github.com/pmezard/go-difflib v1.0.0 // indirect
	github.com/spf13/pflag v1.0.6 // indirect
	github.com/vektah/gqlparser/v2 v2.5.19 // indirect
	golang.org/x/mod v0.20.0 // indirect
	golang.org/x/sync v0.8.0 // indirect
	golang.org/x/tools v0.24.0 // indirect
	gopkg.in/yaml.v2 v2.4.0 // indirect
)
</file>

<file path="cmd/book.go">
package cmd

import (
	"context"
	"fmt"

	"github.com/spf13/cobra"

	"hardcover-cli/internal/client"
)

// bookCmd represents the book command
var bookCmd = &cobra.Command{
	Use:   "book",
	Short: "Manage and retrieve book information",
	Long: `Commands for managing and retrieving book information from Hardcover.app.

Available subcommands:
  get      Get detailed information about a specific book`,
}

// bookListCmd represents the book list command
var bookListCmd = &cobra.Command{
	Use:   "list",
	Short: "List books from Hardcover.app",
	Long: `Retrieves and displays a list of books from Hardcover.app.

The command will display:
- Book ID and description
- Slug and page count
- Rating and ratings count
- Release year
- Creation/update timestamps

Example:
  hardcover book list`,
	Args: cobra.NoArgs,
	RunE: func(cmd *cobra.Command, args []string) error {
		cfg, ok := getConfig(cmd.Context())
		if !ok {
			return fmt.Errorf("failed to get configuration")
		}

		if cfg.APIKey == "" {
			return fmt.Errorf("API key is required. Set it using:\n" +
				"  export HARDCOVER_API_KEY=\"your-api-key\"\n" +
				"  or\n" +
				"  hardcover config set-api-key \"your-api-key\"")
		}

		client := client.NewClient(cfg.BaseURL, cfg.APIKey)

		response, err := client.GetBooks(context.Background())
		if err != nil {
			return fmt.Errorf("failed to get books: %w", err)
		}

		books := response.GetBooks()

		if len(books) == 0 {
			printToStdoutf(cmd.OutOrStdout(), "No books found.\n")
			return nil
		}

		printToStdoutf(cmd.OutOrStdout(), "Books (%d found):\n\n", len(books))

		for i, book := range books {
			printToStdoutf(cmd.OutOrStdout(), "%d. Book ID: %d\n", i+1, book.GetId())

			if book.GetDescription() != "" {
				printToStdoutf(cmd.OutOrStdout(), "   Description: %s\n", book.GetDescription())
			}

			if book.GetSlug() != "" {
				printToStdoutf(cmd.OutOrStdout(), "   Slug: %s\n", book.GetSlug())
			}

			if book.GetPages() > 0 {
				printToStdoutf(cmd.OutOrStdout(), "   Pages: %d\n", book.GetPages())
			}

			if book.GetRating() > 0 {
				printToStdoutf(cmd.OutOrStdout(), "   Rating: %.2f (%d ratings)\n",
					book.GetRating(), book.GetRatings_count())
			}

			if book.GetRelease_year() > 0 {
				printToStdoutf(cmd.OutOrStdout(), "   Release Year: %d\n", book.GetRelease_year())
			}

			if book.GetCreated_at() != "" {
				printToStdoutf(cmd.OutOrStdout(), "   Created: %s\n", book.GetCreated_at())
			}

			if book.GetUpdated_at() != "" {
				printToStdoutf(cmd.OutOrStdout(), "   Updated: %s\n", book.GetUpdated_at())
			}

			printToStdoutf(cmd.OutOrStdout(), "\n")
		}

		return nil
	},
}

// bookGetCmd represents the book get command
var bookGetCmd = &cobra.Command{
	Use:   "get [book-id]",
	Short: "Get detailed information about a specific book",
	Long: `Retrieves and displays detailed information about a specific book from Hardcover.app.

The command will display:
- Book ID, title, and subtitle
- Description and slug
- Pages and release information
- Rating and ratings count
- Contributors and tags
- Creation/update timestamps

Example:
  hardcover book get 123`,
	Args: cobra.ExactArgs(1),
	RunE: func(cmd *cobra.Command, args []string) error {
		cfg, ok := getConfig(cmd.Context())
		if !ok {
			return fmt.Errorf("failed to get configuration")
		}

		if cfg.APIKey == "" {
			return fmt.Errorf("API key is required. Set it using:\n" +
				"  export HARDCOVER_API_KEY=\"your-api-key\"\n" +
				"  or\n" +
				"  hardcover config set-api-key \"your-api-key\"")
		}

		// Parse book ID
		var bookID int
		if _, err := fmt.Sscanf(args[0], "%d", &bookID); err != nil {
			return fmt.Errorf("invalid book ID: %s", args[0])
		}

		client := client.NewClient(cfg.BaseURL, cfg.APIKey)

		response, err := client.GetBook(context.Background(), bookID)
		if err != nil {
			return fmt.Errorf("failed to get book: %w", err)
		}

		book := response.GetBooks_by_pk()

		printToStdoutf(cmd.OutOrStdout(), "Book Details:\n\n")

		printToStdoutf(cmd.OutOrStdout(), "ID: %d\n", book.GetId())

		if book.GetTitle() != "" {
			printToStdoutf(cmd.OutOrStdout(), "Title: %s\n", book.GetTitle())
		}

		if book.GetSubtitle() != "" {
			printToStdoutf(cmd.OutOrStdout(), "Subtitle: %s\n", book.GetSubtitle())
		}

		if book.GetDescription() != "" {
			printToStdoutf(cmd.OutOrStdout(), "Description: %s\n", book.GetDescription())
		}

		if book.GetSlug() != "" {
			printToStdoutf(cmd.OutOrStdout(), "Slug: %s\n", book.GetSlug())
		}

		if book.GetPages() > 0 {
			printToStdoutf(cmd.OutOrStdout(), "Pages: %d\n", book.GetPages())
		}

		if book.GetRating() > 0 {
			printToStdoutf(cmd.OutOrStdout(), "Rating: %.2f (%d ratings)\n",
				book.GetRating(), book.GetRatings_count())
		}

		if book.GetRelease_year() > 0 {
			printToStdoutf(cmd.OutOrStdout(), "Release Year: %d\n", book.GetRelease_year())
		}

		if book.GetRelease_date() != "" {
			printToStdoutf(cmd.OutOrStdout(), "Release Date: %s\n", book.GetRelease_date())
		}

		if book.GetCached_contributors() != "" {
			printToStdoutf(cmd.OutOrStdout(), "Contributors: %s\n", book.GetCached_contributors())
		}

		if book.GetCached_tags() != "" {
			printToStdoutf(cmd.OutOrStdout(), "Tags: %s\n", book.GetCached_tags())
		}

		if book.GetCached_image() != "" {
			printToStdoutf(cmd.OutOrStdout(), "Image: %s\n", book.GetCached_image())
		}

		if book.GetCreated_at() != "" {
			printToStdoutf(cmd.OutOrStdout(), "Created: %s\n", book.GetCreated_at())
		}

		if book.GetUpdated_at() != "" {
			printToStdoutf(cmd.OutOrStdout(), "Updated: %s\n", book.GetUpdated_at())
		}

		return nil
	},
}

// setupBookCommands registers the book commands with the root command
func setupBookCommands() {
	bookCmd.AddCommand(bookListCmd)
	bookCmd.AddCommand(bookGetCmd)
	rootCmd.AddCommand(bookCmd)
}
</file>

<file path="cmd/me_test.go">
package cmd

import (
	"bytes"
	"context"
	"encoding/json"
	"net/http"
	"net/http/httptest"
	"testing"

	"github.com/spf13/cobra"
	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/require"

	"hardcover-cli/internal/config"
)

func TestMeCmd_Success(t *testing.T) {
	// Create test server
	server := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
		// Verify request
		assert.Equal(t, "POST", r.Method)
		assert.Equal(t, "Bearer test-api-key", r.Header.Get("Authorization"))

		// Verify GraphQL query
		var req map[string]interface{}
		err := json.NewDecoder(r.Body).Decode(&req)
		require.NoError(t, err)
		assert.Contains(t, req["query"], "query GetCurrentUser")
		assert.Contains(t, req["query"], "me")

		// Send response
		response := map[string]interface{}{
			"data": map[string]interface{}{
				"me": []map[string]interface{}{
					{
						"id":         123,
						"username":   "testuser",
						"email":      "test@example.com",
						"created_at": "2023-01-01T00:00:00Z",
						"updated_at": "2023-01-02T00:00:00Z",
					},
				},
			},
		}
		w.Header().Set("Content-Type", "application/json")
		json.NewEncoder(w).Encode(response)
	}))
	defer server.Close()

	// Create command with test context
	cfg := &config.Config{
		APIKey:  "test-api-key",
		BaseURL: server.URL,
	}
	ctx := withConfig(context.Background(), cfg)

	cmd := &cobra.Command{}
	cmd.SetContext(ctx)

	// Capture output
	var output bytes.Buffer
	cmd.SetOut(&output)

	// Execute command
	err := meCmd.RunE(cmd, []string{})
	require.NoError(t, err)

	// Verify output
	outputStr := output.String()
	assert.Contains(t, outputStr, "User Profile:")
	assert.Contains(t, outputStr, "ID: 123")
	assert.Contains(t, outputStr, "Username: testuser")
	assert.Contains(t, outputStr, "Email: test@example.com")
	assert.Contains(t, outputStr, "Created: 2023-01-01T00:00:00Z")
	assert.Contains(t, outputStr, "Updated: 2023-01-02T00:00:00Z")
}

func TestMeCmd_MissingAPIKey(t *testing.T) {
	// Create command with empty API key
	cfg := &config.Config{
		APIKey:  "",
		BaseURL: "https://api.hardcover.app/v1/graphql",
	}
	ctx := withConfig(context.Background(), cfg)

	cmd := &cobra.Command{}
	cmd.SetContext(ctx)

	// Execute command
	err := meCmd.RunE(cmd, []string{})
	require.Error(t, err)
	assert.Contains(t, err.Error(), "API key is required")
}

func TestMeCmd_NoConfig(t *testing.T) {
	// Create command without config
	cmd := &cobra.Command{}
	cmd.SetContext(context.Background())

	// Execute command
	err := meCmd.RunE(cmd, []string{})
	require.Error(t, err)
	assert.Contains(t, err.Error(), "failed to get configuration")
}

func TestMeCmd_APIError(t *testing.T) {
	// Create test server that returns error
	server := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
		response := map[string]interface{}{
			"data": nil,
			"errors": []map[string]interface{}{
				{
					"message": "User not found",
				},
			},
		}
		w.Header().Set("Content-Type", "application/json")
		json.NewEncoder(w).Encode(response)
	}))
	defer server.Close()

	// Create command with test context
	cfg := &config.Config{
		APIKey:  "test-api-key",
		BaseURL: server.URL,
	}
	ctx := withConfig(context.Background(), cfg)

	cmd := &cobra.Command{}
	cmd.SetContext(ctx)

	// Execute command
	err := meCmd.RunE(cmd, []string{})
	require.Error(t, err)
	assert.Contains(t, err.Error(), "failed to get user profile")
}

func TestMeCmd_HTTPError(t *testing.T) {
	// Create test server that returns HTTP error
	server := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
		w.WriteHeader(http.StatusUnauthorized)
		w.Write([]byte("Unauthorized"))
	}))
	defer server.Close()

	// Create command with test context
	cfg := &config.Config{
		APIKey:  "test-api-key",
		BaseURL: server.URL,
	}
	ctx := withConfig(context.Background(), cfg)

	cmd := &cobra.Command{}
	cmd.SetContext(ctx)

	// Execute command
	err := meCmd.RunE(cmd, []string{})
	require.Error(t, err)
	assert.Contains(t, err.Error(), "failed to get user profile")
}

func TestMeCmd_PartialData(t *testing.T) {
	// Create test server with minimal user data
	server := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
		response := map[string]interface{}{
			"data": map[string]interface{}{
				"me": []map[string]interface{}{
					{
						"id":       123,
						"username": "testuser",
					},
				},
			},
		}
		w.Header().Set("Content-Type", "application/json")
		json.NewEncoder(w).Encode(response)
	}))
	defer server.Close()

	// Create command with test context
	cfg := &config.Config{
		APIKey:  "test-api-key",
		BaseURL: server.URL,
	}
	ctx := withConfig(context.Background(), cfg)

	cmd := &cobra.Command{}
	cmd.SetContext(ctx)

	// Capture output
	var output bytes.Buffer
	cmd.SetOut(&output)

	// Execute command
	err := meCmd.RunE(cmd, []string{})
	require.NoError(t, err)

	// Verify output contains required fields but not optional ones
	outputStr := output.String()
	assert.Contains(t, outputStr, "ID: 123")
	assert.Contains(t, outputStr, "Username: testuser")
	assert.NotContains(t, outputStr, "Email:")
	assert.NotContains(t, outputStr, "Created:")
	assert.NotContains(t, outputStr, "Updated:")
}

func TestMeCmd_CommandProperties(t *testing.T) {
	// Test command properties
	assert.Equal(t, "me", meCmd.Use)
	assert.Equal(t, "Get your user profile information", meCmd.Short)
	assert.NotEmpty(t, meCmd.Long)
	assert.Contains(t, meCmd.Long, "User ID")
	assert.Contains(t, meCmd.Long, "Username")
	assert.Contains(t, meCmd.Long, "Email address")
	assert.Contains(t, meCmd.Long, "hardcover me")
}

func TestMeCmd_Integration(t *testing.T) {
	// Setup commands for testing
	SetupCommands()

	// Test the command is properly registered
	found := false
	for _, cmd := range rootCmd.Commands() {
		if cmd.Use == "me" {
			found = true
			break
		}
	}
	assert.True(t, found, "me command should be registered with root command")
}
</file>

<file path="internal/config/config.go">
package config

import (
	"fmt"
	"os"
	"path/filepath"
	"strings"

	yaml "gopkg.in/yaml.v3"
)

// Config holds the application configuration
type Config struct {
	APIKey  string `yaml:"api_key"`
	BaseURL string `yaml:"base_url"`
}

// DefaultConfig returns the default configuration
func DefaultConfig() *Config {
	return &Config{
		BaseURL: "https://api.hardcover.app/v1/graphql",
	}
}

// LoadConfig loads configuration from environment variables and config file
func LoadConfig() (*Config, error) {
	cfg := DefaultConfig()

	// Try to load from config file first
	configPath, err := getConfigPath()
	if err != nil {
		return nil, fmt.Errorf("failed to get config path: %w", err)
	}

	if _, statErr := os.Stat(configPath); !os.IsNotExist(statErr) {
		// Config file exists, load it
		data, err := os.ReadFile(configPath) //nolint:gosec // configPath is constructed from user home directory
		if err != nil {
			return nil, fmt.Errorf("failed to read config file: %w", err)
		}

		if err := yaml.Unmarshal(data, cfg); err != nil {
			return nil, fmt.Errorf("failed to parse config file: %w", err)
		}
	}

	// Check environment variable - it overrides config file
	if apiKey := os.Getenv("HARDCOVER_API_KEY"); apiKey != "" {
		// Trim whitespace and check if it's still non-empty
		if trimmedAPIKey := strings.TrimSpace(apiKey); trimmedAPIKey != "" {
			cfg.APIKey = trimmedAPIKey
		}
	}

	return cfg, nil
}

// SaveConfig saves the configuration to a file
func SaveConfig(cfg *Config) error {
	configPath, err := getConfigPath()
	if err != nil {
		return fmt.Errorf("failed to get config path: %w", err)
	}

	// Create config directory if it doesn't exist
	configDir := filepath.Dir(configPath)
	const configDirPerm = 0o750
	if mkdirErr := os.MkdirAll(configDir, configDirPerm); mkdirErr != nil {
		return fmt.Errorf("failed to create config directory: %w", mkdirErr)
	}

	data, err := yaml.Marshal(cfg)
	if err != nil {
		return fmt.Errorf("failed to marshal config: %w", err)
	}

	const configFilePerm = 0o600
	if err := os.WriteFile(configPath, data, configFilePerm); err != nil {
		return fmt.Errorf("failed to write config file: %w", err)
	}

	return nil
}

// getConfigPath returns the path to the configuration file
func getConfigPath() (string, error) {
	homeDir, err := os.UserHomeDir()
	if err != nil {
		return "", fmt.Errorf("failed to get home directory: %w", err)
	}

	return filepath.Join(homeDir, ".hardcover", "config.yaml"), nil
}

// GetConfigPath returns the configuration file path for external access
func GetConfigPath() (string, error) {
	return getConfigPath()
}
</file>

<file path=".github/workflows/nightly.yml">
name: Nightly Tests

on:
  schedule:
    # Run every night at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:

jobs:
  test-latest-dependencies:
    name: Test with Latest Dependencies
    runs-on: ubuntu-latest
    
    steps:
    - name: Set up Go
      uses: actions/setup-go@v4
      with:
        go-version: '1.21'
    
    - name: Check out code
      uses: actions/checkout@v4
    
    - name: Update to latest dependencies
      run: |
        go get -u ./...
        go mod tidy
    
    - name: Run tests with race detection
      run: go test -v -race -timeout=10m ./...
    
    - name: Run tests with coverage
      run: go test -v -coverprofile=coverage.out ./...
    
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.out
        flags: nightly
        name: nightly-coverage

  test-go-versions:
    name: Test Go Versions
    runs-on: ubuntu-latest
    strategy:
      matrix:
        go-version: ['1.19', '1.20', '1.21', '1.22']
    
    steps:
    - name: Set up Go ${{ matrix.go-version }}
      uses: actions/setup-go@v4
      with:
        go-version: ${{ matrix.go-version }}
    
    - name: Check out code
      uses: actions/checkout@v4
    
    - name: Cache Go modules
      uses: actions/cache@v3
      with:
        path: |
          ~/.cache/go-build
          ~/go/pkg/mod
        key: ${{ runner.os }}-go-${{ matrix.go-version }}-${{ hashFiles('**/go.sum') }}
        restore-keys: |
          ${{ runner.os }}-go-${{ matrix.go-version }}-
          ${{ runner.os }}-go-
    
    - name: Download dependencies
      run: go mod download
    
    - name: Run tests
      run: go test -v ./...
    
    - name: Build application
      run: go build -v .

  benchmark:
    name: Performance Benchmarks
    runs-on: ubuntu-latest
    
    steps:
    - name: Set up Go
      uses: actions/setup-go@v4
      with:
        go-version: '1.21'
    
    - name: Check out code
      uses: actions/checkout@v4
    
    - name: Cache Go modules
      uses: actions/cache@v3
      with:
        path: |
          ~/.cache/go-build
          ~/go/pkg/mod
        key: ${{ runner.os }}-go-1.21-${{ hashFiles('**/go.sum') }}
        restore-keys: |
          ${{ runner.os }}-go-1.21-
          ${{ runner.os }}-go-
    
    - name: Download dependencies
      run: go mod download
    
    - name: Run benchmarks
      run: |
        go test -bench=. -benchmem ./... | tee benchmark.txt
    
    - name: Store benchmark result
      uses: benchmark-action/github-action-benchmark@v1
      with:
        tool: 'go'
        output-file-path: benchmark.txt
        github-token: ${{ secrets.GITHUB_TOKEN }}
        auto-push: true
        comment-on-alert: true
        alert-threshold: '200%'
        fail-on-alert: false

  integration-test:
    name: Integration Tests
    runs-on: ubuntu-latest
    if: github.repository_owner == 'your-username'  # Only run for main repo
    
    steps:
    - name: Set up Go
      uses: actions/setup-go@v4
      with:
        go-version: '1.21'
    
    - name: Check out code
      uses: actions/checkout@v4
    
    - name: Cache Go modules
      uses: actions/cache@v3
      with:
        path: |
          ~/.cache/go-build
          ~/go/pkg/mod
        key: ${{ runner.os }}-go-1.21-${{ hashFiles('**/go.sum') }}
        restore-keys: |
          ${{ runner.os }}-go-1.21-
          ${{ runner.os }}-go-
    
    - name: Download dependencies
      run: go mod download
    
    - name: Build application
      run: go build -o hardcover .
    
    - name: Test CLI commands (without real API calls)
      run: |
        # Test help commands
        ./hardcover --help
        ./hardcover config --help
        ./hardcover search --help
        ./hardcover book --help
        
        # Test config commands (these don't require API)
        ./hardcover config show-path
        
        echo "Integration tests completed successfully"

  notify-failure:
    name: Notify on Failure
    runs-on: ubuntu-latest
    needs: [test-latest-dependencies, test-go-versions, benchmark, integration-test]
    if: failure()
    
    steps:
    - name: Create issue on failure
      uses: actions/github-script@v7
      with:
        script: |
          const title = `Nightly tests failed - ${new Date().toISOString().split('T')[0]}`;
          const body = `
          ## Nightly Test Failure
          
          The nightly tests have failed. Please investigate the following:
          
          - Check if there are any dependency conflicts
          - Verify external API compatibility
          - Review performance regressions
          - Check for Go version compatibility issues
          
          **Run details:** [View workflow run](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})
          
          **Commit:** ${{ github.sha }}
          **Branch:** ${{ github.ref }}
          
          This issue was automatically created by the nightly test workflow.
          `;
          
          const issues = await github.rest.issues.listForRepo({
            owner: context.repo.owner,
            repo: context.repo.repo,
            state: 'open',
            labels: 'nightly-failure'
          });
          
          // Check if there's already an open issue for nightly failures
          const existingIssue = issues.data.find(issue => 
            issue.title.includes('Nightly tests failed')
          );
          
          if (!existingIssue) {
            await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: title,
              body: body,
              labels: ['bug', 'nightly-failure', 'automated']
            });
          } else {
            // Add a comment to the existing issue
            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: existingIssue.number,
              body: `Nightly tests failed again on ${new Date().toISOString().split('T')[0]}. [View run](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})`
            });
          }
</file>

<file path=".github/workflows/dependency-update.yml">
name: Dependency Update

on:
  schedule:
    # Run weekly on Mondays at 9 AM UTC
    - cron: '0 9 * * 1'
  workflow_dispatch:

jobs:
  update-dependencies:
    name: Update Go Dependencies
    runs-on: ubuntu-latest
    
    steps:
    - name: Set up Go
      uses: actions/setup-go@v4
      with:
        go-version: '1.21'
    
    - name: Check out code
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
    
    - name: Configure git
      run: |
        git config --global user.name 'github-actions[bot]'
        git config --global user.email 'github-actions[bot]@users.noreply.github.com'
    
    - name: Update dependencies
      run: |
        go get -u ./...
        go mod tidy
    
    - name: Run tests
      run: go test ./...
    
    - name: Check for changes
      id: verify-changed-files
      run: |
        if [ -n "$(git status --porcelain)" ]; then
          echo "changed=true" >> $GITHUB_OUTPUT
        else
          echo "changed=false" >> $GITHUB_OUTPUT
        fi
    
    - name: Create Pull Request
      if: steps.verify-changed-files.outputs.changed == 'true'
      uses: peter-evans/create-pull-request@v5
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        commit-message: 'chore: update Go dependencies'
        title: 'chore: update Go dependencies'
        body: |
          ## Automated Dependency Update
          
          This PR updates Go dependencies to their latest versions.
          
          ### Changes
          - Updated all Go module dependencies
          - Ran `go mod tidy` to clean up unused dependencies
          
          ### Testing
          - [x] All tests pass
          - [x] Dependencies verified with `go mod verify`
          
          This is an automated pull request created by GitHub Actions.
        branch: dependency-updates
        delete-branch: true

  security-audit:
    name: Security Audit
    runs-on: ubuntu-latest
    
    steps:
    - name: Set up Go
      uses: actions/setup-go@v4
      with:
        go-version: '1.21'
    
    - name: Check out code
      uses: actions/checkout@v4
    
    - name: Cache Go modules
      uses: actions/cache@v3
      with:
        path: |
          ~/.cache/go-build
          ~/go/pkg/mod
        key: ${{ runner.os }}-go-1.21-${{ hashFiles('**/go.sum') }}
        restore-keys: |
          ${{ runner.os }}-go-1.21-
          ${{ runner.os }}-go-
    
    - name: Download dependencies
      run: go mod download
    
    - name: Install Nancy for dependency scanning
      run: go install github.com/sonatypecommunity/nancy@latest
    
    - name: Run Nancy security scan
      run: go list -json -deps ./... | nancy sleuth
    
    - name: Install govulncheck
      run: go install golang.org/x/vuln/cmd/govulncheck@latest
    
    - name: Run govulncheck
      run: govulncheck ./...
    
    - name: Run Gosec Security Scanner
      uses: securecodewarrior/github-action-gosec@master
      with:
        args: '-fmt sarif -out results.sarif ./...'
    
    - name: Upload SARIF file
      uses: github/codeql-action/upload-sarif@v2
      with:
        sarif_file: results.sarif

  license-check:
    name: License Check
    runs-on: ubuntu-latest
    
    steps:
    - name: Set up Go
      uses: actions/setup-go@v4
      with:
        go-version: '1.21'
    
    - name: Check out code
      uses: actions/checkout@v4
    
    - name: Cache Go modules
      uses: actions/cache@v3
      with:
        path: |
          ~/.cache/go-build
          ~/go/pkg/mod
        key: ${{ runner.os }}-go-1.21-${{ hashFiles('**/go.sum') }}
        restore-keys: |
          ${{ runner.os }}-go-1.21-
          ${{ runner.os }}-go-
    
    - name: Download dependencies
      run: go mod download
    
    - name: Install go-licenses
      run: go install github.com/google/go-licenses@latest
    
    - name: Check licenses
      run: |
        echo "Checking licenses for all dependencies..."
        go-licenses check ./...
        
        echo "Generating license report..."
        go-licenses report ./... > licenses.txt
        
        echo "License summary:"
        cat licenses.txt
</file>

<file path=".github/workflows/release.yml">
name: Release

on:
  push:
    tags:
      - 'v*'

jobs:
  test:
    name: Test Before Release
    runs-on: ubuntu-latest
    
    steps:
    - name: Set up Go
      uses: actions/setup-go@v4
      with:
        go-version: '1.23'
    
    - name: Check out code
      uses: actions/checkout@v4
    
    - name: Cache Go modules
      uses: actions/cache@v3
      with:
        path: |
          ~/.cache/go-build
          ~/go/pkg/mod
        key: ${{ runner.os }}-go-1.23-${{ hashFiles('**/go.sum') }}
        restore-keys: |
          ${{ runner.os }}-go-1.23-
          ${{ runner.os }}-go-
    
    - name: Download dependencies
      run: go mod download
    
    - name: Run tests
      run: go test -v -race ./...
    
    - name: Run linter
      uses: golangci/golangci-lint-action@v8
      with:
        version: latest

  build:
    name: Build and Release
    runs-on: ubuntu-latest
    needs: test
    
    strategy:
      matrix:
        goos: [linux, windows, darwin]
        goarch: [amd64, arm64]
        exclude:
          # Windows on ARM64 is not widely supported yet
          - goos: windows
            goarch: arm64
    
    steps:
    - name: Set up Go
      uses: actions/setup-go@v4
      with:
        go-version: '1.23'
    
    - name: Check out code
      uses: actions/checkout@v4
    
    - name: Cache Go modules
      uses: actions/cache@v3
      with:
        path: |
          ~/.cache/go-build
          ~/go/pkg/mod
        key: ${{ runner.os }}-go-1.23-${{ hashFiles('**/go.sum') }}
        restore-keys: |
          ${{ runner.os }}-go-1.23-
          ${{ runner.os }}-go-
    
    - name: Download dependencies
      run: go mod download
    
    - name: Build binary
      env:
        GOOS: ${{ matrix.goos }}
        GOARCH: ${{ matrix.goarch }}
      run: |
        VERSION=${GITHUB_REF#refs/tags/}
        BINARY_NAME=hardcover
        if [ "${{ matrix.goos }}" = "windows" ]; then
          BINARY_NAME="${BINARY_NAME}.exe"
        fi
        
        go build -ldflags="-s -w -X main.version=${VERSION}" -o ${BINARY_NAME} .
        
        # Create archive
        ARCHIVE_NAME="hardcover-${VERSION}-${{ matrix.goos }}-${{ matrix.goarch }}"
        if [ "${{ matrix.goos }}" = "windows" ]; then
          zip "${ARCHIVE_NAME}.zip" ${BINARY_NAME} README.md LICENSE
          echo "ASSET=${ARCHIVE_NAME}.zip" >> $GITHUB_ENV
        else
          tar -czf "${ARCHIVE_NAME}.tar.gz" ${BINARY_NAME} README.md LICENSE
          echo "ASSET=${ARCHIVE_NAME}.tar.gz" >> $GITHUB_ENV
        fi
    
    - name: Upload binary
      uses: actions/upload-artifact@v4
      with:
        name: ${{ env.ASSET }}
        path: ${{ env.ASSET }}

  release:
    name: Create Release
    runs-on: ubuntu-latest
    needs: build
    
    steps:
    - name: Check out code
      uses: actions/checkout@v4
    
    - name: Download all artifacts
      uses: actions/download-artifact@v4
      with:
        path: ./artifacts
    
    - name: Display structure of downloaded files
      run: ls -R ./artifacts
    
    - name: Create Release
      id: create_release
      uses: actions/create-release@v1
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      with:
        tag_name: ${{ github.ref }}
        release_name: Release ${{ github.ref }}
        draft: false
        prerelease: false
        body: |
          ## Changes in this Release
          
          See the [CHANGELOG](CHANGELOG.md) for detailed information about this release.
          
          ## Installation
          
          Download the appropriate binary for your platform:
          
          - **Linux (amd64)**: `hardcover-${{ github.ref }}-linux-amd64.tar.gz`
          - **Linux (arm64)**: `hardcover-${{ github.ref }}-linux-arm64.tar.gz`
          - **macOS (amd64)**: `hardcover-${{ github.ref }}-darwin-amd64.tar.gz`
          - **macOS (arm64)**: `hardcover-${{ github.ref }}-darwin-arm64.tar.gz`
          - **Windows (amd64)**: `hardcover-${{ github.ref }}-windows-amd64.zip`
          
          Extract the archive and move the binary to a directory in your PATH.
          
          ## Usage
          
          ```bash
          # Set your API key
          export HARDCOVER_API_KEY="your-api-key"
          
          # Or use config file
          hardcover config set-api-key "your-api-key"
          
          # Get help
          hardcover --help
          
          # Example commands
          hardcover me
          hardcover search books "golang"
          hardcover book get 12345
          ```
    
    - name: Upload Release Assets
      run: |
        for artifact in ./artifacts/*/; do
          file=$(find "$artifact" -type f \( -name "*.tar.gz" -o -name "*.zip" \))
          if [ -f "$file" ]; then
            echo "Uploading $file"
            gh release upload ${{ github.ref }} "$file"
          fi
        done
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

  homebrew:
    name: Update Homebrew Formula
    runs-on: ubuntu-latest
    needs: release
    if: startsWith(github.ref, 'refs/tags/v')
    
    steps:
    - name: Update Homebrew formula
      uses: mislav/bump-homebrew-formula-action@v3
      with:
        formula-name: hardcover-cli
        homebrew-tap: your-username/homebrew-tap
        base-branch: main
        download-url: https://github.com/${{ github.repository }}/releases/download/${{ github.ref }}/hardcover-${{ github.ref }}-darwin-amd64.tar.gz
      env:
        COMMITTER_TOKEN: ${{ secrets.COMMITTER_TOKEN }}
</file>

<file path=".github/workflows/ci.yml">
name: CI

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

jobs:
  test:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Go
      uses: actions/setup-go@v4
      with:
        go-version: '1.23'
    
    - name: Cache Go modules
      uses: actions/cache@v3
      with:
        path: |
          ~/.cache/go-build
          ~/go/pkg/mod
        key: ${{ runner.os }}-go-${{ hashFiles('**/go.sum') }}
        restore-keys: |
          ${{ runner.os }}-go-
    
    - name: Download dependencies
      run: go mod download
    
    - name: Run tests
      run: go test -v ./...
    
    - name: Run tests with coverage
      run: go test -v -coverprofile=coverage.out ./...
    
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.out
        flags: unittests
        name: codecov-umbrella
        fail_ci_if_error: false
    
    - name: Build
      run: go build -v ./...
    
    - name: Build binary
      run: make build
    
    - name: Test binary help
      run: ./bin/hardcover-cli --help

  lint:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Go
      uses: actions/setup-go@v4
      with:
        go-version: '1.23'
    
    - name: golangci-lint
      uses: golangci/golangci-lint-action@v7
      with:
        version: v2.2.1
        args: --timeout=3m
</file>

</files>
